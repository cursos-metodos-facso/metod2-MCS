[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "La presente evaluación tiene por objetivo que las y los estudiantes apliquen de forma integral los contenidos del curso a una temática de interés específica utilizando la base de datos del Estudio Social Longitudinal de Chile (ELSOC) 2022. Se espera un ejercicio de investigación que logre dar cuenta del aprendizaje de las herramientas de análisis estadístico que configuran las habilidades básicas para desarrollar procesos de investigación social, analizando fuentes de información de carácter cuantitativo desde una perspectiva sociológica.\n\n\n\nEl trabajo debe ser realizado en parejas.\nSe realizará una entrega final tipo reporte de investigación breve.\nSe recomienda que elaboren un problema de investigación que trate sobre las características sociales de algún problema actual de la sociedad chilena, y que sea factible de investigar con los datos del Estudio Social Longitudinal de Chile (ELSOC) 2022.\n\n\n\n\nPara la entrega del informe se espera que, habiendo seleccionado un fenómeno específico de interés, se desarrollen los siguientes temas:\n\n\n\n\n\n\n\n\nComponente\nDetalle\nPuntaje\n\n\n\n\nFormulación del problema\nFormular una pregunta y un objetivo general de investigación. Fundamentar el interés sociológico que habilita el estudio de la temática elegida, utilizando al menos 3 referencias bibliográficas. El objetivo de investigación formulado debe permitir entender cómo se analizará la temática elegida. (1 plana)\n2.0\n\n\nDefinición base de datos\nDefinir la fuente de información a utilizar indicando el nombre de la base de datos y la institución que la disponibiliza, la población que busca representar el estudio, el procedimiento de muestreo utilizado y el tamaño de la muestra. Dado que trabajaremos solo con el Estudio Social Longitudinal de Chile (ELSOC) 2022, se espera que las parejas describan qué busca medir y representar el módulo (o selección de variables) elegido. (½ plana)\n1.0\n\n\nOperacionalización y descripción de variables\nOperacionalizar correctamente las variables de interés. Esta sección también incluye una tabla de descriptivos básicos, y una descripción detallada de la operacionalización y medición de las variables. - Tabla de descriptivos: etiquetas claras, debe ser posible identificar cada variable - Descripción de la operacionalización de cada variable y recodificación apropiada (por ejemplo, de menos a más presencia del atributo medido)\n3.0\n\n\nInferencia y Correlación\nEstimar, visualizar e interpretar los coeficientes de correlación entre variables. - Matriz de correlaciones (tabla): 1 - interpretación de tamaño de efecto: 1 - inferencia: 1\n3.0\n\n\nRegresión lineal\nEstimar, visualizar e interpretar coeficientes de regresión lineal - tabla de regresión: 0.5 - interpretación de coeficientes (interpretación de efectos de interacción es opcional, pero se valorará positivamente): 1 - inferencia/significación: 1 - ajuste global del modelo (R2): 0.5.\n3.0\n\n\nRegresión logística\nEstimar, visualizar e interpretar coeficientes de regresión logística - tabla de regresión: 0.5 - interpretación coeficientes (interpretación de efectos de interacción es opcional, pero se valorará positivamente): 1 - inferencia: 1 - ajuste: 0.5\n3.0\n\n\nConclusiones\nEn las conclusiones se deben sintetizar los aspectos más relevantes de los análisis estadísticos ya expuestos, articulando toda la información trabajada debe presentarse una respuesta tentativa a la pregunta de investigación. Además, debe reflexionar sobre los límites de su diseño de investigación y señalar posibles ejes de investigación que podrían ser considerados en futuras indagaciones (1 plana).\n2.0\n\n\nTrabajo en R\nAdemás del informe, entregar la carpeta con el Proyecto R, que contenga un archivo .Rproject, y las carpetas input, procesamiento y output. - La carpeta input debe contener la base de datos, manual de usuario, libro de códigos. - La carpeta procesamiento debe contener un archivo de sintaxis para el procesamiento y otro para el análisis de los datos. - La carpeta output debe contener la base de datos procesada y el resto de salidas asociadas (tablas, gráficos, etc.). - Se evaluará que los códigos utilizados generen las salidas (tablas, gráficos, etc.) que se presentan en el informe.\n1.0\n\n\n\n\n\n\nPara la construcción del reporte de investigación por favor considere:\n● El trabajo debe tener una portada que incluya: título, logo de la universidad, nombre de los estudiantes, profesor/a, fecha y ayudantes.\n● Debe incluirse un índice. Tablas, referencias y bibliografía utilizada debe presentarse en formato APA.\n● La fuente a utilizar debe ser Letra Times New Roman 12, interlineado simple y justificado. Notas a pie de página en tamaño 10, en mismo formato que el texto central.\n● El trabajo debe tener una redacción adecuada y sin errores de ortografía.\n● Se descontarán hasta 5 décimas sobre la nota final por errores de este tipo.\n\n\n\nEl formato de entrega del informe debe ser un documento en formato PDF (.pdf), que debe estar alojado en la carpeta output del Proyecto R. Fecha de entrega: jueves 18 de julio hasta las 12:00AM vía módulo Tareas en plataforma U-Cursos.\n● Entregas atrasadas hasta las 23:59 del jueves 18 de julio tendrán 0,5 puntos de descuento sobre la nota final.\n● Entregas atrasadas hasta el viernes 19 de julio hasta las 23:59 tendrán 1,0 punto de descuento sobre la nota final. No serán evaluadas entregas posteriores a esta fecha.\n\n\n\nTodos los trabajos se procesan en software para detección de plagio: evidencia de una situación de plagio implica obtención de la nota mínima en la evaluación (1,0) junto con constituirse como causal de reprobación de la asignatura.\n\n\n\n● Máxima de escritura: una idea por párrafo. Si comienza una idea nueva, se recomienda comenzar otro párrafo. Al revés, si el párrafo siguiente habla de lo mismo, sumarlo al párrafo anterior.\n● La idea del párrafo se resume en la primera parte del párrafo, lo que en inglés se llama “topic sentence”.\n● Declarar domicilio disciplinar: ej, mencionar la palabra “sociología” en el primer/segundo párrafo, esto fuerza que la investigación se enmarque en la disciplina.\nEn caso de tener dudas, no dude en contactar a sus ayudantes respectivos, o bien, vía foro U-Cursos al equipo docente de la asignatura."
  },
  {
    "objectID": "trabajos.html#cuestiones-a-considerar",
    "href": "trabajos.html#cuestiones-a-considerar",
    "title": "Trabajos",
    "section": "",
    "text": "El trabajo debe ser realizado en parejas.\nSe realizará una entrega final tipo reporte de investigación breve.\nSe recomienda que elaboren un problema de investigación que trate sobre las características sociales de algún problema actual de la sociedad chilena, y que sea factible de investigar con los datos del Estudio Social Longitudinal de Chile (ELSOC) 2022."
  },
  {
    "objectID": "trabajos.html#instrucciones-para-el-informe",
    "href": "trabajos.html#instrucciones-para-el-informe",
    "title": "Trabajos",
    "section": "",
    "text": "Para la entrega del informe se espera que, habiendo seleccionado un fenómeno específico de interés, se desarrollen los siguientes temas:\n\n\n\n\n\n\n\n\nComponente\nDetalle\nPuntaje\n\n\n\n\nFormulación del problema\nFormular una pregunta y un objetivo general de investigación. Fundamentar el interés sociológico que habilita el estudio de la temática elegida, utilizando al menos 3 referencias bibliográficas. El objetivo de investigación formulado debe permitir entender cómo se analizará la temática elegida. (1 plana)\n2.0\n\n\nDefinición base de datos\nDefinir la fuente de información a utilizar indicando el nombre de la base de datos y la institución que la disponibiliza, la población que busca representar el estudio, el procedimiento de muestreo utilizado y el tamaño de la muestra. Dado que trabajaremos solo con el Estudio Social Longitudinal de Chile (ELSOC) 2022, se espera que las parejas describan qué busca medir y representar el módulo (o selección de variables) elegido. (½ plana)\n1.0\n\n\nOperacionalización y descripción de variables\nOperacionalizar correctamente las variables de interés. Esta sección también incluye una tabla de descriptivos básicos, y una descripción detallada de la operacionalización y medición de las variables. - Tabla de descriptivos: etiquetas claras, debe ser posible identificar cada variable - Descripción de la operacionalización de cada variable y recodificación apropiada (por ejemplo, de menos a más presencia del atributo medido)\n3.0\n\n\nInferencia y Correlación\nEstimar, visualizar e interpretar los coeficientes de correlación entre variables. - Matriz de correlaciones (tabla): 1 - interpretación de tamaño de efecto: 1 - inferencia: 1\n3.0\n\n\nRegresión lineal\nEstimar, visualizar e interpretar coeficientes de regresión lineal - tabla de regresión: 0.5 - interpretación de coeficientes (interpretación de efectos de interacción es opcional, pero se valorará positivamente): 1 - inferencia/significación: 1 - ajuste global del modelo (R2): 0.5.\n3.0\n\n\nRegresión logística\nEstimar, visualizar e interpretar coeficientes de regresión logística - tabla de regresión: 0.5 - interpretación coeficientes (interpretación de efectos de interacción es opcional, pero se valorará positivamente): 1 - inferencia: 1 - ajuste: 0.5\n3.0\n\n\nConclusiones\nEn las conclusiones se deben sintetizar los aspectos más relevantes de los análisis estadísticos ya expuestos, articulando toda la información trabajada debe presentarse una respuesta tentativa a la pregunta de investigación. Además, debe reflexionar sobre los límites de su diseño de investigación y señalar posibles ejes de investigación que podrían ser considerados en futuras indagaciones (1 plana).\n2.0\n\n\nTrabajo en R\nAdemás del informe, entregar la carpeta con el Proyecto R, que contenga un archivo .Rproject, y las carpetas input, procesamiento y output. - La carpeta input debe contener la base de datos, manual de usuario, libro de códigos. - La carpeta procesamiento debe contener un archivo de sintaxis para el procesamiento y otro para el análisis de los datos. - La carpeta output debe contener la base de datos procesada y el resto de salidas asociadas (tablas, gráficos, etc.). - Se evaluará que los códigos utilizados generen las salidas (tablas, gráficos, etc.) que se presentan en el informe.\n1.0"
  },
  {
    "objectID": "trabajos.html#aspectos-formales",
    "href": "trabajos.html#aspectos-formales",
    "title": "Trabajos",
    "section": "",
    "text": "Para la construcción del reporte de investigación por favor considere:\n● El trabajo debe tener una portada que incluya: título, logo de la universidad, nombre de los estudiantes, profesor/a, fecha y ayudantes.\n● Debe incluirse un índice. Tablas, referencias y bibliografía utilizada debe presentarse en formato APA.\n● La fuente a utilizar debe ser Letra Times New Roman 12, interlineado simple y justificado. Notas a pie de página en tamaño 10, en mismo formato que el texto central.\n● El trabajo debe tener una redacción adecuada y sin errores de ortografía.\n● Se descontarán hasta 5 décimas sobre la nota final por errores de este tipo."
  },
  {
    "objectID": "trabajos.html#fecha-y-formato-de-entrega",
    "href": "trabajos.html#fecha-y-formato-de-entrega",
    "title": "Trabajos",
    "section": "",
    "text": "El formato de entrega del informe debe ser un documento en formato PDF (.pdf), que debe estar alojado en la carpeta output del Proyecto R. Fecha de entrega: jueves 18 de julio hasta las 12:00AM vía módulo Tareas en plataforma U-Cursos.\n● Entregas atrasadas hasta las 23:59 del jueves 18 de julio tendrán 0,5 puntos de descuento sobre la nota final.\n● Entregas atrasadas hasta el viernes 19 de julio hasta las 23:59 tendrán 1,0 punto de descuento sobre la nota final. No serán evaluadas entregas posteriores a esta fecha."
  },
  {
    "objectID": "trabajos.html#sobre-plagio",
    "href": "trabajos.html#sobre-plagio",
    "title": "Trabajos",
    "section": "",
    "text": "Todos los trabajos se procesan en software para detección de plagio: evidencia de una situación de plagio implica obtención de la nota mínima en la evaluación (1,0) junto con constituirse como causal de reprobación de la asignatura."
  },
  {
    "objectID": "trabajos.html#recomendaciones-para-la-entrega",
    "href": "trabajos.html#recomendaciones-para-la-entrega",
    "title": "Trabajos",
    "section": "",
    "text": "● Máxima de escritura: una idea por párrafo. Si comienza una idea nueva, se recomienda comenzar otro párrafo. Al revés, si el párrafo siguiente habla de lo mismo, sumarlo al párrafo anterior.\n● La idea del párrafo se resume en la primera parte del párrafo, lo que en inglés se llama “topic sentence”.\n● Declarar domicilio disciplinar: ej, mencionar la palabra “sociología” en el primer/segundo párrafo, esto fuerza que la investigación se enmarque en la disciplina.\nEn caso de tener dudas, no dude en contactar a sus ayudantes respectivos, o bien, vía foro U-Cursos al equipo docente de la asignatura."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases teóricas y las actividades prácticas. Las clases se realizarán los días Viernes 09:00 a 10:50 en sala 334\n\nClases ( ): Lecturas, documentos de presentación y video (en caso que la sesión sea grabada)\nPrácticos y evaluaciones (): Actividades prácticas a desarrollar en clases y durante la semana.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n\n\n\n\n\n\n Clases\n Prácticas y evaluaciones\n Lecturas y material adicional\n\n\n\n\n\n\nUNIDAD 0: Introducción\n\n\n\n Marzo \n\n\n\n\n\nViernes 21\nIntroducción\nAproximación inicial a R\n- Leer detalladamente programa del curso\n\n\nViernes 28\nDocumentos Dinámicos y Markdown/Quarto\nDocumentos Dinámicos y Markdown/Quarto\n\n\n\n Abril \n\n\n\n\n\nViernes 04\nIntroducción a R/Rstudio y Estadística Descriptiva\n\n\n\n\nViernes 11\n1° Semana de integración\n\n\n\n\nViernes 18\nFeriado\n\n\n\n\n\n\n\nUNIDAD 1: Inferencia y Estadística Correlacional\n\n\n\nViernes 25\nCorrelación 1: Inferencia\n\n\n\n\n Mayo \n\n\n\n\n\nViernes 02\nCorrelación 2: Asociación\n\n\n\n\nViernes 09\nCorrelación 3: Categóricas\n\n\n\n\nViernes 16\n2° Semana de integración\n\n\n\n\nViernes 23\nSemana de pausa Escuela de Pregrado\n\n\n\n\n\n\n\nUNIDAD 2: Regresión lineal y regresión logística\n\n\n\nViernes 30\nRegresión lineal 1\n\n\n\n\n Junio \n\n\n\n\n\nViernes 06\nRegresión lineal 2\n\n\n\n\nViernes 13\n3° Semana de integración\n\n\n\n\nViernes 20\nFeriado\n\n\n\n\nViernes 27\nRegresión logística\n\n\n\n\n Julio \n\n\n\n\n\nViernes 04\nDocumentos Dinámicos y Markdown/Quarto\n\n\n\n\nViernes 11\n\nEvaluación\n\n\n\n—–\n—-\n———–\n———–"
  },
  {
    "objectID": "resource/08-resource.html",
    "href": "resource/08-resource.html",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de introducir en los supuestos y robustez del modelo de regresión. Por esta razón, volveremos a algunos de los contenidos previos relacionados con la estimación, análisis de residuos y ajuste. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\nLa versión original de este ejercicio proviene del curso de Estadística multivariada versión 2022."
  },
  {
    "objectID": "resource/08-resource.html#explorar-datos",
    "href": "resource/08-resource.html#explorar-datos",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "Explorar datos",
    "text": "Explorar datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\n\nview(dfSummary(elsoc, headings = FALSE, method = \"render\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nsexo [numeric]\nSexo entrevistado\n\n\n\nMin : 0\n\n\nMean : 0.6\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n1446\n(\n38.6%\n)\n\n\n1\n:\n2302\n(\n61.4%\n)\n\n\n\n\n3748 (100.0%)\n0 (0.0%)\n\n\n2\nedad [numeric]\nEdad entrevistado\n\n\n\nMean (sd) : 47.1 (15.5)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 47 ≤ 90\n\n\nIQR (CV) : 25 (0.3)\n\n\n\n70 distinct values\n\n3748 (100.0%)\n0 (0.0%)\n\n\n3\neduc [factor]\nNivel educacional\n\n\n\n1. 1\n\n\n2. 2\n\n\n3. 3\n\n\n4. 4\n\n\n5. 5\n\n\n\n\n\n\n450\n(\n12.0%\n)\n\n\n370\n(\n9.9%\n)\n\n\n1600\n(\n42.7%\n)\n\n\n598\n(\n16.0%\n)\n\n\n725\n(\n19.4%\n)\n\n\n\n\n3743 (99.9%)\n5 (0.1%)\n\n\n4\npospol [factor]\nAutoubicacion escala izquierda-derecha\n\n\n\n1. 1\n\n\n2. 2\n\n\n3. 3\n\n\n4. 4\n\n\n\n\n\n\n807\n(\n22.0%\n)\n\n\n952\n(\n26.0%\n)\n\n\n734\n(\n20.0%\n)\n\n\n1171\n(\n32.0%\n)\n\n\n\n\n3664 (97.8%)\n84 (2.2%)\n\n\n5\npart01 [numeric]\nFrecuencia: Firma carta o peticion apoyando causa\n\n\n\nMean (sd) : 1.5 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 1 (0.6)\n\n\n\n\n\n\n1\n:\n2717\n(\n72.6%\n)\n\n\n2\n:\n476\n(\n12.7%\n)\n\n\n3\n:\n411\n(\n11.0%\n)\n\n\n4\n:\n117\n(\n3.1%\n)\n\n\n5\n:\n21\n(\n0.6%\n)\n\n\n\n\n3742 (99.8%)\n6 (0.2%)\n\n\n6\npart02 [numeric]\nFrecuencia: Asiste a marcha o manifestacion pacifica\n\n\n\nMean (sd) : 1.2 (0.6)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 0 (0.5)\n\n\n\n\n\n\n1\n:\n3289\n(\n87.8%\n)\n\n\n2\n:\n195\n(\n5.2%\n)\n\n\n3\n:\n191\n(\n5.1%\n)\n\n\n4\n:\n51\n(\n1.4%\n)\n\n\n5\n:\n19\n(\n0.5%\n)\n\n\n\n\n3745 (99.9%)\n3 (0.1%)\n\n\n7\npart03 [numeric]\nFrecuencia: Participa en huelga\n\n\n\nMean (sd) : 1.2 (0.5)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 0 (0.5)\n\n\n\n\n\n\n1\n:\n3407\n(\n91.0%\n)\n\n\n2\n:\n152\n(\n4.1%\n)\n\n\n3\n:\n146\n(\n3.9%\n)\n\n\n4\n:\n29\n(\n0.8%\n)\n\n\n5\n:\n11\n(\n0.3%\n)\n\n\n\n\n3745 (99.9%)\n3 (0.1%)\n\n\n8\npart04 [numeric]\nFrecuencia: Usa redes sociales para opinar en temas publicos\n\n\n\nMean (sd) : 1.6 (1.1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 1 (0.7)\n\n\n\n\n\n\n1\n:\n2598\n(\n69.4%\n)\n\n\n2\n:\n310\n(\n8.3%\n)\n\n\n3\n:\n514\n(\n13.7%\n)\n\n\n4\n:\n223\n(\n6.0%\n)\n\n\n5\n:\n98\n(\n2.6%\n)\n\n\n\n\n3743 (99.9%)\n5 (0.1%)\n\n\n9\nquintilemiss [factor]\n\n\n\n\n1. Quintil 1\n\n\n2. Quintil 2\n\n\n3. Quintil 3\n\n\n4. Quintil 4\n\n\n5. Quintil 5\n\n\n6. Missing\n\n\n\n\n\n\n711\n(\n19.0%\n)\n\n\n711\n(\n19.0%\n)\n\n\n710\n(\n18.9%\n)\n\n\n710\n(\n18.9%\n)\n\n\n710\n(\n18.9%\n)\n\n\n196\n(\n5.2%\n)\n\n\n\n\n3748 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-04-25\n\n\n\n\nview_df(elsoc,max.len = 50)\n\n\nData frame: elsoc\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nsexo\nSexo entrevistado\n0\n1\nHombre\nMujer\n\n\n2\nedad\nEdad entrevistado\nrange: 18-90\n\n\n3\neduc\nNivel educacional\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\n\n\n4\npospol\nAutoubicacion escala izquierda-derecha\n1\n2\n3\n4\nDerecha\nCentro\nIzquierda\nIndep./Ninguno\n\n\n5\npart01\nFrecuencia: Firma carta o peticion apoyando causa\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n6\npart02\nFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n7\npart03\nFrecuencia: Participa en huelga\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n8\npart04\nFrecuencia: Usa redes sociales para opinar en\ntemas publicos\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n9\nquintilemiss\n\n\nQuintil 1\nQuintil 2\nQuintil 3\nQuintil 4\nQuintil 5\nMissing\n\n\n\n\n\n\nelsoc &lt;- elsoc %&gt;% mutate(partpol=rowSums(select(., part01,part02,part03,part04)))"
  },
  {
    "objectID": "resource/08-resource.html#diágnosticos",
    "href": "resource/08-resource.html#diágnosticos",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "Diágnosticos",
    "text": "Diágnosticos\n\nCasos influyentes\nPara determinar si un outlier es un caso influyente, es decir que su presencia/ausencia genera un cambio importante en la estimación de los coeficientes de regresión, calculamos la Distancia de Cook..\nPosteriormente, se establece un punto de corte de \\(4/(n-k-1)\\):\n\nn&lt;- nobs(fit04) #n de observaciones\nk&lt;- length(coef(fit04)) # n de parametros\ndcook&lt;- 4/(n-k-1) #punt de corte\n\nSi lo graficamos se ve de la siguiente manera:\n\nfinal &lt;- broom::augment_columns(fit04,data = elsoc)\nfinal$id &lt;- as.numeric(row.names(final))\n# identify obs with Cook's D above cutoff\nggplot(final, aes(id, .cooksd)) +\n  geom_bar(stat=\"identity\", position=\"identity\") +\n  xlab(\"Obs. Number\")+ # Modificación nombre eje x\n  ylab(\"Cook's distance\")+ # Modificación nombre eje y\n  geom_hline(yintercept=dcook)+ # Incluir una línea horizontal\n  geom_text(aes(label=ifelse((.cooksd&gt;dcook),id,\"\")), # geom text agrega nombre a los casos, en esta oportunidad solo a los valores mayores a dcook\n            vjust=-0.2, hjust=0.5)\n\n\n\n\nIdentificamos los casos influyentes y filtramos la base de datos:\n\nident&lt;- final %&gt;% filter(.cooksd&gt;dcook)\nelsoc02 &lt;- final %&gt;% filter(!(id %in% ident$id))\n\nEstimación sin casos influyentes:\n\nfit05&lt;- lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc02)\n\nlabs02 &lt;- c(\"Intercepto\",\"Sexo (mujer=1)\",\"Edad\",\n            \"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Quintil perdido\",\n            \"Izquierda (ref. derecha)\",\"Centro\",\"Idep./Ninguno\")\n\nhtmlreg(list(fit04,fit05), \n        doctype = FALSE,\n        custom.model.names = c(\"Modelo 4\", \"Modelo 5\"),\n        custom.coef.names = labs02)\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo 4\n\n\nModelo 5\n\n\n\n\n\n\nIntercepto\n\n\n7.97***\n\n\n7.05***\n\n\n\n\n \n\n\n(0.16)\n\n\n(0.11)\n\n\n\n\nSexo (mujer=1)\n\n\n0.12\n\n\n0.07\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.05)\n\n\n\n\nEdad\n\n\n-0.04***\n\n\n-0.03***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nQuintil 2\n\n\n0.21\n\n\n0.11\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 3\n\n\n0.51***\n\n\n0.34***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 4\n\n\n0.50***\n\n\n0.32***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 5\n\n\n0.88***\n\n\n0.57***\n\n\n\n\n \n\n\n(0.12)\n\n\n(0.08)\n\n\n\n\nQuintil perdido\n\n\n0.59***\n\n\n0.31*\n\n\n\n\n \n\n\n(0.18)\n\n\n(0.13)\n\n\n\n\nIzquierda (ref. derecha)\n\n\n-1.04***\n\n\n-0.65***\n\n\n\n\n \n\n\n(0.10)\n\n\n(0.07)\n\n\n\n\nCentro\n\n\n-1.13***\n\n\n-0.71***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nIdep./Ninguno\n\n\n-1.60***\n\n\n-1.14***\n\n\n\n\n \n\n\n(0.10)\n\n\n(0.07)\n\n\n\n\nR2\n\n\n0.17\n\n\n0.18\n\n\n\n\nAdj. R2\n\n\n0.17\n\n\n0.18\n\n\n\n\nNum. obs.\n\n\n3656\n\n\n3460\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n\nEn términos generales, el sentido y significación estadística de los coeficientes del Modelo 5 se mantiene respecto al Modelo 4. Adicionalmente, si observamos que el modelo sin casos influyentes presenta una mejora en ajuste. Por lo tanto, los análisis posteriores se realizaran en base a este modelo.\n\n\nLinealidad\nPara analizar la linealidad respecto de un modelo de regresión, debemos analizar la distribución de los residuos con respecto a la recta de regresión.\n\nLos residuos deben ser independientes de los valores predichos (fitted values).\nCualquier correlación entre residuo y valores predichos violarían este supuesto.\nLa presencia de un patrón no lineal, es señal de que el modelo está especificado incorrectamente.\n\n\nggplot(fit05, aes(.fitted, .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_smooth(se = TRUE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nRelación entre residuos y valores predichos\n\n\n\n\nEl gráfico nos indica que existe un patrón en la distribución de los residuos. Para intentar mejorar la estimación podemos realizar una transformación de variables. A continuación presentaremos un ejemplo para la Edad y para los Ingresos.\n\nPolinomio: \\(\\text{Edad}^2\\)\n\n\nelsoc02$edad2 &lt;- elsoc02$edad^2\nfit06&lt;- lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\n\n\nedad&lt;- fit06$model$edad\nfit&lt;- fit06$fitted.values\ndata01 &lt;- as.data.frame(cbind(edad,fit))\n\nggplot(data01, aes(x = edad, y = fit)) +\n  theme_bw() +\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nEfecto cuadrático de la edad (Modelo 5)\n\n\n\n\n\nfit07 &lt;- lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\n\nlabs03 &lt;- c(\"Intercepto\",\"Sexo (mujer=1)\",\"Edad\",\n            \"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Quintil perdido\",\n            \"Izquierda (ref. derecha)\",\"Centro\",\"Idep./Ninguno\", \"Edad²\")\n\nhtmlreg(list(fit05, fit06, fit07), doctype = FALSE,\n        custom.model.names = c(\"Modelo 4\", \"Modelo 5\", \"Modelo 6\"), \n          custom.coef.names = labs03)\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo 4\n\n\nModelo 5\n\n\nModelo 6\n\n\n\n\n\n\nIntercepto\n\n\n7.05***\n\n\n7.62***\n\n\n7.62***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.24)\n\n\n(0.24)\n\n\n\n\nSexo (mujer=1)\n\n\n0.07\n\n\n0.08\n\n\n0.08\n\n\n\n\n \n\n\n(0.05)\n\n\n(0.05)\n\n\n(0.05)\n\n\n\n\nEdad\n\n\n-0.03***\n\n\n-0.06***\n\n\n-0.06***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n\n\nQuintil 2\n\n\n0.11\n\n\n0.11\n\n\n0.11\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 3\n\n\n0.34***\n\n\n0.34***\n\n\n0.34***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 4\n\n\n0.32***\n\n\n0.32***\n\n\n0.32***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 5\n\n\n0.57***\n\n\n0.57***\n\n\n0.57***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil perdido\n\n\n0.31*\n\n\n0.31*\n\n\n0.31*\n\n\n\n\n \n\n\n(0.13)\n\n\n(0.13)\n\n\n(0.13)\n\n\n\n\nIzquierda (ref. derecha)\n\n\n-0.65***\n\n\n-0.65***\n\n\n-0.65***\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.07)\n\n\n(0.07)\n\n\n\n\nCentro\n\n\n-0.71***\n\n\n-0.70***\n\n\n-0.70***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nIdep./Ninguno\n\n\n-1.14***\n\n\n-1.13***\n\n\n-1.13***\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.07)\n\n\n(0.07)\n\n\n\n\nEdad²\n\n\n \n\n\n0.00**\n\n\n0.00**\n\n\n\n\n \n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nR2\n\n\n0.18\n\n\n0.19\n\n\n0.19\n\n\n\n\nAdj. R2\n\n\n0.18\n\n\n0.18\n\n\n0.18\n\n\n\n\nNum. obs.\n\n\n3460\n\n\n3460\n\n\n3460\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05"
  },
  {
    "objectID": "resource/08-resource.html#referencias",
    "href": "resource/08-resource.html#referencias",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "Referencias",
    "text": "Referencias\nDarlington & Hayes 2016 Cap16 Detecting and Managing Irregularities\nDarlington & Hayes 2016 Cap12 Nonlinear relationships"
  },
  {
    "objectID": "resource/06-resource.html",
    "href": "resource/06-resource.html",
    "title": "Práctico 6. Asociación con variables categóricas",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en técnicas de asociación entre variables categóricas, aplicando lo apredendido hasta ahora sobre inferencia estadística.\nEn detalle, aprenderemos:\n\nGenerar y analizar tablas de contingencia (o cruzadas)\nEstimar e interpretar la prueba de Chi-cuadrado\nAplicar coeficientes de correlación entre variables categóricas\n\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienen la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022."
  },
  {
    "objectID": "resource/06-resource.html#recursos-de-la-práctica",
    "href": "resource/06-resource.html#recursos-de-la-práctica",
    "title": "Práctico 6. Asociación con variables categóricas",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienen la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022."
  },
  {
    "objectID": "resource/04-resource.html",
    "href": "resource/04-resource.html",
    "title": "Práctico 4. Inferencia Estadística y Curva Normal",
    "section": "",
    "text": "El objetivo de esta guía práctica es continuar profundizando en la inferencia estadística, en particular en .\n\nAplicar pruebas de hipótesis de diferencia de medias.\nAplicar pruebas de hipótesis direccionales.\nAplicar inferencia estadística a proporciones.\nEmplear la correlación en contexto de inferencia.\n\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022."
  },
  {
    "objectID": "resource/04-resource.html#recursos-de-la-práctica",
    "href": "resource/04-resource.html#recursos-de-la-práctica",
    "title": "Práctico 4. Inferencia Estadística y Curva Normal",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022."
  },
  {
    "objectID": "resource/04-resource.html#pruebas-de-dos-colas-o-una-cola",
    "href": "resource/04-resource.html#pruebas-de-dos-colas-o-una-cola",
    "title": "Práctico 4. Inferencia Estadística y Curva Normal",
    "section": "Pruebas de dos colas o una cola",
    "text": "Pruebas de dos colas o una cola\nEn estadística, la formulación de hipótesis que implica dos variables (o la comparación de grupos) busca determinar si existen diferencias en una variable entre grupos y, de ser el caso, evaluar si esta diferencia es estadísticamente significativa.\nExisten los contrastes de hipótesis sobre diferencias entre grupos, también se les llama hipótesis de dos colas.\n\n\n\n\n\n\nPrueba de dos colas\n\n\n\nContrastamos la hipótesis nula (o de trabajo) de no diferencias entre grupos: \\[  H_{0}: \\mu_{1} - \\mu_{2} = 0 \\] En relación a una hipótesis alternativa sobre diferencias entre grupos: \\[  H_{A}: \\mu_{1} - \\mu_{2} \\neq 0 \\]\n\n\nSin embargo, también podemos plantear hipótesis respecto a que el valor de cierto parámetro para un grupo puede ser mayor o menor al de otro grupo. A esto se le conoce como hipótesis de una cola.\n\n\n\n\n\n\nPrueba de una cola\n\n\n\n\\[  H_{0}: \\mu_{0} ≥ \\mu_{1} ; \\mu_{0} ≤ \\mu_{1}\\]\n\\[  H_{A}: \\mu_{0} &gt; \\mu_{1} \\]\n\\[  H_{A}: \\mu_{0} &lt; \\mu_{1} \\]"
  },
  {
    "objectID": "resource/04-resource.html#cálculo-paso-a-paso-de-estadístico-t",
    "href": "resource/04-resource.html#cálculo-paso-a-paso-de-estadístico-t",
    "title": "Práctico 4. Inferencia Estadística y Curva Normal",
    "section": "Cálculo paso a paso de estadístico t",
    "text": "Cálculo paso a paso de estadístico t\nEn esta sección se realizará el cálculo paso a paso del estadístico \\(t\\) del ejemplo anterior para demostrar cómo se origina la información que aparece en el output de R.\nLa fórmula de t:\n\\(t=\\frac{(\\bar{x}_1-\\bar{x}_2)}{\\sqrt{\\frac{s_1²}{\\sqrt{n_1}}+\\frac{s_2²}{\\sqrt{n_2}} }}\\)\nDonde en la parte superior se encuentra la diferencia de medias entre dos grupos, y en la inferior el error estándar de t.\nPasos:\n\nSe calcula la diferencia de medias\nSe calcula el error estándar de la diferencia de medias\nCálculo del valor t\nSe fija un \\(\\alpha\\) (usualmente 0.05) para rechazar \\(H_0\\), y se busca el valor crítico asociado a este \\(\\alpha\\) (en una tabla de valores t, o en R)\nSi nuestro t es superior al valor crítico, se rechaza \\(H_0\\)\n\nPaso 1: Calculamos la diferencia de medias \\((\\bar{x}_1-\\bar{x}_2)\\)\n\nmuestra %&gt;%\n  dplyr::group_by(sexo=sjlabelled::as_label(sexo)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=mean(edad, na.rm=TRUE),SD=sd(edad, na.rm=TRUE)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(format = \"markdown\")\n\n\n\n\nsexo\nObs.\nPromedio\nSD\n\n\n\n\n1\n6\n32.33333\n1.505545\n\n\n2\n4\n25.25000\n2.629956\n\n\n\n\ndif_medias &lt;- 32.333 - 25.250\ndif_medias\n\n[1] 7.083\n\n\nPaso 2: Calculamos el error estándar de la diferencia de medias: \\(\\sqrt{\\frac{s_1²}{\\sqrt{n_1}}+\\frac{s_2²}{\\sqrt{n_2}}}\\)\n\nmuestra_h &lt;- muestra %&gt;% filter(sexo==1)\nmuestra_m &lt;- muestra %&gt;% filter(sexo==2)\n  \ns_h &lt;- sd(muestra_h$edad)\nn_h &lt;- length(muestra_h$edad)\ns_m &lt;- sd(muestra_m$edad)\nn_m &lt;- length(muestra_m$edad)\n\nee &lt;- sqrt((s_h^2)/n_h + (s_m^2)/n_m)\nee\n\n[1] 1.451532\n\n\nPaso 3: Cálculo del valor t\n\nte &lt;- dif_medias/ee\nte\n\n[1] 4.879673\n\n\nPaso 4: Fijamos un \\(\\alpha\\) y se busca el valor crítico de t asociado al \\(\\alpha\\). En este caso utilizaremos el valor usual de \\(\\alpha = 0.05\\).\n\ntt &lt;- qt(0.05/2,df=9,lower.tail=F)\ntt\n\n[1] 2.262157\n\n\nPaso 5: test de hipótesis\nSegún la distribución t, el valor crítico para poder rechazar \\(H_0\\) con un 95% de confianza es 2.26. El t calculado con información de la muestra (o t empírico) es 4.87. Este valor es superior al t crítico, por lo tanto se rechaza \\(H_0\\) con un 95% de confianza, o una probabilidad de error p&lt;0.05."
  },
  {
    "objectID": "resource/04-resource.html#ejemplo-casos-reales",
    "href": "resource/04-resource.html#ejemplo-casos-reales",
    "title": "Práctico 4. Inferencia Estadística y Curva Normal",
    "section": "Ejemplo casos reales",
    "text": "Ejemplo casos reales\nComencemos por preparar nuestros datos. Iniciamos cargando las librerías necesarias.\n\npacman::p_load(tidyverse, # Manipulacion datos\n               sjPlot, #tablas\n               confintr, # IC\n               gginference, # Visualizacion \n               rempsyc, # Reporte\n               broom) # Varios\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\nCargamos los datos directamente desde internet.\n\nload(url(\"https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/proc_casen.RData\")) #Cargar base de datos\n\nA continuación, exploramos la base de datos proc_casen.\n\nnames(proc_casen) # Nombre de columnas\n\n [1] \"id_vivienda\"      \"folio\"            \"id_persona\"       \"hogar\"           \n [5] \"nucleo\"           \"varunit\"          \"varstrat\"         \"expr\"            \n [9] \"edad\"             \"sexo\"             \"educ\"             \"activ\"           \n[13] \"y1\"               \"ytrabajocor\"      \"pobreza_multi_5d\" \"o15\"             \n[17] \"qaut\"             \"fdt\"              \"ocupado\"          \"desocupado\"      \n[21] \"inact\"            \"hijo\"             \"n_educ\"           \"universitaria\"   \n[25] \"tipo_ocup\"        \"ss_salud\"         \"ayuda_moverse\"    \"ayuda_thogar\"    \n[29] \"disc_fisica\"     \n\ndim(proc_casen) # Dimensiones\n\n[1] 202111     29\n\n\nContamos con 24 variables (columnas) y 202.111 observaciones (filas).\nEvaluemos si el promedio de ingresos del trabajo de las mujeres es distinto al de los hombres en Chile en el 2022.\nApliquemos nuestros cinco pasos para inferencia.\n\nFormulamos nuestras hipótesis y dirección de la prueba:\n\n\n\\(H_{0}\\): \\(\\mu_{hombres}\\) \\(-\\) \\(\\mu_{mujeres}\\) \\(=\\) \\(0\\)\n\\(H_{A}\\): \\(\\mu_{hombres}\\) \\(-\\) \\(\\mu_{mujeres}\\) \\(\\neq\\) \\(0\\)\n\n\nCalcula el error estándar (SE) para diferencia de medias:\n\n\nocupados &lt;- proc_casen %&gt;%\n  filter(ocupado == 1) %&gt;% \n  na.omit() #  subset de datos solo con personas ocupadas\n\ndatos_t &lt;- ocupados %&gt;% \n  group_by(sexo) %&gt;% \n  summarise(media = mean(ytrabajocor, na.rm = T),\n            ds = sd(ytrabajocor, na.rm = T),\n            n = n())\n\ndatos_t\n\n# A tibble: 2 × 4\n   sexo   media      ds     n\n  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n1     1 578107. 388352.    64\n2     2 516235. 405302.   109\n\n\nObtenemos la diferencia de medias (\\(\\bar{x_1}\\) - \\(\\bar{x_2}\\))\n\ndif_medias &lt;- 817688.2 - 674428.3\ndif_medias\n\n[1] 143259.9\n\n\nAhora, calculamos el error estándar.\n\ns_h &lt;- 837710.9 \ns_m &lt;- 638044.1\n\nn_h &lt;- 32019 \nn_m &lt;- 26313    \n\nse_dif &lt;- sqrt((s_h^2)/n_h + (s_m^2)/n_m)\nse_dif\n\n[1] 6114.607\n\n\n\nCalcula el valor estimado de la prueba (t para diferencia de medias):\n\n\nt_stat &lt;- dif_medias/se_dif\nt_stat\n\n[1] 23.42912\n\n\n\nEspecifica el valor crítico:\n\n\ndf &lt;- n_h + n_m - 2 # definimos grados de libertad\n\nt_critico &lt;- qt(p = 0.05/2, df, lower.tail = FALSE)\nt_critico\n\n[1] 1.960005\n\n\n\nContrasta el valor estimado con el crítico e interpreta los resultados:\n\n\nt_stat &gt; t_critico\n\n[1] TRUE\n\n\nComparamos el valor estimado con el valor crítico para dos colas. Por tanto, nuestro valor estimado queda dentro de la zona de rechazo de \\(H_0\\). En consecuencia, podemos decir que:\n\nLa prueba T que evalúa la diferencia de medias entre el ingreso del trabajo según sexo sugiere que el efecto es positivo y estadísticamente signficativo (diferencia = 143.260, t(58004.33) = 23.43, p &lt; .001). Por tanto, rechazamos la \\(H_{0}\\) sobre igualdad de medias con un 95% de confianza, existiendo evidencia a favor de nuestra \\(H_{A}\\) ya que hay diferencias salariales significativas entre hombres y mujeres.\n\n\nY el cálculo directo en R:\n\n\nt_results &lt;- t.test(ocupados$ytrabajocor ~ ocupados$sexo, \n       alternative = \"two.sided\")\n\n# stats.table &lt;- tidy(t_results, conf_int = T)\n# nice_table(stats.table, broom = \"t.test\")\n\nVisualicemos la distribución de esta prueba y su zona de rechazo.\n\nggttest(t_results)\n\n\n\n\nAdemás, podemos calcular un intervalo de confianza que acompaña nuestra estimación. En este caso, vemos que el IC para la diferencia de medias oscila entre [131.275 - 155.245] y no contiene el cero, por lo que podemos rechazar la hipótesis nula."
  },
  {
    "objectID": "resource/02-resource.html",
    "href": "resource/02-resource.html",
    "title": "Práctico 2. Matrices de correlación y tamaños de efecto",
    "section": "",
    "text": "El objetivo de esta guía práctica es conocer maneras de reportar coeficientes de correlación y cómo interpretar sus tamaños de efecto en ciencias sociales. Además, nos introduciremos en el tratamiento de valores perdidos y otras medidas de correlación entre variables.\nEn detalle, aprenderemos:\n\nCómo reportar y presentar matrices de correlación.\nInterpretar el tamaño de efecto de una correlación.\nTratamiento de casos perdidos.\nQué es y cómo calcular la correlación de Spearman.\nQué es el coeficiente de determinación \\(R^2\\).\n\n\n\n\n\n\n\nNota\n\n\n\n¿Qué era la correlación?\nLa correlación es una medida de asociación entre variables, que describe el sentido (dirección) y fuerza de la asociación.\nEn otras palabras, nos permite conocer cómo y cuánto se relaciona la variación de una variable, con la variación de otra variable.\n\n\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados del Estudio Longitudinal Social de Chile (ELSOC) del año 2016, elaborado por COES. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  ELSOC 2016. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos ELSOC 2016."
  },
  {
    "objectID": "resource/02-resource.html#recursos-de-la-práctica",
    "href": "resource/02-resource.html#recursos-de-la-práctica",
    "title": "Práctico 2. Matrices de correlación y tamaños de efecto",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados del Estudio Longitudinal Social de Chile (ELSOC) del año 2016, elaborado por COES. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  ELSOC 2016. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos ELSOC 2016."
  },
  {
    "objectID": "resource/02-resource.html#tratamiento-de-casos-perdidos",
    "href": "resource/02-resource.html#tratamiento-de-casos-perdidos",
    "title": "Práctico 2. Matrices de correlación y tamaños de efecto",
    "section": "Tratamiento de casos perdidos",
    "text": "Tratamiento de casos perdidos\nTrabajar con datos a menudo implica enfrentar valores perdidos (NA), lo que puede ser un gran desafío. Estos valores indican la ausencia de un valor en una base de datos. Los valores perdidos pueden originarse por diversas razones, como el sesgo de no respuesta en encuestas, errores en la entrada de datos o simplemente la falta de información para ciertas variables.\n\n\n\n\n\n\nX1\nX2\nX3\nX4\n\n\n\n\nNA\n4\n1\nHola\n\n\n7\n1\n4\nNo soy un NA\n\n\n8\nNA\n2\nNA\n\n\n9\nNA\n9\nAmo R\n\n\n3\n3\n6\nNA\n\n\n\n\n\n\n\n\nLa presencia de valores perdidos puede tener un impacto considerable en la precisión y confiabilidad de los análisis estadísticos, lo que a su vez puede conducir a resultados sesgados y conclusiones incorrectas.\nExisten varias formas de tratar valores perdidos, que van desde enfoques simples hasta métodos más complejos, como la imputación. En esta ocasión, nos centraremos en las dos estrategias más comunes:\n\ntrabajar exclusivamente con casos completos (listwise) o\nretener los casos con valores perdidos, pero excluyéndolos al calcular estadísticas (pairwise).\n\n\na) Analísis con casos completos: listwise deletion\nEste enfoque es uno de los más conocidos: implica remover completamente las observaciones que tienen valores perdidos en cualquier variable de interés. En otras palabras, si una fila/caso en un conjunto de datos tiene al menos un valor faltante en alguna de las variables que estás considerando, se eliminará por completo.\nEn R, esto podemos hacerlo con la función na.omit. Para hacer esto, sigamos estos pasos:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos)-\ncontamos el número de casos con el comando dim.\ncontamos cuántos y en dónde tenemos casos perdidos.\nborramos los casos perdidos con na.omit.\ncontamos nuevamente con dim para asegurarnos que se borraron.\n\n\nproc_elsoc_original &lt;- proc_elsoc\ndim(proc_elsoc)\n\n[1] 2927    7\n\n\n\nsum(is.na(proc_elsoc))\n\n[1] 81\n\n\n\ncolSums(is.na(proc_elsoc))\n\nmesfuerzo  mtalento       ess    edcine      sexo      edad    pmerit \n       18        20        12         2         0         0        29 \n\n\n\nproc_elsoc &lt;- na.omit(proc_elsoc)\ndim(proc_elsoc)\n\n[1] 2887    7\n\n\nAhora nos quedamos con 2887 observaciones sin casos perdidos.\nAunque es simple de implementar, con este enfoque podemos perder información importante, especialmente si los valores perdidos no se distribuyen aleatoriamente.\n\nSiempre hay que intentar rescatar la mayor cantidad de casos posibles. Por lo tanto, si un listwise genera más de un 10% de casos perdidos se debe detectar qué variables esta produciendo esta pérdida e intentar recuperar datos. Puedes revisar un ejemplo aquí.\n\n\n\nb) Retener pero excluir: pairwise deletion\nA diferencia del anterior, este es un enfoque en el que las observaciones se utilizan para el análisis siempre que tengan datos disponibles para las variables específicas que se están analizando. En lugar de eliminar toda una fila si falta un valor, se eliminan solo los valores faltantes en las variables que se están analizando en ese momento.\nPara hacer esto en R debemos siempre verificar e indicar en nuestro código si queremos (o no) remover los NA para realizar los análisis.\n\nmean(proc_elsoc_original$pmerit); mean(proc_elsoc$edad); mean(proc_elsoc$ess)\n\n[1] NA\n\n\n[1] 45.98337\n\n\n[1] 4.333564\n\nmean(proc_elsoc_original$pmerit, na.rm = TRUE); mean(proc_elsoc$edad, na.rm = TRUE); mean(proc_elsoc$ess, na.rm = TRUE)\n\n[1] 2.653899\n\n\n[1] 45.98337\n\n\n[1] 4.333564\n\n\nCon el primer código no obtuvimos información sustantiva en ciertas variables, pero con el segundo sí al remover los NA solo de dicha variable para un cálculo determinado."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Metodología Cuantitativa Avanzada\n        ",
    "section": "",
    "text": "Metodología Cuantitativa Avanzada\n        \n        \n            Magister en Ciencias Sociales, mención Sociología de la Modernización\n        \n        \n            MCS7171-1 • Primer Semestre 2025Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n        \n    \n\n\n\n\n\nProfesores\n\n\n\n\n   Daniela Olivares Collío\n   FACSO - sala 328\n   danielaolivarescollio@gmail.com\n   \n\n\n\n\n\n\n   Kevin Carrasco Quintanilla\n   FACSO - sala 328\n   kevin.carrasco@ug.uchile.cl\n   kevincarrascoq1\n\n\n\nInformación del curso\n\n   Viernes\n   Marzo – Julio, 2025\n   09:00-11:30 hrs.\n   Sala 334, FACSO \n\n\n\n\nContacto\nA través de correo o U-Cursos\n\n\nVersiones anteriores del curso\n\n2024"
  },
  {
    "objectID": "content/11-content.html#lecturas",
    "href": "content/11-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/09-content.html#lecturas",
    "href": "content/09-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/07-content.html#lecturas",
    "href": "content/07-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nBrown (2015)The Common Factor Model and Exploratory Factor Analysis"
  },
  {
    "objectID": "content/05-content.html#lecturas",
    "href": "content/05-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Clase 01",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Prácticos",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.3.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto (o en blanco):\n\n\n\n\n\n\n\n\nNota\n\n\n\nAlternativa a lo anterior: https://posit.cloud/\n\nVersión online de Rstudio\nUtilizar en caso de problemas con PC"
  },
  {
    "objectID": "assignment/index.html#r-y-rstudio",
    "href": "assignment/index.html#r-y-rstudio",
    "title": "Prácticos",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.3.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto (o en blanco):\n\n\n\n\n\n\n\n\nNota\n\n\n\nAlternativa a lo anterior: https://posit.cloud/\n\nVersión online de Rstudio\nUtilizar en caso de problemas con PC"
  },
  {
    "objectID": "assignment/01-practico.html",
    "href": "assignment/01-practico.html",
    "title": "Práctico 01. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso."
  },
  {
    "objectID": "assignment/01-practico.html#objetivos-de-la-práctica",
    "href": "assignment/01-practico.html#objetivos-de-la-práctica",
    "title": "Práctico 01. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso."
  },
  {
    "objectID": "assignment/01-practico.html#r-y-rstudio",
    "href": "assignment/01-practico.html#r-y-rstudio",
    "title": "Práctico 01. Aproximación inicial a R",
    "section": "R y Rstudio",
    "text": "R y Rstudio\n\nGuía de instalación\n\nAcceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2 \n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())"
  },
  {
    "objectID": "assignment/01-practico.html#primeros-pasos",
    "href": "assignment/01-practico.html#primeros-pasos",
    "title": "Práctico 01. Aproximación inicial a R",
    "section": "Primeros pasos",
    "text": "Primeros pasos\nEn primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n0. Ejemplos\nR puede ser una calculadora\n\n10 + 5 # ¿cuánto es 10 + 5?\n\n[1] 15\n\n\n\n10 * 5 # ¿cuánto es 10 * 5?\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\na &lt;- 28\nb &lt;- 8\n\na + b\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\nc &lt;- a + b\n\nAsí como también agregar texto\n\nd &lt;- \"hola\"\n\nd\n\n[1] \"hola\"\n\n\ny operaciones un poco más complejas\n\ne &lt;- b^2\n\ne + a * c\n\n[1] 1072\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\nsum(28,8)\n\n[1] 36\n\n\n\nround(10.14536) #aproximar\n\n[1] 10"
  },
  {
    "objectID": "assignment/01-practico.html#flujo-de-trabajo-en-r",
    "href": "assignment/01-practico.html#flujo-de-trabajo-en-r",
    "title": "Práctico 01. Aproximación inicial a R",
    "section": "2. Flujo de trabajo en R",
    "text": "2. Flujo de trabajo en R\nTal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\n\n\nRproject\nUn Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n1. Librerías principales (de R) a utilizar\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, guaguas, ggplot2)\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\nbase &lt;- guaguas\n\nConocemos las dimensiones de la base de datos\n\ndim(base)\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\nnames(base)\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\nhead(base)\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\ntable(base$sexo)\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\nfilter(base, nombre==\"Kevin\")\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n[1] 1312\n\n\nAvanzando un poco más, podemos utilizar ggplot2 para hacer un gráfico de líneas que muestre la evolución en el tiempo\n\ndatos &lt;- filter(base, nombre==\"Kevin\")\nggplot(datos, aes(x = anio, y = n)) +\n  geom_line() + \n  labs(x = \"Año\", y = \"Número de personas\", title = \"Número de personas llamadas Kevin por año\")\n\n\n\n\n¿Qué puede explicar el peak de “Kevins” previo a los 2000?\nspoiler: link"
  },
  {
    "objectID": "assignment/01-practico.html#otro-ejemplo",
    "href": "assignment/01-practico.html#otro-ejemplo",
    "title": "Práctico 01. Aproximación inicial a R",
    "section": "Otro ejemplo",
    "text": "Otro ejemplo\n\nguaguas %&gt;% \n  filter(nombre %in% c(\"Salvador\", \"Augusto\"), anio &gt;= 1960 & anio &lt;= 1979) %&gt;% \n  ggplot(aes(anio, n, color = nombre)) + \n  geom_line() +\n  labs(x = \"año\", y = \"total inscripciones\", color = \"nombre\", \n       title = \"Inscripciones de 'Salvador' y 'Augusto' entre 1960 - 1979\")"
  },
  {
    "objectID": "assignment/02-practico.html",
    "href": "assignment/02-practico.html",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en los procedimientos básicos del uso del lenguaje y ambiente R.\nEn detalle, aprenderemos:\n\nHerramientas básicas de programación en R\nOperadores en R\nTipos de datos\n\n\n\n\nTal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\nLleva este nombre por el sistema de carpetas que se implementan: Input, Procesamiento y Output. En la carpeta Input guardaremos todos aquellso recursos iniciales que usaremos, como las bases de datos, el libro de códigos, entre otros. En la carpeta de Procesamiento, como dice el nombre, guardaremos todos los archivos que procesen y analicen datos. En la carpeta Output guardaremos todo aquello que hayamos producido en los archivos de procesamiento, como las bases de datos procesadas listas para compartir o publicas, los documentos de reporte, informes o analísis, gráficos o tablas.\n\n\n\n\n\n\n\n\n\nLa implementación de la reproducibilidad en este tipo de protocolos se basa en generar un conjunto de archivos auto-contenidos organizado en una estructura de proyecto que cualquier persona pueda compartir y ejecutar. En otras palabras, debe tener todo lo que necesita para ejecutar y volver a ejecutar el análisis. Para conocer más, visita el Laboratorio de Ciencia Abierta.\n\n\n\n\n\n\n\n\n\n\n\n\nUn Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto\n\n\n\n\nRevisemos algunos conocimientos básicos para la programación en R. Pero antes, tengamos dos cosas en mente:\n\nPrimero, ¿qué es codificar?, en programación codificar corresponde a un proceso de entrega de instrucciones en un lenguaje específico, siguiendo un orden lógico y coherente.\nSegundo, de aquí en adelante nos manejaremos con una máxima en el curso; existe un acuerdo implícito entre tú y R: R hará todos los cálculos por ti, pero en cambio tú debes dar las instrucciones con total precisión.\n\n\n\nUno de los usos más sencillos y que están a la base de R, es usarlo como una calculadora.\n\n5+5\n\n[1] 10\n\n25/5\n\n[1] 5\n\n2*2\n\n[1] 4\n\n27-2\n\n[1] 25\n\n\nComo podrás ver, el resultado de estas instrucciones aparecen como un [1] en la consola. También podemos hacer operatorias más complejas y con más cálculos.\n\n12*(7+2)+(45-32)+8\n\n[1] 129\n\n22^2 - 2^2\n\n[1] 480\n\n1/200 * 30\n\n[1] 0.15\n\n\n\n\n\nR es un lenguaje de programación orientado a objetos. ¿Qué significa eso?, implica que podemos crear elementos dentro del ambiente de R, a los cuales les asignaremos información que quedará almacenada, información que puede ir desde números, palabras, cálculos hasta grandes bases de datos.\nTodas las instrucciones en R en las que crees objetos, es decir, instrucciones de asignación, tendrán la misma estructura:\nnombre_objeto &lt;- valor\nEl asignador &lt;- se utiliza para crear objetos y forma parte de uno de los operadores usados en R.\nLos elementos que podemos asignar a objetos son múltiples, como números, palabras acompañadas siempre de corchetes \" \" y vectores que corresponden a un conjunto o secuencia de elementos del mismo tipo definidos por la funcion de concatenar = c().\nVeamos un ejemplo creando objetos:\n\nx &lt;- 4 # asignar\n\nx # ejecutar\n\n[1] 4\n\ny &lt;- \"Hola mundo\" # los carácteres alfabéticos siempre van acompañados de corchetes\n\ny \n\n[1] \"Hola mundo\"\n\n\nHagamos un pequeño reto: ¿Cuál es el valor de a y b? Si a &lt;- 5; b &lt;- a; a &lt;- 4\n\na &lt;- 5\nb &lt;- a\na &lt;- 4\n\nprint(a) # imprimir en la consola\n\n[1] 4\n\nprint(b)\n\n[1] 5\n\na + 10\n\n[1] 14\n\n\nAhora, sea z = a^2 ¿qué resultado obtenemos de a * b + z?\n\nz &lt;- a^2 # asignar\n\na * b + z\n\n[1] 36\n\n\n¿Y concatenando? Hacemos un vector.\n\nedad &lt;- c(18,22,36,19,35) # concatenar (variable de razon)\n\nedad\n\n[1] 18 22 36 19 35\n\ngenero &lt;- c(3,1,1,2,3) # masculino = 1; femenino = 2; transgenero = 3 (variable nominal)\n\ngenero \n\n[1] 3 1 1 2 3\n\ngse &lt;- c(\"ABC1\", \"C2\", \"E\", \"AbC1\", \"E\")  # tambíen se pueden usar carácteres (variable ordinal)\n\ngse\n\n[1] \"ABC1\" \"C2\"   \"E\"    \"AbC1\" \"E\"   \n\n\nAdemás de lo anterior, en R es fundamental la creación de data.frames. Un Data.frame es una estructura de datos de dos dimensiones (columnas y filas), donde las columnas pueden ser de diferente naturaleza, pero deben tener el mismo largo. A partir de ella agrupamos variables en una matriz, o sea, construimos una base de datos. Es como “pegar” las columnas (variables) una al lado de otra.\nCreemos un data.frame con los vectores que ya creamos antes.\n\nbase1 &lt;- data.frame(genero, gse, edad) # Resulta como objeto de \"datos\" en\n                                       # entorno.\n\nbase1\n\n  genero  gse edad\n1      3 ABC1   18\n2      1   C2   22\n3      1    E   36\n4      2 AbC1   19\n5      3    E   35\n\n\nComo puedes ver, para crear el data.frame usamos la función que lleva el mismo nombre, colocando dentro del paréntesis los vectores que creamos anteriormente: data.frame(mis_vectores).\nAhora, creemos un data.frame desce cero. En este ejemplo, crearemos los vectores dentro de la función data.frame().\n\n# Ejemplo de como crear un data.frame desde 0: \n\nbase2 &lt;- data.frame(Sexo=c(\"H\",\"M\",\"H\",\"M\",\"H\",\"M\"),\n                    Estatura=c(1.83,1.76,1.82,1.60,1.90,1.66),\n                    Peso=c(67,58,66,48,75,55))\n\nhead(base2)  # Me permite visualizar las primeras filas\n\n  Sexo Estatura Peso\n1    H     1.83   67\n2    M     1.76   58\n3    H     1.82   66\n4    M     1.60   48\n5    H     1.90   75\n6    M     1.66   55\n\n\n\n\n\n\nAntes de trabajar con datos, debemos conocer el concepto de operadores. Estos símbolos no son de uso exclusivo en R, pero no todos tienen el mismo significado que en otros softwares.\nLos operadores son símbolos que permiten, en los distintos procedimientos de procesamiento, simplificar procesos. Por ejemplo, serán útilizados cuando filtremos nuestros datos para personas de ciertas categorías, cuando calculemos variables nuevas (de manera aritmética o condicional) o, simplemente, cuando queramos hacer procesos “concatenados”.\n\nVeamos algunos ejemplos:\n\n20 == 5 # igualdad\n\n[1] FALSE\n\n30 &gt;= 14 # mayor o igual que\n\n[1] TRUE\n\n22 &lt;= 2 # menor o igual que\n\n[1] FALSE\n\n25 != 10 # no es igual a\n\n[1] TRUE\n\np = 10; y = 5; p &lt;= y # operatoria en objetos\n\n[1] FALSE\n\n\n\n\n\n\n\nEn R, al igual que en la mayoría de lenguajes de programación, contamos con datos de diversos tipos, en razón de los cuales podemos realizar determinados procedimientos de tratamiento o análisis.\nLos tipos de datos están íntimamente relacionados con el nivel de medición de las variables a las que corresponden. Como viste en clases, la teoría de los niveles de medición contempla cuatro tipos:\n\n\n\n\nPara responder esta pregunta, exploremos algunos datos. En esta oportunidad trabajaremos con el Estudio Longitudinal Social de Chile, que es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena, basándose en modelos conceptuales descritos en la literatura nacional e internacional que abordan dichas materias. Se orienta a examinar los principales antecedentes, factores moderadores y mediadores, así como las principales consecuencias asociadas al desarrollo de distintas formas de conflicto y cohesión social en Chile. Su objetivo fundamental es constituirse en un insumo empírico para la comprensión de las creencias, actitudes y percepciones de los chilenos hacia las distintas dimensiones de la convivencia y el conflicto, y como éstas cambian a lo largo del tiempo.\n\n\n\n\nEn R es es posible importar y exportar datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo, lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en la página oficial de ELSOC en este enlace.\nLuego de descargar la base de datos, asegurate de dejar el archivo .sav en la carpeta input/data de tu proyecto. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con load(), crearemos un objeto que contiene la base de datos. Fijate en el Enviroment, ya que si lo anterior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\nSin embargo, por esta vez podemos descargar la base desde internet\n\nload(url((\"https://github.com/cursos-metodos-facso/metod1-MCS/raw/main/resource/files/ELSOC_W05_v1.0_R.RData\"))\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos\n\n\n\n\n\nNo siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos.\n\nreadxl para archivos .xlsx\nhaven para archivos .sav\nreadr para .csv\n\n\n\n\n\nLo más probable es que no trabajemos con todos los datos que importamos, por lo que debemos seleccionar aquellas variables con las que trabajaremos para nuestro problema de investigación (cualquiera sea).\nPero, para ello primero debemos explorar nuestros datos. En R, las funciones más comunes para explorar datos son:\n\nView(elsoc_2021) # Ver datos\nnames(elsoc_2021) # Nombre de columnas\ndim(elsoc_2021) # Dimensiones\n\nTenemos una base de datos con 2740 casos o filas y con 311 variables o columnas.\n\n\n\nEn R se trabaja a partir de paquetes (packages). ¿Qué son? De forma resumida, los paquetes son un conjunto de funciones o herramientas que pueden ser usadas en R. Los directorios de R donde se almacenan los paquetes se denominan librerías. La lógica es instalar paquetes y luego cargar (o llamar) las librerías cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura (instalación y carga) de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\n\n\npacman::p_load(dplyr, # para manipular datos\n               car # para recodificar datos\n               )\n\nComo se puede ver, antes de la función p_load hay un ::, esto se refiere a que se “fuerza” que esa función provenga de ese paquete (en este caso del paquete pacman).\n\n\n\n\n\nLos datos character están directamente asociados a las variables cualitativas (o categóricas). Generalmente suelen ser variables de texto abierto, como es el caso de la variable pais, que detalla el país de procedencia de la persona encuestada.\nPara conocer cuál es el tipo de variable en R, utilizamos el comando class(), y para detallar dentro de la base de datos cuál es la variable de interés, utilizamos el símbolo $ posterior a la base de datos:\n\nclass(elsoc_2021$comuna) # siempre es la misma estructura = base$variable\n\n[1] \"character\"\n\n\nSin embargo, estas variables no tienden a ser las mejores a la hora de presentar nuestros resultados. Como solución, tenemos las variables de tipo Factor.\n\n\n\nLas variables de tipo factor son ideales para trabajar con variables de tipo nominal u ordinal. Esto es así debido a que permiten establecer un orden entre las categorías de la variable, lo cual es fundamental si trabajamos, por ejemplo, con variables nominales como el sexo de los encuestados, o si trabajamos con variables ordinales como su ideología política.\n\nclass(elsoc_2021$m0_sexo)\n\n[1] \"factor\"\n\nclass(elsoc_2021$m38) #religion\n\n[1] \"factor\"\n\n\n\n\n\nLas variables de tipo numeric son variables de tipo númerica, las cuales pueden ser intervales o de razón. Así, por ejemplo, cuando trabajamos con variables de razón trabajamos con variables como el número de hijos o la edad (aunque sería extraño encuestar a alguien con 0 años).\n\nclass(elsoc_2021$m0_edad)\n\n[1] \"numeric\""
  },
  {
    "objectID": "assignment/02-practico.html#objetivo-de-la-práctica",
    "href": "assignment/02-practico.html#objetivo-de-la-práctica",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en los procedimientos básicos del uso del lenguaje y ambiente R.\nEn detalle, aprenderemos:\n\nHerramientas básicas de programación en R\nOperadores en R\nTipos de datos"
  },
  {
    "objectID": "assignment/02-practico.html#flujo-de-trabajo-en-r",
    "href": "assignment/02-practico.html#flujo-de-trabajo-en-r",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Tal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\nLleva este nombre por el sistema de carpetas que se implementan: Input, Procesamiento y Output. En la carpeta Input guardaremos todos aquellso recursos iniciales que usaremos, como las bases de datos, el libro de códigos, entre otros. En la carpeta de Procesamiento, como dice el nombre, guardaremos todos los archivos que procesen y analicen datos. En la carpeta Output guardaremos todo aquello que hayamos producido en los archivos de procesamiento, como las bases de datos procesadas listas para compartir o publicas, los documentos de reporte, informes o analísis, gráficos o tablas.\n\n\n\n\n\n\n\n\n\nLa implementación de la reproducibilidad en este tipo de protocolos se basa en generar un conjunto de archivos auto-contenidos organizado en una estructura de proyecto que cualquier persona pueda compartir y ejecutar. En otras palabras, debe tener todo lo que necesita para ejecutar y volver a ejecutar el análisis. Para conocer más, visita el Laboratorio de Ciencia Abierta."
  },
  {
    "objectID": "assignment/02-practico.html#rproject",
    "href": "assignment/02-practico.html#rproject",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Un Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto"
  },
  {
    "objectID": "assignment/02-practico.html#conocimientos-básicos-de-programación",
    "href": "assignment/02-practico.html#conocimientos-básicos-de-programación",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Revisemos algunos conocimientos básicos para la programación en R. Pero antes, tengamos dos cosas en mente:\n\nPrimero, ¿qué es codificar?, en programación codificar corresponde a un proceso de entrega de instrucciones en un lenguaje específico, siguiendo un orden lógico y coherente.\nSegundo, de aquí en adelante nos manejaremos con una máxima en el curso; existe un acuerdo implícito entre tú y R: R hará todos los cálculos por ti, pero en cambio tú debes dar las instrucciones con total precisión.\n\n\n\nUno de los usos más sencillos y que están a la base de R, es usarlo como una calculadora.\n\n5+5\n\n[1] 10\n\n25/5\n\n[1] 5\n\n2*2\n\n[1] 4\n\n27-2\n\n[1] 25\n\n\nComo podrás ver, el resultado de estas instrucciones aparecen como un [1] en la consola. También podemos hacer operatorias más complejas y con más cálculos.\n\n12*(7+2)+(45-32)+8\n\n[1] 129\n\n22^2 - 2^2\n\n[1] 480\n\n1/200 * 30\n\n[1] 0.15\n\n\n\n\n\nR es un lenguaje de programación orientado a objetos. ¿Qué significa eso?, implica que podemos crear elementos dentro del ambiente de R, a los cuales les asignaremos información que quedará almacenada, información que puede ir desde números, palabras, cálculos hasta grandes bases de datos.\nTodas las instrucciones en R en las que crees objetos, es decir, instrucciones de asignación, tendrán la misma estructura:\nnombre_objeto &lt;- valor\nEl asignador &lt;- se utiliza para crear objetos y forma parte de uno de los operadores usados en R.\nLos elementos que podemos asignar a objetos son múltiples, como números, palabras acompañadas siempre de corchetes \" \" y vectores que corresponden a un conjunto o secuencia de elementos del mismo tipo definidos por la funcion de concatenar = c().\nVeamos un ejemplo creando objetos:\n\nx &lt;- 4 # asignar\n\nx # ejecutar\n\n[1] 4\n\ny &lt;- \"Hola mundo\" # los carácteres alfabéticos siempre van acompañados de corchetes\n\ny \n\n[1] \"Hola mundo\"\n\n\nHagamos un pequeño reto: ¿Cuál es el valor de a y b? Si a &lt;- 5; b &lt;- a; a &lt;- 4\n\na &lt;- 5\nb &lt;- a\na &lt;- 4\n\nprint(a) # imprimir en la consola\n\n[1] 4\n\nprint(b)\n\n[1] 5\n\na + 10\n\n[1] 14\n\n\nAhora, sea z = a^2 ¿qué resultado obtenemos de a * b + z?\n\nz &lt;- a^2 # asignar\n\na * b + z\n\n[1] 36\n\n\n¿Y concatenando? Hacemos un vector.\n\nedad &lt;- c(18,22,36,19,35) # concatenar (variable de razon)\n\nedad\n\n[1] 18 22 36 19 35\n\ngenero &lt;- c(3,1,1,2,3) # masculino = 1; femenino = 2; transgenero = 3 (variable nominal)\n\ngenero \n\n[1] 3 1 1 2 3\n\ngse &lt;- c(\"ABC1\", \"C2\", \"E\", \"AbC1\", \"E\")  # tambíen se pueden usar carácteres (variable ordinal)\n\ngse\n\n[1] \"ABC1\" \"C2\"   \"E\"    \"AbC1\" \"E\"   \n\n\nAdemás de lo anterior, en R es fundamental la creación de data.frames. Un Data.frame es una estructura de datos de dos dimensiones (columnas y filas), donde las columnas pueden ser de diferente naturaleza, pero deben tener el mismo largo. A partir de ella agrupamos variables en una matriz, o sea, construimos una base de datos. Es como “pegar” las columnas (variables) una al lado de otra.\nCreemos un data.frame con los vectores que ya creamos antes.\n\nbase1 &lt;- data.frame(genero, gse, edad) # Resulta como objeto de \"datos\" en\n                                       # entorno.\n\nbase1\n\n  genero  gse edad\n1      3 ABC1   18\n2      1   C2   22\n3      1    E   36\n4      2 AbC1   19\n5      3    E   35\n\n\nComo puedes ver, para crear el data.frame usamos la función que lleva el mismo nombre, colocando dentro del paréntesis los vectores que creamos anteriormente: data.frame(mis_vectores).\nAhora, creemos un data.frame desce cero. En este ejemplo, crearemos los vectores dentro de la función data.frame().\n\n# Ejemplo de como crear un data.frame desde 0: \n\nbase2 &lt;- data.frame(Sexo=c(\"H\",\"M\",\"H\",\"M\",\"H\",\"M\"),\n                    Estatura=c(1.83,1.76,1.82,1.60,1.90,1.66),\n                    Peso=c(67,58,66,48,75,55))\n\nhead(base2)  # Me permite visualizar las primeras filas\n\n  Sexo Estatura Peso\n1    H     1.83   67\n2    M     1.76   58\n3    H     1.82   66\n4    M     1.60   48\n5    H     1.90   75\n6    M     1.66   55"
  },
  {
    "objectID": "assignment/02-practico.html#operadores-en-r",
    "href": "assignment/02-practico.html#operadores-en-r",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Antes de trabajar con datos, debemos conocer el concepto de operadores. Estos símbolos no son de uso exclusivo en R, pero no todos tienen el mismo significado que en otros softwares.\nLos operadores son símbolos que permiten, en los distintos procedimientos de procesamiento, simplificar procesos. Por ejemplo, serán útilizados cuando filtremos nuestros datos para personas de ciertas categorías, cuando calculemos variables nuevas (de manera aritmética o condicional) o, simplemente, cuando queramos hacer procesos “concatenados”.\n\nVeamos algunos ejemplos:\n\n20 == 5 # igualdad\n\n[1] FALSE\n\n30 &gt;= 14 # mayor o igual que\n\n[1] TRUE\n\n22 &lt;= 2 # menor o igual que\n\n[1] FALSE\n\n25 != 10 # no es igual a\n\n[1] TRUE\n\np = 10; y = 5; p &lt;= y # operatoria en objetos\n\n[1] FALSE"
  },
  {
    "objectID": "assignment/02-practico.html#tipos-de-datos",
    "href": "assignment/02-practico.html#tipos-de-datos",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "En R, al igual que en la mayoría de lenguajes de programación, contamos con datos de diversos tipos, en razón de los cuales podemos realizar determinados procedimientos de tratamiento o análisis.\nLos tipos de datos están íntimamente relacionados con el nivel de medición de las variables a las que corresponden. Como viste en clases, la teoría de los niveles de medición contempla cuatro tipos:\n\n\n\n\nPara responder esta pregunta, exploremos algunos datos. En esta oportunidad trabajaremos con el Estudio Longitudinal Social de Chile, que es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena, basándose en modelos conceptuales descritos en la literatura nacional e internacional que abordan dichas materias. Se orienta a examinar los principales antecedentes, factores moderadores y mediadores, así como las principales consecuencias asociadas al desarrollo de distintas formas de conflicto y cohesión social en Chile. Su objetivo fundamental es constituirse en un insumo empírico para la comprensión de las creencias, actitudes y percepciones de los chilenos hacia las distintas dimensiones de la convivencia y el conflicto, y como éstas cambian a lo largo del tiempo."
  },
  {
    "objectID": "assignment/02-practico.html#importar-datos",
    "href": "assignment/02-practico.html#importar-datos",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "En R es es posible importar y exportar datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo, lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en la página oficial de ELSOC en este enlace.\nLuego de descargar la base de datos, asegurate de dejar el archivo .sav en la carpeta input/data de tu proyecto. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con load(), crearemos un objeto que contiene la base de datos. Fijate en el Enviroment, ya que si lo anterior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\nSin embargo, por esta vez podemos descargar la base desde internet\n\nload(url((\"https://github.com/cursos-metodos-facso/metod1-MCS/raw/main/resource/files/ELSOC_W05_v1.0_R.RData\"))\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos\n\n\n\n\n\nNo siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos.\n\nreadxl para archivos .xlsx\nhaven para archivos .sav\nreadr para .csv"
  },
  {
    "objectID": "assignment/02-practico.html#explorar-datos",
    "href": "assignment/02-practico.html#explorar-datos",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Lo más probable es que no trabajemos con todos los datos que importamos, por lo que debemos seleccionar aquellas variables con las que trabajaremos para nuestro problema de investigación (cualquiera sea).\nPero, para ello primero debemos explorar nuestros datos. En R, las funciones más comunes para explorar datos son:\n\nView(elsoc_2021) # Ver datos\nnames(elsoc_2021) # Nombre de columnas\ndim(elsoc_2021) # Dimensiones\n\nTenemos una base de datos con 2740 casos o filas y con 311 variables o columnas."
  },
  {
    "objectID": "assignment/02-practico.html#cargar-librerías",
    "href": "assignment/02-practico.html#cargar-librerías",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "En R se trabaja a partir de paquetes (packages). ¿Qué son? De forma resumida, los paquetes son un conjunto de funciones o herramientas que pueden ser usadas en R. Los directorios de R donde se almacenan los paquetes se denominan librerías. La lógica es instalar paquetes y luego cargar (o llamar) las librerías cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura (instalación y carga) de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\n\n\npacman::p_load(dplyr, # para manipular datos\n               car # para recodificar datos\n               )\n\nComo se puede ver, antes de la función p_load hay un ::, esto se refiere a que se “fuerza” que esa función provenga de ese paquete (en este caso del paquete pacman)."
  },
  {
    "objectID": "assignment/02-practico.html#tipos-de-datos-1",
    "href": "assignment/02-practico.html#tipos-de-datos-1",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Los datos character están directamente asociados a las variables cualitativas (o categóricas). Generalmente suelen ser variables de texto abierto, como es el caso de la variable pais, que detalla el país de procedencia de la persona encuestada.\nPara conocer cuál es el tipo de variable en R, utilizamos el comando class(), y para detallar dentro de la base de datos cuál es la variable de interés, utilizamos el símbolo $ posterior a la base de datos:\n\nclass(elsoc_2021$comuna) # siempre es la misma estructura = base$variable\n\n[1] \"character\"\n\n\nSin embargo, estas variables no tienden a ser las mejores a la hora de presentar nuestros resultados. Como solución, tenemos las variables de tipo Factor.\n\n\n\nLas variables de tipo factor son ideales para trabajar con variables de tipo nominal u ordinal. Esto es así debido a que permiten establecer un orden entre las categorías de la variable, lo cual es fundamental si trabajamos, por ejemplo, con variables nominales como el sexo de los encuestados, o si trabajamos con variables ordinales como su ideología política.\n\nclass(elsoc_2021$m0_sexo)\n\n[1] \"factor\"\n\nclass(elsoc_2021$m38) #religion\n\n[1] \"factor\"\n\n\n\n\n\nLas variables de tipo numeric son variables de tipo númerica, las cuales pueden ser intervales o de razón. Así, por ejemplo, cuando trabajamos con variables de razón trabajamos con variables como el número de hijos o la edad (aunque sería extraño encuestar a alguien con 0 años).\n\nclass(elsoc_2021$m0_edad)\n\n[1] \"numeric\""
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "",
    "text": "Crear cuenta en www.github.com\nDescargar Github Desktop"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#prerequisitos",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#prerequisitos",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "",
    "text": "Crear cuenta en www.github.com\nDescargar Github Desktop"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#descripción",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#descripción",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Descripción",
    "text": "Descripción\nGithub es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto."
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#repositorios",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#repositorios",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Repositorios",
    "text": "Repositorios\nUn repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados."
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#principales-términos",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#principales-términos",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Principales términos",
    "text": "Principales términos\n\n\n\n\n\n\n\nTérmino\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente»."
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#crear-cuenta-e-instalación",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#crear-cuenta-e-instalación",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Crear cuenta e instalación",
    "text": "Crear cuenta e instalación\n\nAcceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos descritos (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#crear-repositorio",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#crear-repositorio",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Crear repositorio",
    "text": "Crear repositorio\nEn la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio\n\n\n\n\n\n\n\nNota\n\n\n\nUn buen nombre debería intentar resumir las principales características del proyecto de investigación en no más de 3 o 4 conceptos (por ejemplo, movilidad-social-AL para proyecto sobre movilidad social en América Latina)\nEn esta oportunidad, una recomendación sería generar un repositorio “ejercicios-practicos” para almacenar los distintos scripts de ejercicios prácticos que realizaremos en el curso.\nLuego pueden generar un segundo repositorio que sea “Trabajo” para almacenar el desarrollo de sus trabajos de investigación."
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#github-desktop",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#github-desktop",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Github desktop",
    "text": "Github desktop\nUna vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio ejercicios-practicos en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento y apretamos ‘clone’.\n\n7- Creamos las carpetas pertenecientes al protocolo IPO (input-procesamiento-output) para organizar nuestro proyecto)"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#rstudio-projects",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#rstudio-projects",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n\nFile -&gt; New Project"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#abriendo-la-sesión-de-rstudio-como-proyecto",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#abriendo-la-sesión-de-rstudio-como-proyecto",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Abriendo la sesión de RStudio como proyecto",
    "text": "Abriendo la sesión de RStudio como proyecto\n\nidentificar en la carpeta respectiva el archivo .Rproj\nejecutar y se abre R / RStudio con ese directorio como raíz"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#rutas-relativas-en-código",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#rutas-relativas-en-código",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Rutas relativas en código",
    "text": "Rutas relativas en código\n\nforma de “señalar el camino” para abrir y guardar archivos al interior de una carpeta de proyecto autocontenido (= sin referencias locales)\neste camino tiene básicamente 3 direcciones:\n\nbajar -&gt; hacia subcarpetas\nsubir -&gt; hacia carpetas superiores\nsubir y bajar -&gt; hacia otras subcarpetas\n\n\n\nbajando\n\npara “bajar” hacia a una subcarpeta, simplemente damos la ruta de la carpeta/archivo\n\nej: si estoy en el archivo paper.Rmd (directorio raíz), y quiero incluir una imagen (directorio input/images/imagen.jpg), entonces la ruta es input/images/imagen.jpg\no para señalar la ruta al bib desde paper.Rmd (en raíz): input/bib/referencias.bib\n\n\n\n\nsubiendo\n\npara subir se utilizan los caracteres ../ por cada nivel.\nEj: si quiero guardar una tabla en el directorio raíz generada desde un archivo de código en la subcarpeta proc, entonces la ruta es ../tabla.html\n\n\n\nsubiendo y bajando\n\ncombinación de las anteriores\nEj: para abrir la base de datos original en la subcarpeta input/data desde el código de procesamiento en la subcarpeta proc, entonces:\n\n../input/data/original.dat"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#cargar-paquetes",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#cargar-paquetes",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Cargar paquetes",
    "text": "Cargar paquetes\n\npacman::p_load(sjlabelled,\n               dplyr, #Manipulacion de datos\n              stargazer, #Tablas\n              sjmisc, # Tablas\n              summarytools, # Tablas\n              kableExtra, #Tablas\n              sjPlot, #Tablas y gráficos\n              corrplot, # Correlaciones\n              sessioninfo, # Información de la sesión de trabajo\n              ggplot2) # Para la mayoría de los gráficos"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#cargar-bases-de-datos",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#cargar-bases-de-datos",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Cargar bases de datos",
    "text": "Cargar bases de datos\nCargamos ambas bases de datos desde internet\n\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/latinobarometro_total.RData\")) #Cargar base de datos\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/data_wvs.RData\")) #Cargar base de datos\n\nPara trabajar con ambas bases, agruparemos las variables de interés por país, por lo que ya no trabajaremos directamente con individuos.\n\ncontext_data &lt;- wvs %&gt;% group_by(B_COUNTRY) %&gt;% # Agrupar por país\n  summarise(gdp = mean(GDPpercap1, na.rm = TRUE), # Promedio de GDP per capita\n         life_exp = mean(lifeexpect, na.rm = TRUE), # Promedio esperanza de vida\n         gini = mean(giniWB, na.rm = TRUE)) %&gt;%  # Promedio gini\n  rename(idenpa=B_COUNTRY) # Para poder vincular ambas bases, es necesario que la variable de identificación se llamen igual\ncontext_data$idenpa &lt;- as.numeric(context_data$idenpa) # Como era categórica, la dejamos numérica\n\nproc_data &lt;- proc_data %&gt;% group_by(idenpa) %&gt;%  # agrupamos por país\n  summarise(promedio = mean(conf_inst, na.rm = TRUE)) # promedio de confianza en instituciones por país"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#unir-bases-de-datos",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#unir-bases-de-datos",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Unir bases de datos",
    "text": "Unir bases de datos\nPara vincular nuestras bases de datos existen múltiples opciones, la primera es ‘merge’ de R base y las siguientes tres vienen desde dplyr: ‘right_join’, ‘full_join’ y ‘left_join’. Cada una tiene sus propias potencialidades y limitaciones y dependerá de cada caso cuál usemos\n\nProbemos merge\n\ndata &lt;- merge(proc_data, context_data, by=\"idenpa\")\n\n\ndata &lt;- data %&gt;%\n  mutate(idenpa = as.character(idenpa)) %&gt;%\n  mutate(idenpa = case_when(\n    idenpa == \"32\" ~ \"Argentina\",\n    idenpa == \"68\" ~ \"Bolivia\",\n    idenpa == \"76\" ~ \"Brasil\",\n    idenpa == \"152\" ~ \"Chile\",\n    idenpa == \"170\" ~ \"Colombia\",\n    idenpa == \"188\" ~ \"Costa Rica\",\n    idenpa == \"214\" ~ \"Cuba\",\n    idenpa == \"218\" ~ \"República Dominicana\",\n    idenpa == \"222\" ~ \"Ecuador\",\n    idenpa == \"320\" ~ \"El Salvador\",\n    idenpa == \"340\" ~ \"Guatemala\",\n    idenpa == \"484\" ~ \"Honduras\",\n    idenpa == \"558\" ~ \"México\",\n    idenpa == \"591\" ~ \"Nicaragua\",\n    idenpa == \"600\" ~ \"Panamá\",\n    idenpa == \"604\" ~ \"Paraguay\",\n    idenpa == \"858\" ~ \"Uruguay\",\n    idenpa == \"862\" ~ \"Venezuela\"))\n\ndata$gdp &lt;- as.numeric(data$gdp)\ndata$gdp[data$gdp==0] &lt;- NA\ndata &lt;- na.omit(data)\n\n\n\nGuardamos esta nueva base en nuestra carpeta input\n\nsave(data, file=\"input/data/proc/data.RData\")"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#visualizaciones",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#visualizaciones",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Visualizaciones",
    "text": "Visualizaciones\nPodemos establecer referencias cruzadas para las tablas y gráficos dentro del texto, para poder automatizarlo, como ejemplo así, pero dentro del chunk:\n#| label: tbl-sjmisc\n#| tbl-cap: “Descriptivos con sjmisc”\n\nDescriptivos\nEl Chunk se debería ver así:\n#| label: tbl-sjmisc\n#| tbl-cap: “Descriptivos con sjmisc”\nsjmisc::descr(data,\n  show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n\n  kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\nsjmisc::descr(data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;% # Selecciona estadísticos\n      kable(.,\"markdown\") # Esto es para que se vea bien en quarto\n\n\n\nTabla 1: Descriptivos con sjmisc\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n4\npromedio\npromedio\n11\n0\n3.40077\n1.016976\n3.59 (2.3-5.9)\n\n\n1\ngdp\ngdp\n11\n0\n15528.18364\n6480.045512\n19523.79 (5631.2-25154.99)\n\n\n3\nlife_exp\nlife_exp\n11\n0\n75.90909\n2.286593\n8.8 (71.24-80.04)\n\n\n2\ngini\ngini\n11\n0\n45.46364\n4.156266\n14.2 (39.7-53.9)\n\n\n\n\n\n\nLuego de establecer el link y el nombre de la tabla, podemos referenciar acá con un @, así: @ tbl-sjmisc (pero junto), y que se vería así Tabla 1\n\n\nGráficos\nY para los gráficos se hace de la misma forma:\n#| label: fig-gdp\n#| fig-cap: “Plots”\n\ngraph1&lt;-ggplot(data, aes(x = idenpa, y = gdp)) +\n  geom_point() +\n  labs(x = \"País\", y = \"Gdp\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngraph1\n\n\n\n\nFigura 1: Producto interno bruto por país\n\n\n\n\nSin embargo la Figura 1 entrega información desordenada. Mejor ordenar por tamaño de PIB que por orden alfabético de los países. Para eso\n\ndata_sorted &lt;- data %&gt;% arrange(desc(gdp))\ngraph2&lt;-ggplot(data_sorted, aes(x = factor(idenpa, levels = idenpa), y = gdp)) +\n  geom_point() +\n  labs(x = \"País\", y = \"GDP\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngraph2\n\n\n\n\nFigura 2: Producto interno bruto por país ordenado\n\n\n\n\nAhora sí la Figura 2 muestra un gráfico más ordenado.\n\n\nGuardamos este nuevo gráfico en la carpeta output\n\nggsave(graph2, file=\"output/graphs/graph2.png\")\n\nY comparar el promedio de confianza en instituciones según producto interno bruto por país?\n\ndata %&gt;%\n  ggplot(aes(x = gdp, y = promedio, label = idenpa)) +\n  geom_point() +\n  geom_text(vjust = -0.5) +\n  labs(x = \"GDP\", y = \"Promedio\") +\n  theme_bw()\n\n\n\n\nFigura 3: Confianza en instituciones según el producto interno bruto por país\n\n\n\n\nLa Figura 3 muestra la relación que existe entre el producto interno bruto y la confianza en instituciones para los 18 países analizados. Es interesante comparar los casos de Chile y urugay, que al tener similar GDP, tienen un nivel de confianza en instituciones muy diferente.\n\nLuego renderizamos\n\n\ny se debería ver así:\n\n\n\nAhora que tenemos nuestra investigación podemos subirla a Github Pages a través de Github Desktop."
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#github-desktop-1",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#github-desktop-1",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Github desktop",
    "text": "Github desktop"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#github-pages",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#github-pages",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Github pages",
    "text": "Github pages\nAhora podemos ver los documentos modificados en nuestro repositorio online de github.\n\nVamos a settings\n\n\n\nDentro de Settings vamos a Pages, luego ‘none’ y seleccionamos ‘main’. Luego apretamos Save\n\n\nLuego de aproximadamente un minuto se actualiza la página y aparecerá un link en la parte superior, algo así como kevin-carrasco.github.io/ipo que es nuestra página principal de nuestro sitio web de github.\nEl link para llegar a nuestro documento renderizado de quarto sigue la estructura del repositorio:\nkevin-carrasco.github.io/ipo/trabajo.html"
  },
  {
    "objectID": "assignment/taller-github-quarto/taller-github-quarto.html#footnotes",
    "href": "assignment/taller-github-quarto/taller-github-quarto.html#footnotes",
    "title": "Práctico 02: Taller de Quarto y Github",
    "section": "Notas",
    "text": "Notas\n\n\nEsta es la nota al pie↩︎"
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/06-content.html#lecturas",
    "href": "content/06-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/08-content.html#lecturas",
    "href": "content/08-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/10-content.html#lecturas",
    "href": "content/10-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Presentaciones, lecturas y actividades",
    "section": "",
    "text": "En esta sección se encuentran los documentos de presentación correspondientes a cada clase, lecturas y también actividades prácticas."
  },
  {
    "objectID": "resource/01-resource.html",
    "href": "resource/01-resource.html",
    "title": "Práctico 1. Cálculo y reporte de Correlación",
    "section": "",
    "text": "El objetivo de esta guía práctica es aprender a calcular y graficar la correlación entre dos variables utilizando R.\nEn detalle, aprenderemos:\n\nQué es una correlación\nCuál es la correlación de Pearson\nCómo calcular una correlación de Pearson y graficarla"
  },
  {
    "objectID": "resource/01-resource.html#diagrama-de-dispersión-nube-de-puntos-o-scatterplot",
    "href": "resource/01-resource.html#diagrama-de-dispersión-nube-de-puntos-o-scatterplot",
    "title": "Práctico 1. Cálculo y reporte de Correlación",
    "section": "Diagrama de dispersión (nube de puntos o scatterplot)",
    "text": "Diagrama de dispersión (nube de puntos o scatterplot)\nSiempre es recomendable acompañar el valor de la correlación con una exploración gráfica de la distribución bivariada de los datos. El gráfico o diagrama de dispersión es una buena herramienta, ya que muestra la forma, la dirección y la fuerza de la relación entre dos variables cuantitativas.\nEste tipo de gráfico lo podemos realizar usando la librería ggplot2.\n\npacman::p_load(ggplot2)\nplot1 &lt;- ggplot(data, \n                aes(x=educ, y=ing)) + \n                geom_point(colour = \"red\", \n                size = 5)\nplot1\n\n\n\n\nEn el gráfico podemos ver como se crea una nube de puntos en las intersecciones de los valores para ambas variables de cada caso."
  },
  {
    "objectID": "resource/01-resource.html#el-cuarteto-de-anscombe-y-las-limitaciones-de-la-correlación-lineal",
    "href": "resource/01-resource.html#el-cuarteto-de-anscombe-y-las-limitaciones-de-la-correlación-lineal",
    "title": "Práctico 1. Cálculo y reporte de Correlación",
    "section": "El cuarteto de Anscombe y las limitaciones de la correlación lineal",
    "text": "El cuarteto de Anscombe y las limitaciones de la correlación lineal\nAhora, revisaremos un muy buen ejemplo de la importancia de la exploración gráfica de los datos mediante un ejemplo de Anscombe (1973), que permite visualizar las limitaciones del coeficiente de correlación.\nPrimero, crearemos la base de datos:\n\nanscombe &lt;- data.frame(\n  x1 = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5),\n  y1 = c(8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68),\n  x2 = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5),\n  y2 = c(9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74),\n  x3 = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5),\n  y3 = c(7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73),\n  x4 = c(8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8),\n  y4 = c(6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89)\n)\n\nCalculamos la correlación pares de datos\n\ncor(anscombe$x1, anscombe$y1)\n\n[1] 0.8164205\n\ncor(anscombe$x2, anscombe$y2)\n\n[1] 0.8162365\n\ncor(anscombe$x3, anscombe$y3)\n\n[1] 0.8162867\n\ncor(anscombe$x4, anscombe$y4)\n\n[1] 0.8165214\n\n\nPodemos observar que los valores de las correlaciones son equivalentes, por lo tanto podríamos pensar que todos los pares de columnas se encuentran correlacionados de manera similar.\nPero, ¿será suficiente con esa información? Pasemos a revisar los gráficos de dispersión de cada par de variables.\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n  geom_point(colour = \"red\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso I\")\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n  geom_point(colour = \"green\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso II\")\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n  geom_point(colour = \"yellow\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso III\")\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n  geom_point(colour = \"orange\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso IV\")\n\n\n\n\nComo vemos, con distintas distribuciones las correlaciones pueden ser las mismas, principalmente porque Pearson es una medida que solo captura relaciones lineales (rectas), además de verse influido fuertemente por valores extremos. Por lo mismo, es relevante siempre una buena visualización de la distribución bivariada de los datos como complemento al cálculo del coeficiente de correlación."
  },
  {
    "objectID": "resource/03-resource.html",
    "href": "resource/03-resource.html",
    "title": "Práctico 3. Inferencia Estadística y Curva Normal",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en la inferencia estadística, revisando los conceptos y aplicaciones de la curva normal y las probabilidades bajo esta con puntajes Z.\nEn detalle, aprenderemos:\n\nQué es la inferencia estadística.\nQué es una distribución muestral.\nQué es el error estándar.\nQué es la distribución normal y cómo interpretarla.\nCómo calcular probabilidades asociadas con valores Z en R.\nQué son y cómo calcular intervalos de conafianza."
  },
  {
    "objectID": "resource/03-resource.html#qué-es-una-distribución",
    "href": "resource/03-resource.html#qué-es-una-distribución",
    "title": "Práctico 3. Inferencia Estadística y Curva Normal",
    "section": "2.1. ¿Qué es una distribución?",
    "text": "2.1. ¿Qué es una distribución?\nRecordemos que por distribución nos referimos al conjunto de todos los valores posibles de una variable y las frecuencias (o probabilidades) con las que se producen.\nExisten distribuciones empíricas y distribuciones teóricas, en donde:\n\nlas primeras reflejan la distribución de los valores que asume la variable en un grupo concreto a partir de una observación.\nlas segundas son una función matématica que expresan la distribución de un conjunto de números mediante su probabilidad de ocurencia.\n\nUna de las distribuciones teóricas más conocidas es la distribución normal estándar."
  },
  {
    "objectID": "resource/03-resource.html#distribución-muestral-1",
    "href": "resource/03-resource.html#distribución-muestral-1",
    "title": "Práctico 3. Inferencia Estadística y Curva Normal",
    "section": "2.2. Distribución muestral",
    "text": "2.2. Distribución muestral\n\n\n\n\n\n\nNota\n\n\n\nVariabilidad muestral: el valor de un estadístico varía en un muestreo aleatorio repetido.\n\n\nLa distribución muestral es la distribución de las estimaciones, o estadísticos como la media o proporción, tomadas de múltiples muestras aleatorias de una población. Permite comprender cómo varían las estimaciones de una muestra a otra.\nEjemplo 1: Imaginemos que tenemos una población de niñ_s de 0 a 9 años, y tomamos múltiples muestras de 6 individu_s (n=6). Cada una de las muestras tendrá un promedio (estadístico muestral, en este caso \\(\\bar{x}\\)) diferente, que no necesariamente coincidirá con el promedio de la población (parámetro, en este caso \\(\\mu_{x}\\))\n\nEjemplo 2: Si usamos valores simulados, podemos ver que todas las medias obtenidas en cada muesta son distintas.\n\nset.seed(100)  # Establecer semilla \nmuestras &lt;- replicate(100, mean(rnorm(30, mean = 50, sd = 10))) # 100 muestras de tamaño 30\nmuestras\n\n  [1] 50.28864 50.92574 49.56125 49.25099 48.40735 51.67506 49.28325 48.90829\n  [9] 50.64635 51.94797 49.68514 49.00100 49.87287 47.58167 50.91109 47.61967\n [17] 47.94270 52.20491 51.38777 50.76559 49.02265 49.16394 50.59675 51.40631\n [25] 50.28247 51.94561 50.39929 51.95632 55.25584 51.26112 49.02810 46.46643\n [33] 52.21139 49.48146 50.43067 52.84081 47.97451 46.55278 49.87576 50.88025\n [41] 50.78748 49.42165 50.46664 51.06194 49.94867 48.39219 49.79581 49.82214\n [49] 49.93791 49.16883 52.24256 51.46923 46.51443 50.23611 49.87410 50.87291\n [57] 52.32911 46.21546 47.26934 51.29019 50.49509 49.63433 53.25368 50.81717\n [65] 49.45387 49.61571 50.33774 47.02089 47.94071 50.16296 51.12409 50.68963\n [73] 50.32398 52.22186 49.95585 50.74844 48.08507 52.90382 51.43478 46.74822\n [81] 49.21148 51.83738 49.66936 49.32308 50.31842 46.47797 50.64338 50.01220\n [89] 52.26135 47.49504 49.93140 53.04953 49.59253 48.83580 49.57802 49.23299\n [97] 50.32517 50.82952 48.92960 49.47553\n\n\nSi conocemos la desviación estándar de los promedios, podedmos construir un intervalo de probabilidad, basado en la curva normal.\n\n\n\n\n\n\nNota\n\n\n\nUna característica importante es que se asume que las muestras tomadas de la población son aleatorias y representativas, lo que es esencial para que la distribución muestral refleje adecuadamente la variabilidad de las estimaciones.\n\n\nLa importancia de la distribución muestral es que nos permitirá estimar parámetros poblacionales a partir de estadísticos muestrales, construir intervalos de confianza, y realizar pruebas de hipótesis."
  },
  {
    "objectID": "resource/03-resource.html#ejercicio-de-aplicación",
    "href": "resource/03-resource.html#ejercicio-de-aplicación",
    "title": "Práctico 3. Inferencia Estadística y Curva Normal",
    "section": "Ejercicio de aplicación",
    "text": "Ejercicio de aplicación\nAhora que hemos generado distribuciones normales, echemos un vistazo a algunos datos y compárelos con la distribución normal. Utilizaremos un conjunto de datos desde internet, con mediciones de 247 hombres y 260 mujeres, la mayoría de los cuales eran considerados adultos jóvenes sanos. Puede encontrar una clave para los nombres de las variables aquí, pero nos centraremos en solo tres columnas: peso en kg (wgt), altura en cm (hgt) y sexo (1 = hombre; 0 = mujer).\n\nload(url(\"http://www.openintro.org/stat/data/bdims.RData\"))\n\nSeparemos estos datos en dos conjuntos, uno de hombres y otro de mujeres con la función subset\n\nmdims &lt;- subset(bdims, sex == 1)\nfdims &lt;- subset(bdims, sex == 0)\n\n\nEjercicio 1\nHaz un histograma de la altura de los hombres y un histograma de la altura de las mujeres. ¿Cómo compararía los diversos aspectos de las dos distribuciones?\n\nhist(mdims$hgt, xlim = c(150,200))\n\n\n\nhist(fdims$hgt, xlim = c(140,190))\n\n\n\n\n\n\nEjercicio 2\nscale es una función en R y se puede aplicar a cualquier vector numérico (lista de números en R). Genere los dos histogramas siguientes, esta vez graficando scale() de las estaturas y determine cómo la versión escalada de las alturas corresponde a las alturas originales. ¿Qué calcula la escala para cada punto?\n\nhist(scale(mdims$hgt))\n\n\n\nhist(scale(fdims$hgt))\n\n\n\n\n\n\nEjercicio 3\nNos gustaría comparar la distribución de estaturas en este conjunto de datos con la distribución normal. Para cada uno de los histogramas de alturas (sin escalar), trace una curva normal en la parte superior del histograma.\n\nCalcule la media y la desviación estándar para las alturas femeninas y guárdelas como variables, fhgtmean y fhgtsd, respectivamente.\nDetermine la lista de valores de x (el rango del eje X) y guarde este vector. Puede hacer fácilmente una lista de números usando la función seq() como lo hemos hecho antes, o teniendo el límite inferior:límite superior. Por ejemplo, para generar un vector (lista de números) del 1 al 10 y guardarlo como one_ten, usaría one_ten &lt;- 1:10.\nComo arriba, use dnorm() para tomar la lista de valores de x y encontrar el valor de y correspondiente si fuera una distribución normal perfecta. Guarde este vector como la variable y.\nVuelva a trazar su histograma y luego, en la siguiente línea, use lines(x = x, y = y, col = \"blue\") para dibujar una distribución normal encima.\n\n\nfhgtmean &lt;- mean(fdims$hgt)\nfhgtsd   &lt;- sd(fdims$hgt)\nhist(fdims$hgt, probability = TRUE, ylim = c(0, .07))\nx &lt;- 140:190\ny &lt;- dnorm(x = x, mean = fhgtmean, sd = fhgtsd)\nlines(x = x, y = y, col = \"blue\")\n\n\n\n\nSegún este gráfico, ¿parece que los datos siguen una distribución casi normal? Haz lo mismo con las estaturas masculinas.\n\nRespuesta: En general, sí, consideraría que estos valores siguen una distribución casi normal ya que el histograma se ajusta bastante bien a la curva.\n\nObserve que la forma del histograma es una forma de determinar si los datos parecen estar distribuidos casi normalmente, pero puede resultar frustrante decidir qué tan cerca está el histograma de la curva. Un enfoque alternativo implica construir una gráfica de probabilidad normal, también llamada gráfica Q-Q por “quantil-quantil”. Ejecute ambas líneas juntas.\n\nqqnorm(fdims$hgt)\nqqline(fdims$hgt)\n\n\n\n\nUn QQ plot nos muestra en el eje x los cuantiles teóricos de la distribución en términos de desviaciones estandar, y en el eje y los valores de la variable. La distribución de los puntos en una línea recta es una indicación de que los datos se distribuyen normalmente.\nVeamos otro ejemplo de otra variable de la base de datos:\n\nhist(fdims$che.de)\n\n\n\nqqnorm(fdims$che.de)\nqqline(fdims$che.de)\n\n\n\n\nUna vez que decidimos que una variable se distribuyte de forma normal, podemos responder todo tipo de preguntas sobre esa variable relacionadas con la probabilidad. Tomemos, por ejemplo, la pregunta: “¿Cuál es la probabilidad de que una mujer adulta joven elegida al azar mida más 182 cm?”\nSi suponemos que las alturas de las mujeres se distribuyen normalmente (una aproximación muy cercana también está bien), podemos encontrar esta probabilidad calculando una puntuación Z y consultando una tabla Z (también llamada tabla de probabilidad normal).\nEn R, esto se hace en un solo paso con la función pnorm (como hicimos anteriormente para la distribución normal estándar).\n\npnorm(q = 182, mean = fhgtmean, sd = fhgtsd)\n\n[1] 0.9955656\n\n\nObtenemos la proporción de mujeres que está bajo esa estatura, es decir 99,6%. Si queremos saber la proporción de mujeres que está sobre esa estatura:\n\n1 - pnorm(q = 182, mean = fhgtmean, sd = fhgtsd)\n\n[1] 0.004434387\n\n\nEn este caso, el 0,4% de las mujeres se encontraría sobre esa estatura.\nPodemos también hacer la operación inversa, es decir, a qué valor (estatura) corresponde un porcentaje o probabilidad basada en una distribución normal. Para ello utilizamos la función qnorm. Por ejemplo, para la probabilidad que calculamos más arriba para una altura de 182cm en las mujeres:\n\nqnorm(.9955656, fhgtmean, fhgtsd)\n\n[1] 182"
  },
  {
    "objectID": "resource/03-resource.html#cálculo-de-intervalos-de-confianza",
    "href": "resource/03-resource.html#cálculo-de-intervalos-de-confianza",
    "title": "Práctico 3. Inferencia Estadística y Curva Normal",
    "section": "Cálculo de intervalos de confianza",
    "text": "Cálculo de intervalos de confianza\nAhora ¡Manos a la obra!\nCalculemos intervalos de confianza. Primero, carguemos las librerías necesarias:\n\nlibrary(pacman)\n\nWarning: package 'pacman' was built under R version 4.3.3\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               car,       # para recodificar\n               psych,     # para analizar datos\n               sjmisc,    # para analizar datos\n               srvyr,     # para estimación de IC y ponderadores\n               Publish)   # para IC\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\ny también carguemos la base de datos que utilizaremos, que corresponde a un subset de la Encuesta Suplementaria de ingresos ESI para ocupados:\n\nload(url(\"https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/esi-2021-ocupados.rdata\"))\n\n\n\n\n\n\n\nNota\n\n\n\nRecordemos que podemos contar con bases de datos que tengan factor de expansión (ponderador) o no. Esta distinción se presenta cuando trabajamos con muestras simples o complejas. Al trabajar con muestras complejas debemos identificar cuál es la variable del ponderador e incorporarla en nuestro cálculo, como veremos a continuación.\n\n\n\nIntervalos de confianza sin ponderador\nPodemos calcular intervalos de confianza con muestras representativas sin ponderadores o factores de expansión. Supongamos que es el caso.\n\nIC para Medias\nCalculemos un intervalo de confianza para la media de ingresos de personas ocupadas:\n\npsych::describe(esi$ing_t_p)\n\n   vars     n     mean       sd   median  trimmed      mad min      max\nX1    1 37124 586360.4 697362.9 405347.7 474473.1 255411.6   0 38206253\n      range skew kurtosis      se\nX1 38206253   12   402.32 3619.36\n\n\n\nPublish::ci.mean(esi$ing_t_p, alpha = 0.05)\n\n mean      CI-95%               \n 586360.41 [579266.37;593454.45]\n\n\nAl no aplicar factores de expansión, contamos con una media de ingresos de $586.360 como estimación puntual. Pero también podemos decir que con un 95% de confianza el parámetro poblacional se encontrará entre $579.266 y $593.454.\n\n\nIC para Proporciones\nPara calcular un intervalo de confianza para la proporción por la variable sexo, usamos:\n\nsjmisc::frq(esi$sexo)\n\nx &lt;numeric&gt; \n# total N=37124 valid N=37124 mean=1.44 sd=0.50\n\nValue |     N | Raw % | Valid % | Cum. %\n----------------------------------------\n    1 | 20806 | 56.04 |   56.04 |  56.04\n    2 | 16318 | 43.96 |   43.96 | 100.00\n &lt;NA&gt; |     0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nprop.test(x = 20806, n = 37124, conf.level = 0.95)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  20806 out of 37124, null probability 0.5\nX-squared = 542.32, df = 1, p-value &lt; 0.00000000000000022\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.5553777 0.5655019\nsample estimates:\n        p \n0.5604461 \n\n\nEn este caso, sabemos que el total de las personas ocupadas de la muestra son n=37.124, y que la cantidad de hombres son 20.806, correspondientes al 56% como estimación puntual. También podemos sostener con un 95% que la proporción de hombres en la población se encuentra entre 55.54% y 56.6%.\n\n\n\nIntervalos de confianza con ponderador\nPara muestras complejas que cuentan con ponderador (o factor de expansión) también podemos hacer este ejercicio.\nPrimero, es necesario identificar la variable de factor de expansión o ponderador:\n\nesi_pond &lt;- esi %&gt;% as_survey_design(ids = 1, # indica conglomerados de muestreo; ~0 o ~1 cuando no hay\n                                     strata = estrato, # indica efecto de diseño muestral\n                                     weights = fact_cal_esi) # indica el ponderador\n\noptions(survey.lonely.psu = \"certainty\") # seteamos para que ids no moleste\n\n\nIC para Medias\nAhora, teniendo en consideración el factor de expansión, podemos señalar que:\n\nesi_pond %&gt;% \n  summarise(media = survey_mean(ing_t_p, vartype = \"ci\", levels = 0.95, na.rm=TRUE)) # usamos funcion survey_mean\n\n# A tibble: 1 × 3\n    media media_low media_upp\n    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 681039.   666563.   695516.\n\n\nEl promedio de ingresos de personas ocupadas ponderado en la población corresponde a $681.039 como estimación puntual, pero que es posible afirmar con un 95% de confianza que el parámetro poblacional se encuentra entre $666.562 y $695.516.\n\n\nIC para Proporciones\nFinalmente, si calculamos la proporción de hombres ocupados en la población considerando el factor de expansión:\n\nsjmisc::frq(esi$sexo)\n\nx &lt;numeric&gt; \n# total N=37124 valid N=37124 mean=1.44 sd=0.50\n\nValue |     N | Raw % | Valid % | Cum. %\n----------------------------------------\n    1 | 20806 | 56.04 |   56.04 |  56.04\n    2 | 16318 | 43.96 |   43.96 | 100.00\n &lt;NA&gt; |     0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\nesi_pond %&gt;% \n  group_by(sexo) %&gt;% # agrupamos por sexo\n  summarise(prop = survey_prop(vartype = \"ci\", levels = 0.95, na.rm = TRUE))\n\n# A tibble: 2 × 4\n   sexo  prop prop_low prop_upp\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     1 0.582    0.575    0.590\n2     2 0.418    0.410    0.425\n\n\nTenemos que, con un 95% de conafianza, podemos afirmar que la proporción de hombre ocupados se encuentra entre el 57% y 58%."
  },
  {
    "objectID": "resource/05-resource.html",
    "href": "resource/05-resource.html",
    "title": "Práctico 5. Documentos reproducibles",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de introducir en los supuestos y robustez del modelo de regresión. Por esta razón, volveremos a algunos de los contenidos previos relacionados con la estimación, análisis de residuos y ajuste. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\nLa versión original de este ejercicio proviene del curso de Estadística multivariada versión 2022."
  },
  {
    "objectID": "resource/05-resource.html#explorar-datos",
    "href": "resource/05-resource.html#explorar-datos",
    "title": "Práctico 5. Documentos reproducibles",
    "section": "Explorar datos",
    "text": "Explorar datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\n\nview(dfSummary(elsoc, headings = FALSE, method = \"render\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nsexo [numeric]\nSexo entrevistado\n\n\n\nMin : 0\n\n\nMean : 0.6\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n1446\n(\n38.6%\n)\n\n\n1\n:\n2302\n(\n61.4%\n)\n\n\n\n\n3748 (100.0%)\n0 (0.0%)\n\n\n2\nedad [numeric]\nEdad entrevistado\n\n\n\nMean (sd) : 47.1 (15.5)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 47 ≤ 90\n\n\nIQR (CV) : 25 (0.3)\n\n\n\n70 distinct values\n\n3748 (100.0%)\n0 (0.0%)\n\n\n3\neduc [factor]\nNivel educacional\n\n\n\n1. 1\n\n\n2. 2\n\n\n3. 3\n\n\n4. 4\n\n\n5. 5\n\n\n\n\n\n\n450\n(\n12.0%\n)\n\n\n370\n(\n9.9%\n)\n\n\n1600\n(\n42.7%\n)\n\n\n598\n(\n16.0%\n)\n\n\n725\n(\n19.4%\n)\n\n\n\n\n3743 (99.9%)\n5 (0.1%)\n\n\n4\npospol [factor]\nAutoubicacion escala izquierda-derecha\n\n\n\n1. 1\n\n\n2. 2\n\n\n3. 3\n\n\n4. 4\n\n\n\n\n\n\n807\n(\n22.0%\n)\n\n\n952\n(\n26.0%\n)\n\n\n734\n(\n20.0%\n)\n\n\n1171\n(\n32.0%\n)\n\n\n\n\n3664 (97.8%)\n84 (2.2%)\n\n\n5\npart01 [numeric]\nFrecuencia: Firma carta o peticion apoyando causa\n\n\n\nMean (sd) : 1.5 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 1 (0.6)\n\n\n\n\n\n\n1\n:\n2717\n(\n72.6%\n)\n\n\n2\n:\n476\n(\n12.7%\n)\n\n\n3\n:\n411\n(\n11.0%\n)\n\n\n4\n:\n117\n(\n3.1%\n)\n\n\n5\n:\n21\n(\n0.6%\n)\n\n\n\n\n3742 (99.8%)\n6 (0.2%)\n\n\n6\npart02 [numeric]\nFrecuencia: Asiste a marcha o manifestacion pacifica\n\n\n\nMean (sd) : 1.2 (0.6)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 0 (0.5)\n\n\n\n\n\n\n1\n:\n3289\n(\n87.8%\n)\n\n\n2\n:\n195\n(\n5.2%\n)\n\n\n3\n:\n191\n(\n5.1%\n)\n\n\n4\n:\n51\n(\n1.4%\n)\n\n\n5\n:\n19\n(\n0.5%\n)\n\n\n\n\n3745 (99.9%)\n3 (0.1%)\n\n\n7\npart03 [numeric]\nFrecuencia: Participa en huelga\n\n\n\nMean (sd) : 1.2 (0.5)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 0 (0.5)\n\n\n\n\n\n\n1\n:\n3407\n(\n91.0%\n)\n\n\n2\n:\n152\n(\n4.1%\n)\n\n\n3\n:\n146\n(\n3.9%\n)\n\n\n4\n:\n29\n(\n0.8%\n)\n\n\n5\n:\n11\n(\n0.3%\n)\n\n\n\n\n3745 (99.9%)\n3 (0.1%)\n\n\n8\npart04 [numeric]\nFrecuencia: Usa redes sociales para opinar en temas publicos\n\n\n\nMean (sd) : 1.6 (1.1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 1 (0.7)\n\n\n\n\n\n\n1\n:\n2598\n(\n69.4%\n)\n\n\n2\n:\n310\n(\n8.3%\n)\n\n\n3\n:\n514\n(\n13.7%\n)\n\n\n4\n:\n223\n(\n6.0%\n)\n\n\n5\n:\n98\n(\n2.6%\n)\n\n\n\n\n3743 (99.9%)\n5 (0.1%)\n\n\n9\nquintilemiss [factor]\n\n\n\n\n1. Quintil 1\n\n\n2. Quintil 2\n\n\n3. Quintil 3\n\n\n4. Quintil 4\n\n\n5. Quintil 5\n\n\n6. Missing\n\n\n\n\n\n\n711\n(\n19.0%\n)\n\n\n711\n(\n19.0%\n)\n\n\n710\n(\n18.9%\n)\n\n\n710\n(\n18.9%\n)\n\n\n710\n(\n18.9%\n)\n\n\n196\n(\n5.2%\n)\n\n\n\n\n3748 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-04-25\n\n\n\n\nview_df(elsoc,max.len = 50)\n\n\nData frame: elsoc\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nsexo\nSexo entrevistado\n0\n1\nHombre\nMujer\n\n\n2\nedad\nEdad entrevistado\nrange: 18-90\n\n\n3\neduc\nNivel educacional\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\n\n\n4\npospol\nAutoubicacion escala izquierda-derecha\n1\n2\n3\n4\nDerecha\nCentro\nIzquierda\nIndep./Ninguno\n\n\n5\npart01\nFrecuencia: Firma carta o peticion apoyando causa\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n6\npart02\nFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n7\npart03\nFrecuencia: Participa en huelga\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n8\npart04\nFrecuencia: Usa redes sociales para opinar en\ntemas publicos\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n9\nquintilemiss\n\n\nQuintil 1\nQuintil 2\nQuintil 3\nQuintil 4\nQuintil 5\nMissing\n\n\n\n\n\n\nelsoc &lt;- elsoc %&gt;% mutate(partpol=rowSums(select(., part01,part02,part03,part04)))"
  },
  {
    "objectID": "resource/05-resource.html#diágnosticos",
    "href": "resource/05-resource.html#diágnosticos",
    "title": "Práctico 5. Documentos reproducibles",
    "section": "Diágnosticos",
    "text": "Diágnosticos\n\nCasos influyentes\nPara determinar si un outlier es un caso influyente, es decir que su presencia/ausencia genera un cambio importante en la estimación de los coeficientes de regresión, calculamos la Distancia de Cook..\nPosteriormente, se establece un punto de corte de \\(4/(n-k-1)\\):\n\nn&lt;- nobs(fit04) #n de observaciones\nk&lt;- length(coef(fit04)) # n de parametros\ndcook&lt;- 4/(n-k-1) #punt de corte\n\nSi lo graficamos se ve de la siguiente manera:\n\nfinal &lt;- broom::augment_columns(fit04,data = elsoc)\nfinal$id &lt;- as.numeric(row.names(final))\n# identify obs with Cook's D above cutoff\nggplot(final, aes(id, .cooksd)) +\n  geom_bar(stat=\"identity\", position=\"identity\") +\n  xlab(\"Obs. Number\")+ # Modificación nombre eje x\n  ylab(\"Cook's distance\")+ # Modificación nombre eje y\n  geom_hline(yintercept=dcook)+ # Incluir una línea horizontal\n  geom_text(aes(label=ifelse((.cooksd&gt;dcook),id,\"\")), # geom text agrega nombre a los casos, en esta oportunidad solo a los valores mayores a dcook\n            vjust=-0.2, hjust=0.5)\n\n\n\n\nIdentificamos los casos influyentes y filtramos la base de datos:\n\nident&lt;- final %&gt;% filter(.cooksd&gt;dcook)\nelsoc02 &lt;- final %&gt;% filter(!(id %in% ident$id))\n\nEstimación sin casos influyentes:\n\nfit05&lt;- lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc02)\n\nlabs02 &lt;- c(\"Intercepto\",\"Sexo (mujer=1)\",\"Edad\",\n            \"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Quintil perdido\",\n            \"Izquierda (ref. derecha)\",\"Centro\",\"Idep./Ninguno\")\n\nhtmlreg(list(fit04,fit05), \n        doctype = FALSE,\n        custom.model.names = c(\"Modelo 4\", \"Modelo 5\"),\n        custom.coef.names = labs02)\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo 4\n\n\nModelo 5\n\n\n\n\n\n\nIntercepto\n\n\n7.97***\n\n\n7.05***\n\n\n\n\n \n\n\n(0.16)\n\n\n(0.11)\n\n\n\n\nSexo (mujer=1)\n\n\n0.12\n\n\n0.07\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.05)\n\n\n\n\nEdad\n\n\n-0.04***\n\n\n-0.03***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nQuintil 2\n\n\n0.21\n\n\n0.11\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 3\n\n\n0.51***\n\n\n0.34***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 4\n\n\n0.50***\n\n\n0.32***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 5\n\n\n0.88***\n\n\n0.57***\n\n\n\n\n \n\n\n(0.12)\n\n\n(0.08)\n\n\n\n\nQuintil perdido\n\n\n0.59***\n\n\n0.31*\n\n\n\n\n \n\n\n(0.18)\n\n\n(0.13)\n\n\n\n\nIzquierda (ref. derecha)\n\n\n-1.04***\n\n\n-0.65***\n\n\n\n\n \n\n\n(0.10)\n\n\n(0.07)\n\n\n\n\nCentro\n\n\n-1.13***\n\n\n-0.71***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nIdep./Ninguno\n\n\n-1.60***\n\n\n-1.14***\n\n\n\n\n \n\n\n(0.10)\n\n\n(0.07)\n\n\n\n\nR2\n\n\n0.17\n\n\n0.18\n\n\n\n\nAdj. R2\n\n\n0.17\n\n\n0.18\n\n\n\n\nNum. obs.\n\n\n3656\n\n\n3460\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n\nEn términos generales, el sentido y significación estadística de los coeficientes del Modelo 5 se mantiene respecto al Modelo 4. Adicionalmente, si observamos que el modelo sin casos influyentes presenta una mejora en ajuste. Por lo tanto, los análisis posteriores se realizaran en base a este modelo.\n\n\nLinealidad\nPara analizar la linealidad respecto de un modelo de regresión, debemos analizar la distribución de los residuos con respecto a la recta de regresión.\n\nLos residuos deben ser independientes de los valores predichos (fitted values).\nCualquier correlación entre residuo y valores predichos violarían este supuesto.\nLa presencia de un patrón no lineal, es señal de que el modelo está especificado incorrectamente.\n\n\nggplot(fit05, aes(.fitted, .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_smooth(se = TRUE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nRelación entre residuos y valores predichos\n\n\n\n\nEl gráfico nos indica que existe un patrón en la distribución de los residuos. Para intentar mejorar la estimación podemos realizar una transformación de variables. A continuación presentaremos un ejemplo para la Edad y para los Ingresos.\n\nPolinomio: \\(\\text{Edad}^2\\)\n\n\nelsoc02$edad2 &lt;- elsoc02$edad^2\nfit06&lt;- lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\n\n\nedad&lt;- fit06$model$edad\nfit&lt;- fit06$fitted.values\ndata01 &lt;- as.data.frame(cbind(edad,fit))\n\nggplot(data01, aes(x = edad, y = fit)) +\n  theme_bw() +\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nEfecto cuadrático de la edad (Modelo 5)\n\n\n\n\n\nfit07 &lt;- lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\n\nlabs03 &lt;- c(\"Intercepto\",\"Sexo (mujer=1)\",\"Edad\",\n            \"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Quintil perdido\",\n            \"Izquierda (ref. derecha)\",\"Centro\",\"Idep./Ninguno\", \"Edad²\")\n\nhtmlreg(list(fit05, fit06, fit07), doctype = FALSE,\n        custom.model.names = c(\"Modelo 4\", \"Modelo 5\", \"Modelo 6\"), \n          custom.coef.names = labs03)\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo 4\n\n\nModelo 5\n\n\nModelo 6\n\n\n\n\n\n\nIntercepto\n\n\n7.05***\n\n\n7.62***\n\n\n7.62***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.24)\n\n\n(0.24)\n\n\n\n\nSexo (mujer=1)\n\n\n0.07\n\n\n0.08\n\n\n0.08\n\n\n\n\n \n\n\n(0.05)\n\n\n(0.05)\n\n\n(0.05)\n\n\n\n\nEdad\n\n\n-0.03***\n\n\n-0.06***\n\n\n-0.06***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n\n\nQuintil 2\n\n\n0.11\n\n\n0.11\n\n\n0.11\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 3\n\n\n0.34***\n\n\n0.34***\n\n\n0.34***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 4\n\n\n0.32***\n\n\n0.32***\n\n\n0.32***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 5\n\n\n0.57***\n\n\n0.57***\n\n\n0.57***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil perdido\n\n\n0.31*\n\n\n0.31*\n\n\n0.31*\n\n\n\n\n \n\n\n(0.13)\n\n\n(0.13)\n\n\n(0.13)\n\n\n\n\nIzquierda (ref. derecha)\n\n\n-0.65***\n\n\n-0.65***\n\n\n-0.65***\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.07)\n\n\n(0.07)\n\n\n\n\nCentro\n\n\n-0.71***\n\n\n-0.70***\n\n\n-0.70***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nIdep./Ninguno\n\n\n-1.14***\n\n\n-1.13***\n\n\n-1.13***\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.07)\n\n\n(0.07)\n\n\n\n\nEdad²\n\n\n \n\n\n0.00**\n\n\n0.00**\n\n\n\n\n \n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nR2\n\n\n0.18\n\n\n0.19\n\n\n0.19\n\n\n\n\nAdj. R2\n\n\n0.18\n\n\n0.18\n\n\n0.18\n\n\n\n\nNum. obs.\n\n\n3460\n\n\n3460\n\n\n3460\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05"
  },
  {
    "objectID": "resource/05-resource.html#referencias",
    "href": "resource/05-resource.html#referencias",
    "title": "Práctico 5. Documentos reproducibles",
    "section": "Referencias",
    "text": "Referencias\nDarlington & Hayes 2016 Cap16 Detecting and Managing Irregularities\nDarlington & Hayes 2016 Cap12 Nonlinear relationships"
  },
  {
    "objectID": "resource/07-resource.html",
    "href": "resource/07-resource.html",
    "title": "Práctica 6 Correlación y regresión",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de repasar en la interpretación de coeficientes de correlación y la construcción de índices, así como también en la interpretación de coeficientes de regresión lineal y logística. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\nLa versión original de este ejercicio proviene del curso de Estadística multivariada versión 2022."
  },
  {
    "objectID": "resource/07-resource.html#explorar-datos",
    "href": "resource/07-resource.html#explorar-datos",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Explorar datos",
    "text": "Explorar datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\n\nview_df(elsoc,max.len = 50)\n\n\nData frame: elsoc\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nsexo\nSexo entrevistado\n0\n1\nHombre\nMujer\n\n\n2\nedad\nEdad entrevistado\nrange: 18-90\n\n\n3\neduc\nNivel educacional\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\n\n\n4\npospol\nAutoubicacion escala izquierda-derecha\n1\n2\n3\n4\nDerecha\nCentro\nIzquierda\nIndep./Ninguno\n\n\n5\npart01\nFrecuencia: Firma carta o peticion apoyando causa\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n6\npart02\nFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n7\npart03\nFrecuencia: Participa en huelga\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n8\npart04\nFrecuencia: Usa redes sociales para opinar en\ntemas publicos\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n9\ninghogar\nIngreso total del hogar\nrange: 30000-17000000\n\n\n10\ninghogar_t\nIngreso total del hogar (en tramos)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nMenos de $220.000 mensuales liquidos\nDe $220.001 a $280.000 mensuales liquidos\nDe $280.001 a $330.000 mensuales liquidos\nDe $330.001 a $380.000 mensuales liquidos\nDe $380.001 a $420.000 mensuales liquidos\nDe $420.001 a $470.000 mensuales liquidos\nDe $470.001 a $510.000 mensuales liquidos\nDe $510.001 a $560.000 mensuales liquidos\nDe $560.001 a $610.000 mensuales liquidos\nDe $610.001 a $670.000 mensuales liquidos\nDe $670.001 a $730.000 mensuales liquidos\nDe $730.001 a $800.000 mensuales liquidos\nDe $800.001 a $890.000 mensuales liquidos\nDe $890.001 a $980.000 mensuales liquidos\nDe $980.001 a $1.100.000 mensuales liquidos\nDe $1.100.001 a $1.260.000 mensuales liquidos\nDe $1.260.001 a $1.490.000 mensuales liquidos\nDe $1.490.001 a $1.850.000 mensuales liquidos\nDe $1.850.001 a $2.700.000 mensuales liquidos\nMas de $2.700.000 a mensuales liquidos\n\n\n11\ntamhogar\nHabitantes del hogar\nrange: 1-14"
  },
  {
    "objectID": "resource/07-resource.html#variable-dependiente-participación-política",
    "href": "resource/07-resource.html#variable-dependiente-participación-política",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Variable dependiente: participación política",
    "text": "Variable dependiente: participación política\n\nplot_stackfrq(elsoc[,c(\"part01\",\"part02\",\"part03\",\"part04\")]) + theme(legend.position=\"bottom\")\n\n\n\n\n\ncorrplot.mixed(cor(select(elsoc,part01,part02,part03,part04),\n                   use = \"complete.obs\"))\n\n\n\n\n\nelsoc &lt;- elsoc %&gt;% mutate(partpol=rowSums(select(., part01,part02,part03,part04)))\nsummary(elsoc$partpol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  4.000   4.000   4.000   5.473   6.000  20.000       8"
  },
  {
    "objectID": "resource/07-resource.html#variable-independiente-ingresos",
    "href": "resource/07-resource.html#variable-independiente-ingresos",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Variable independiente: ingresos",
    "text": "Variable independiente: ingresos\ningresos hogar variable continua\n\nsummary(elsoc$inghogar)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n   30000   300000   500000   678843   800000 17000000      668 \n\n\ningreso hogar en tramos\n\nsjmisc::frq(elsoc$inghogar_t,\n            out = \"txt\",\n            show.na = T) %&gt;% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nval\nlabel\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\n\n1\nMenos de $220.000 mensuales liquidos\n62\n1.65\n13.00\n13.00\n\n\n2\nDe $220.001 a $280.000 mensuales liquidos\n46\n1.23\n9.64\n22.64\n\n\n3\nDe $280.001 a $330.000 mensuales liquidos\n57\n1.52\n11.95\n34.59\n\n\n4\nDe $330.001 a $380.000 mensuales liquidos\n40\n1.07\n8.39\n42.98\n\n\n5\nDe $380.001 a $420.000 mensuales liquidos\n38\n1.01\n7.97\n50.94\n\n\n6\nDe $420.001 a $470.000 mensuales liquidos\n37\n0.99\n7.76\n58.70\n\n\n7\nDe $470.001 a $510.000 mensuales liquidos\n27\n0.72\n5.66\n64.36\n\n\n8\nDe $510.001 a $560.000 mensuales liquidos\n15\n0.40\n3.14\n67.51\n\n\n9\nDe $560.001 a $610.000 mensuales liquidos\n24\n0.64\n5.03\n72.54\n\n\n10\nDe $610.001 a $670.000 mensuales liquidos\n12\n0.32\n2.52\n75.05\n\n\n11\nDe $670.001 a $730.000 mensuales liquidos\n15\n0.40\n3.14\n78.20\n\n\n12\nDe $730.001 a $800.000 mensuales liquidos\n16\n0.43\n3.35\n81.55\n\n\n13\nDe $800.001 a $890.000 mensuales liquidos\n8\n0.21\n1.68\n83.23\n\n\n14\nDe $890.001 a $980.000 mensuales liquidos\n14\n0.37\n2.94\n86.16\n\n\n15\nDe $980.001 a $1.100.000 mensuales liquidos\n14\n0.37\n2.94\n89.10\n\n\n16\nDe $1.100.001 a $1.260.000 mensuales liquidos\n10\n0.27\n2.10\n91.19\n\n\n17\nDe $1.260.001 a $1.490.000 mensuales liquidos\n7\n0.19\n1.47\n92.66\n\n\n18\nDe $1.490.001 a $1.850.000 mensuales liquidos\n11\n0.29\n2.31\n94.97\n\n\n19\nDe $1.850.001 a $2.700.000 mensuales liquidos\n14\n0.37\n2.94\n97.90\n\n\n20\nMas de $2.700.000 a mensuales liquidos\n10\n0.27\n2.10\n100.00\n\n\nNA\nNA\n3271\n87.27\nNA\nNA\n\n\n\n\n\n\n\n\n\n\npodemos obtener la mediana de cada tramo\n\nelsoc$inghogar_t[elsoc$inghogar_t==1] &lt;-(       220000 )    # [1]  \"Menos de $220.000 mensuales liquidos\"          \nelsoc$inghogar_t[elsoc$inghogar_t==2] &lt;-(220001 +280000 )/2 # [2]  \"De $220.001 a $280.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==3] &lt;-(280001 +330000 )/2 # [3]  \"De $280.001 a $330.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==4] &lt;-(330001 +380000 )/2 # [4]  \"De $330.001 a $380.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==5] &lt;-(380001 +420000 )/2 # [5]  \"De $380.001 a $420.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==6] &lt;-(420001 +470000 )/2 # [6]  \"De $420.001 a $470.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==7] &lt;-(470001 +510000 )/2 # [7]  \"De $470.001 a $510.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==8] &lt;-(510001 +560000 )/2 # [8]  \"De $510.001 a $560.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==9] &lt;-(560001 +610000 )/2 # [9]  \"De $560.001 a $610.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==10]&lt;-(610001 +670000 )/2 # [10] \"De $610.001 a $670.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==11]&lt;-(670001 +730000 )/2 # [11] \"De $670.001 a $730.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==12]&lt;-(730001 +800000 )/2 # [12] \"De $730.001 a $800.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==13]&lt;-(800001 +890000 )/2 # [13] \"De $800.001 a $890.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==14]&lt;-(890001 +980000 )/2 # [14] \"De $890.001 a $980.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==15]&lt;-(980001 +1100000)/2 # [15] \"De $980.001 a $1.100.000 mensuales liquidos\"      \nelsoc$inghogar_t[elsoc$inghogar_t==16]&lt;-(1100001+1260000)/2 # [16] \"De $1.100.001 a $1.260.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==17]&lt;-(1260001+1490000)/2 # [17] \"De $1.260.001 a $1.490.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==18]&lt;-(1490001+1850000)/2 # [18] \"De $1.490.001 a $1.850.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==19]&lt;-(1850001+2700000)/2 # [19] \"De $1.850.001 a $2.700.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==20]&lt;-(2700000)           # [20] \"Mas de $2.700.000 a mensuales liquidos\"\n\ny luego imputar este valor medio a los casos NA\n\nelsoc$inghogar_i &lt;- ifelse(test = (is.na(elsoc$inghogar)), #¿existen NA en ingresos?\n                           yes = elsoc$inghogar_t,         #VERDADERO, remplazar con la media del tramo\n                           no = elsoc$inghogar)            #FALSE, mantener la variable original.\n\nelsoc$inghogar_i &lt;- set_label(elsoc$inghogar_i,\"Ingreso total del hogar (imputada)\")\n\n\nelsoc$ing_pcap &lt;- elsoc$inghogar_i/elsoc$tamhogar\nelsoc$ing_pcap &lt;- set_label(elsoc$ing_pcap,\"Ingreso per cápita del hogar\")\n\n\nelsoc$quintile&lt;- dplyr::ntile(x = elsoc$ing_pcap,\n                              n = 5) # n de categorias, para quintiles usamos 5 \nelsoc$quintile &lt;- factor(elsoc$quintile,c(1,2,3,4,5), c(\"Quintil 1\",\"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\")) \nelsoc %&gt;% \n  group_by(quintile) %&gt;% \n  summarise(n=n(),\n            Media=mean(ing_pcap,na.rm = T),\n            Mediana=median(ing_pcap,na.rm = T)) %&gt;% \n  knitr::kable()\n\n\n\n\nquintile\nn\nMedia\nMediana\n\n\n\n\nQuintil 1\n711\n62859.09\n66666.67\n\n\nQuintil 2\n711\n112218.97\n111250.12\n\n\nQuintil 3\n710\n167748.23\n166666.67\n\n\nQuintil 4\n710\n262710.27\n250000.50\n\n\nQuintil 5\n710\n710246.41\n500000.00\n\n\nNA\n196\nNaN\nNA\n\n\n\n\n\n\nelsoc$quintilemiss &lt;- factor(elsoc$quintile,ordered = T)\nelsoc$quintilemiss &lt;- ifelse(test=is.na(elsoc$quintilemiss),yes = 6,no = elsoc$quintilemiss)\nelsoc$quintilemiss &lt;- factor(elsoc$quintilemiss ,levels = c(1,2,3,4,5,6),labels =  c(\"Quintil 1\",\"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Missing\")) \nelsoc %&gt;% group_by(quintilemiss) %&gt;% summarise(n=n())\n\n# A tibble: 6 × 2\n  quintilemiss     n\n  &lt;fct&gt;        &lt;int&gt;\n1 Quintil 1      711\n2 Quintil 2      711\n3 Quintil 3      710\n4 Quintil 4      710\n5 Quintil 5      710\n6 Missing        196"
  },
  {
    "objectID": "resource/07-resource.html#variables-dummy",
    "href": "resource/07-resource.html#variables-dummy",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Variables dummy",
    "text": "Variables dummy\nUna forma de pasar una variable categórica a dummies es con la función dummy_cols del paquete fastDummies\n\nelsoc &lt;- dummy_cols(elsoc, select_columns = \"quintilemiss\")\nhead(elsoc[,16:22])\n\n  quintilemiss quintilemiss_Quintil 1 quintilemiss_Quintil 2\n1    Quintil 1                      1                      0\n2    Quintil 5                      0                      0\n3    Quintil 1                      1                      0\n4    Quintil 5                      0                      0\n5      Missing                      0                      0\n6    Quintil 3                      0                      0\n  quintilemiss_Quintil 3 quintilemiss_Quintil 4 quintilemiss_Quintil 5\n1                      0                      0                      0\n2                      0                      0                      1\n3                      0                      0                      0\n4                      0                      0                      1\n5                      0                      0                      0\n6                      1                      0                      0\n  quintilemiss_Missing\n1                    0\n2                    0\n3                    0\n4                    0\n5                    1\n6                    0\n\n\n¿cómo hacerlo para una variable numérica?\nTambién existen muchas formas, como por ejemplo establecer como punto de corte la media o la mediana, o ver la distribución de las respuestas y tratar de establecer una distribución homogénea entre las dos nuevas categorías.\nSi recordamos la distribución de nuestra variable dependiente antes de construir el índice de participación:\n\nplot_stackfrq(elsoc[,c(\"part01\",\"part02\",\"part03\",\"part04\")]) + theme(legend.position=\"bottom\")\n\n\n\n\ny luego en el índice de participación\n\nsummary(elsoc$partpol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  4.000   4.000   4.000   5.473   6.000  20.000       8 \n\n\nPodemos notar que la mayoría de las respuestas se agrupan en la categoría “nunca” de las variables por separado y luego en el índice la mediana también corresponde al valor mínimo posible de “4” que es la suma de todas las personas que nunca han participado en ninguna de las opciones. Por lo tanto, tenemos dos criterios que nos permiten decidir que nuestra variable dependiente puede ser considera como dummy bajo los valores 0=nunca ha participado; y 1=si ha participado.\nUna forma de hacer esta agrupación de valores es con la función case_when del paquete dplyr (similar a ifelse)\n\nelsoc &lt;- elsoc %&gt;% rowwise() %&gt;%  mutate(partpol_dummy = case_when(partpol==4~0,\n                                                                   partpol&gt;4~1,\n                                                                   TRUE ~ NA))\ntable(elsoc$partpol_dummy)\n\n\n   0    1 \n2074 1666"
  },
  {
    "objectID": "resource/07-resource.html#objetivo",
    "href": "resource/07-resource.html#objetivo",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Objetivo",
    "text": "Objetivo\nEn el ejemplo de esta práctica, que utiliza solo casos para Chile entre 2005 y 2022, se intentará responder la pregunta ¿existe una relación entre la afiliación a sindicatos y la participación en marchas?\nDebido a la naturaleza de la variable dependiente participación en marchas (si/no), el objetivo de esta práctica es estimar modelos de regresión logística binaria."
  },
  {
    "objectID": "resource/07-resource.html#explorar-datos-1",
    "href": "resource/07-resource.html#explorar-datos-1",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Explorar datos",
    "text": "Explorar datos\n\nsummary(WVS_2005_2022_Chl) #con comando de paquete haven\n\n   Unionized      demonstr_dummy   petition_dummy       Wave    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Wave 5:373  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   Wave 6:516  \n Median :0.0000   Median :0.0000   Median :0.0000   Wave 7:568  \n Mean   :0.1984   Mean   :0.2073   Mean   :0.1846               \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000               \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000               \n                                                                \n           pol_pos     pol_pos_left    politicization civic_involvement\n left          :360   Min.   :0.0000   Min.   :0.00   Min.   :0.0000   \n center        :509   1st Qu.:0.0000   1st Qu.:1.00   1st Qu.:0.0000   \n right         :215   Median :0.0000   Median :2.00   Median :0.0000   \n Not identified:  0   Mean   :0.2471   Mean   :1.95   Mean   :0.6905   \n NA's          :373   3rd Qu.:0.0000   3rd Qu.:3.00   3rd Qu.:1.0000   \n                      Max.   :1.0000   Max.   :6.00   Max.   :3.0000   \n                                                                       \n      X003       age         Female       Educ    private_sector  \n Min.   :18.00   1:128   Min.   :0.0000   1:123   Min.   :0.0000  \n 1st Qu.:31.00   2:341   1st Qu.:0.0000   2:924   1st Qu.:1.0000  \n Median :41.00   3:400   Median :0.0000   3:410   Median :1.0000  \n Mean   :41.44   4:352   Mean   :0.4084           Mean   :0.8593  \n 3rd Qu.:50.00   5:188   3rd Qu.:1.0000           3rd Qu.:1.0000  \n Max.   :80.00   6: 48   Max.   :1.0000           Max.   :1.0000  \n                                                                  \n    gvt_resp         tax_rich        unempl_aid      state_inc_eq   \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.000  \n 1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000  \n Median : 6.000   Median : 7.000   Median : 7.000   Median : 7.000  \n Mean   : 6.457   Mean   : 6.446   Mean   : 7.103   Mean   : 6.689  \n 3rd Qu.: 9.000   3rd Qu.: 9.000   3rd Qu.:10.000   3rd Qu.: 9.000  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.000  \n NA's   :16       NA's   :87       NA's   :62       NA's   :439     \n\ndescribe(WVS_2005_2022_Chl) #con comando de paquete psych\n\n                  vars    n  mean    sd median trimmed   mad min max range\nUnionized            1 1457  0.20  0.40      0    0.12  0.00   0   1     1\ndemonstr_dummy       2 1457  0.21  0.41      0    0.13  0.00   0   1     1\npetition_dummy       3 1457  0.18  0.39      0    0.11  0.00   0   1     1\nWave*                4 1457  2.13  0.79      2    2.17  1.48   1   3     2\npol_pos*             5 1084  1.87  0.72      2    1.83  1.48   1   3     2\npol_pos_left         6 1457  0.25  0.43      0    0.18  0.00   0   1     1\npoliticization       7 1457  1.95  1.61      2    1.81  1.48   0   6     6\ncivic_involvement    8 1457  0.69  0.98      0    0.49  0.00   0   3     3\nX003                 9 1457 41.44 12.25     41   41.13 13.34  18  80    62\nage*                10 1457  3.19  1.27      3    3.18  1.48   1   6     5\nFemale              11 1457  0.41  0.49      0    0.39  0.00   0   1     1\nEduc*               12 1457  2.20  0.57      2    2.23  0.00   1   3     2\nprivate_sector      13 1457  0.86  0.35      1    0.95  0.00   0   1     1\ngvt_resp            14 1441  6.46  2.58      6    6.61  2.97   1  10     9\ntax_rich            15 1370  6.45  2.72      7    6.64  2.97   1  10     9\nunempl_aid          16 1395  7.10  2.53      7    7.37  2.97   1  10     9\nstate_inc_eq        17 1018  6.69  2.60      7    6.90  2.97   1  10     9\n                   skew kurtosis   se\nUnionized          1.51     0.28 0.01\ndemonstr_dummy     1.44     0.08 0.01\npetition_dummy     1.62     0.64 0.01\nWave*             -0.24    -1.37 0.02\npol_pos*           0.20    -1.04 0.02\npol_pos_left       1.17    -0.63 0.01\npoliticization     0.56    -0.43 0.04\ncivic_involvement  1.31     0.51 0.03\nX003               0.21    -0.63 0.32\nage*               0.15    -0.66 0.03\nFemale             0.37    -1.86 0.01\nEduc*             -0.02    -0.28 0.01\nprivate_sector    -2.06     2.26 0.01\ngvt_resp          -0.32    -0.71 0.07\ntax_rich          -0.34    -0.81 0.07\nunempl_aid        -0.62    -0.43 0.07\nstate_inc_eq      -0.40    -0.61 0.08"
  },
  {
    "objectID": "resource/07-resource.html#tabla-de-contingencia-bivariado-sindicalización-participación-en-marchas",
    "href": "resource/07-resource.html#tabla-de-contingencia-bivariado-sindicalización-participación-en-marchas",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Tabla de contingencia bivariado: sindicalización / participación en marchas",
    "text": "Tabla de contingencia bivariado: sindicalización / participación en marchas\n\nWVS_2005_2022_Chl &lt;- WVS_2005_2022_Chl %&gt;%\n  mutate(Unionized = labelled(.$Unionized,c(\"No\"=0,\"Sí\"=1)),\n         demonstr_dummy = labelled(.$demonstr_dummy,c(\"No\"=0,\"Sí\"=1)))\n\nWVS_2005_2022_Chl &lt;- as.data.frame(WVS_2005_2022_Chl) #para que la base quede como data frame (necesario para las figuras)\n\nfrq(WVS_2005_2022_Chl$Unionized)\n\nx &lt;numeric&gt; \n# total N=1457 valid N=1457 mean=0.20 sd=0.40\n\nValue | Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------\n    0 |    No | 1168 | 80.16 |   80.16 |  80.16\n    1 |    Sí |  289 | 19.84 |   19.84 | 100.00\n &lt;NA&gt; |  &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(WVS_2005_2022_Chl$demonstr_dummy)\n\nx &lt;integer&gt; \n# total N=1457 valid N=1457 mean=0.21 sd=0.41\n\nValue | Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------\n    0 |    No | 1155 | 79.27 |   79.27 |  79.27\n    1 |    Sí |  302 | 20.73 |   20.73 | 100.00\n &lt;NA&gt; |  &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjPlot::tab_xtab(var.col = WVS_2005_2022_Chl$Unionized, \n                 var.row = WVS_2005_2022_Chl$demonstr_dummy, \n                 title = \"Participación en marchas según afiliación sindical\", \n                 show.col.prc = TRUE,\n                 value.labels = TRUE,\n                 encoding = \"UTF-8\")\n\nWarning: `valueLables` needs to be a `list`-object.\n\n\n\n\nParticipación en marchas según afiliación sindical\n \n demonstr_dummy\n Unionized\n Total\n \n \n\n No\n Sí\n \n \n \nNo\n94180.6 %\n21474 %\n115579.3 % \n\n \n \nSí\n22719.4 %\n7526 %\n30220.7 % \n\n \n \nTotal\n1168100 %\n289100 %\n1457100 % \n\nχ2=5.598 · df=1 · φ=0.064 · p=0.018 \n\n \n\n\n\n\nOdds\n\\[Odds_{participar} = \\frac{0.207}{0.793} = 0.26\\]\nLas chances de participar en una marcha son de 0,26, respecto a las chances de no participar\n\nEn otras palabras: por cada 1 persona, hay sólo 0,26 personas que participan en marchas.\nO más intuitivamente, por cada 100 personas, hay sólo 26 personas que participan\n\n¿Cambian las chances de participar según se esté afiliado/a a un sindicato\n\\[Odds_{sindical} = \\frac{0.26}{0.74} = 0.35\\]\n\\[Odds_{no.sindical} = \\frac{0.194}{0.806} = 0.24\\]\n¿Cómo se interpretan los odds?\n\nValores bajo 1 indican que las chances de que ocurra un evento son negativas\nValores iguales a 1 indican chances iguales\nValores sobre 1 indican chances positivas\n\n\n\nOdds ratios (razones de chances)\n\nCálculo que permite reflejar asociación entre dos variables dicotómicas, a partir de una comparación entre chances\nSiguiendo con el ejemplo anterior, ¿tienen los/as sindicalizados más chances de participar en marchas que quienes no están sindicalizados/as?\n\n\\[OR = \\frac{P_{sindical}/(1-P_{sindical})}{P_{no.sindical}/(1-P_{no.sindical})}\\]\n\\[OR = \\frac{0.26/0.74}{0.194/0.806} = \\frac{0.35}{0.24} = 1.46\\]\nLas chances de participar en marchas de los/as sindicalizados/as son 1,5 veces más que las de quienes no están sindicalizados/as\n\nImplicancias:\n\nEl odds ratio o razones de chances es útil porque nos permite expresar en un número la relación entre dos variables categóricas\nEn las regresiones logísticas, el odds ratio es la primera manera de aproximarnos a relación entre variables\nSin embargo, falta un paso más necesario para construir modelos de regresión logística"
  },
  {
    "objectID": "resource/07-resource.html#logit",
    "href": "resource/07-resource.html#logit",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Logit",
    "text": "Logit\n\nEs una unidad de medida de la relación entre dos variables (VD: dicotómica), que en regresión logística se calcula a partir del logaritmo natural de los odds\nEsta transformación logarítmica es la base de la estimación de parámetros en la regresión logística:\n\nLa mejor combinación lineal de predictores no se obtiene a través de MCO, sino a través del procedimiento de máxima verosimilitud\n\nA diferencia de los odds ratio, los coeficientes logit tienen valores que van de –a +"
  },
  {
    "objectID": "resource/07-resource.html#modelo-de-probabilidad-lineal",
    "href": "resource/07-resource.html#modelo-de-probabilidad-lineal",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Modelo de probabilidad lineal",
    "text": "Modelo de probabilidad lineal\nPrimero, solo para comparación, estimamos un modelo de probabilidad lineal.\n\nm1mpl &lt;- lm(demonstr_dummy ~ Unionized + Wave, data = WVS_2005_2022_Chl)\n\nhtmlreg(m1mpl,\n          custom.model.names = \"Modelo de Prob Lineal\",\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo de Prob Lineal\n\n\n\n\n\n\n(Intercept)\n\n\n0.167***\n\n\n\n\n \n\n\n(0.022)\n\n\n\n\nUnionized\n\n\n0.072**\n\n\n\n\n \n\n\n(0.027)\n\n\n\n\nWaveWave 6\n\n\n0.079**\n\n\n\n\n \n\n\n(0.027)\n\n\n\n\nWaveWave 7\n\n\n-0.005\n\n\n\n\n \n\n\n(0.027)\n\n\n\n\nR2\n\n\n0.013\n\n\n\n\nAdj. R2\n\n\n0.011\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1"
  },
  {
    "objectID": "resource/07-resource.html#modelo-de-regresión-logística",
    "href": "resource/07-resource.html#modelo-de-regresión-logística",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Modelo de regresión logística",
    "text": "Modelo de regresión logística\n\nm0log &lt;- glm(demonstr_dummy~ Unionized, data = WVS_2005_2022_Chl, family = \"binomial\"(link = \"logit\"))\nm1log &lt;- glm(demonstr_dummy~ Unionized + Wave, data = WVS_2005_2022_Chl, family = \"binomial\"(link = \"logit\"))\n#nota: \"logit\" viene por defecto en la opción \"binomial\", por eso no es necesario \n#incluirla explícitamente en el código (tal como lo hago en los modelos sgtes)\nm2log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector + Wave, data = WVS_2005_2022_Chl,family = \"binomial\")\nm3log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector + politicization + Wave, data = WVS_2005_2022_Chl,family = \"binomial\")\n\nhtmlreg(list(m1mpl, m1log,m2log,m3log),\n          custom.model.names = c(\"M1 (m prob lineal)\",\"M1 (log odds)\",\"M2 (log odds)\",\"M3 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nM1 (m prob lineal)\n\n\nM1 (log odds)\n\n\nM2 (log odds)\n\n\nM3 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n0.167***\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n\n\n \n\n\n(0.022)\n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n\n\nUnionized\n\n\n0.072**\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n\n\n \n\n\n(0.027)\n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n0.079**\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n\n\n \n\n\n(0.027)\n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.005\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n\n\n \n\n\n(0.027)\n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n \n\n\n0.282***\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n\n\nR2\n\n\n0.013\n\n\n \n\n\n \n\n\n \n\n\n\n\nAdj. R2\n\n\n0.011\n\n\n \n\n\n \n\n\n \n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\nAIC\n\n\n \n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n\n\nBIC\n\n\n \n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n\n\nLog Likelihood\n\n\n \n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n\n\nDeviance\n\n\n \n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\nEn el Modelo 1 (M1), el log-odds de participación en marchas para afiliados a sindicatos aumenta en 0.418 en comparación con los no sindicalizados (p&lt;0.01). Este resultado mantiene su significación estadística en el Modelo 2 y baja su significación a p&lt;0.1 en el Modelo 3, al controlar por las demás variables independientes.\nEn el Modelo 2, En comparación a los/as trabajadores/as del sector público (categoría de referencia), el log-odds de participación en marchas para los/as del sector privado disminuye en 0,52 (p &lt; 0,01), manteniendo el resto de variables constantes.\nEn el Modelo 3, por cada unidad de aumento en la escala de politización, el log-odds de participación en marchas aumenta en 0,28 (p &lt; 0,001), manteniendo el resto de las variables constantes.\n\nProblemas de interpretación\nA pesar de sus ventajas, los coeficientes logit son difíciles de interpretar:\n\nLos coef. logit son el resultado de una transformación de la escala original\nEllos no muestran directamente probabilidades\nEntonces: Volver a la escala original de odds ratio mediante la exponenciación de los coeficientes (la función exponencial es la inversa del logaritmo)\n\n\\[logit_x = log(odds)\\]\n\\[e^{logit} = odds_x\\]\n\\[e^{0.39} = odds_x = 1.477\\]\nLas chances (odds) de participar en marchas de los/as sindicalizados/as son 1,5 veces más que las de quienes no están sindicalizados/as, controlando por las otras variables incluidas en el modelo"
  },
  {
    "objectID": "resource/07-resource.html#estimación-de-odds-ratios",
    "href": "resource/07-resource.html#estimación-de-odds-ratios",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Estimación de odds ratios",
    "text": "Estimación de odds ratios\n\nexp(coef(m1log)) #comando básico\n\n(Intercept)   Unionized  WaveWave 6  WaveWave 7 \n  0.2016888   1.5185264   1.5996549   0.9694021 \n\n### Cálculo de OR para cada modelo\nm0log_OR &lt;- exp(coef(m0log))\nm1log_OR &lt;- exp(coef(m1log))\nm2log_OR &lt;- exp(coef(m2log))\nm3log_OR &lt;- exp(coef(m3log))\n\n##Odds ratios en tabla de texreg\nhtmlreg(list(m1log,m2log,m3log), \n          override.coef = list(m1log_OR,m2log_OR,m3log_OR), # Sobreescribir coeficientes\n          custom.model.names = c(\"m1 (OR)\",\"m2 (OR)\",\"m3 (OR)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nm1 (OR)\n\n\nm2 (OR)\n\n\nm3 (OR)\n\n\n\n\n\n\n(Intercept)\n\n\n0.202***\n\n\n0.359*\n\n\n0.252**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n\n\nUnionized\n\n\n1.519**\n\n\n1.477*\n\n\n1.366†\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n1.600**\n\n\n1.646**\n\n\n1.642**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n0.969\n\n\n0.903\n\n\n0.886\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n0.980\n\n\n1.106\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n0.993\n\n\n0.988*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n1.042\n\n\n0.949\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n1.684†\n\n\n1.296\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n0.597**\n\n\n0.641*\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n1.326***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\n#Nota: errores estándares en esta tabla NO tienen  sentido (no están calculados a partir de OR, sino de log odds)\n#Es mejor no reportarlos si solo se van a presentar odds ratios\nSin embargo, los coeficientes de un modelo de reg. logística (log-odds u odds-ratios) no son comparables con los coeficientes de otro modelo"
  },
  {
    "objectID": "resource/07-resource.html#cálculo-de-probabilidades-predichas",
    "href": "resource/07-resource.html#cálculo-de-probabilidades-predichas",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Cálculo de probabilidades predichas",
    "text": "Cálculo de probabilidades predichas\n# Tabla básica: sólo sindicalizacion como vble independ\nhtmlreg(m0log,\n          custom.model.names = c(\"m0 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nm0 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.422***\n\n\n\n\n \n\n\n(0.074)\n\n\n\n\nUnionized\n\n\n0.374*\n\n\n\n\n \n\n\n(0.153)\n\n\n\n\nAIC\n\n\n1485.340\n\n\n\n\nBIC\n\n\n1495.908\n\n\n\n\nLog Likelihood\n\n\n-740.670\n\n\n\n\nDeviance\n\n\n1481.340\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\nA partir de este modelo se pueden predecir log-odds y, más importante aún, probabilidades para personas con distintos atributos controlados en el modelo (ej., sindicalizadas o no)\n\\[logit(prob.marcha) = 𝛼+ 𝛽_1X_1 \\]\n\\[logit(prob.marcha)_{sindical} = -1.422 + (0.374 * Unionized=1) = -1.048 \\]\n\\[logit(prob.marcha)_{no.sindical} = -1.422 + (0.374 * Unionized=0) = -1.422 \\]\nEste “puntaje predicho” (log-odds) no tiene interpretación, por lo que hay que pasarlo a Odds\n\\[Odds_x = e^{𝛼+𝛽_jX_j}\\]\n\\[Odds_{sindicalizados} = e^{-1.048} = 0.35\\]\n\\[Odds_{no.sindicalizados} = e^{-1.422} = 0.24\\]\nFinalmente, habiendo calculado los odds para cada tipo de persona se pueden calcular sus probabilidades predichas\n\\[p = \\frac{e^{𝛼+𝛽_jX_j}}{1+e^{𝛼+𝛽_jX_j}} = \\frac{odds_{xj}}{1+odds_{xj}}\\]\n\\[p_{sindicalizados} = \\frac{0.35}{1+0.35} = \\frac{0.35}{1.35} = 0.26\\]\n\\[p_{no.sindicalizados} = \\frac{0.24}{1+0.24} = \\frac{0.24}{1.24} = 0.19\\]\nLa probabilidad de que un/a sindicalizado participe en marchas es del 26%, mientras que la probabilidad de que alguien que no esté sindicalizado/a es del 19%"
  },
  {
    "objectID": "resource/07-resource.html#cálculo-de-probabilidades-predichas-en-r",
    "href": "resource/07-resource.html#cálculo-de-probabilidades-predichas-en-r",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Cálculo de probabilidades predichas en R",
    "text": "Cálculo de probabilidades predichas en R\n\nPaquete ggeffects de R: últil para estimar probabilidades predichas a partir de modelos de regresión logísticas\nCombinado con ggplot2, se pueden generar gráficos que muestran de modo más intuitivo la relación entre variables\n\nGráfico de probabilidades predichas para sindicalizados/as y no sindicalizados/as\n\nFigSind_1_Prob &lt;- ggeffects::ggpredict(m3log, terms = c(\"Unionized\")) %&gt;%\n  ggplot(aes(x=x, y=predicted)) +\n  geom_bar(stat=\"identity\", color=\"grey\", fill=\"grey\")+\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width=.1) +\n  labs(title=\"Sindicalización\", x = \"\", y = \"\") +\n  theme_bw() +\n  theme(plot.title = element_text(size = 12), \n        axis.text.x = element_text(angle = 0, vjust = 0.5, size = 12),\n        axis.text.y = element_text(vjust = 0.5, size = 10)) +\n  scale_x_continuous(name = \"\",\n                     breaks = c(0,1),\n                     labels = c(\"Non-union members\", \"Union members\")) +\n  scale_y_continuous(limits = c(0,0.35), \n                     breaks = seq(0,0.35, by = 0.05),\n                     labels = scales::percent_format(accuracy = 1L))\n\nFigSind_1_Prob\n\n\n\n\nGráfico de probabilidades predichas para variable politización\n\nFigPolit_1_Prob&lt;- ggeffects::ggpredict(m3log, terms=\"politicization\") %&gt;%\n  ggplot(mapping=aes(x = x, y=predicted)) +\n  labs(title=\"Politización\", x = \"\", y = \"\")+\n  theme_bw() +\n  geom_smooth()+\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, fill = \"black\") +\n  theme(plot.title = element_text(size = 12), \n        axis.text.x = element_text(angle = 0, vjust = 0.5, size = 10),\n        axis.text.y = element_text(vjust = 0.5, size = 10))+\n  scale_x_continuous(breaks = seq(0,6, by = 1))+\n  scale_y_continuous(limits = c(0,0.6), breaks=seq(0,0.6, by = 0.1),\n                     labels = scales::percent_format(accuracy = 1L))\n\nFigPolit_1_Prob\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "resource/07-resource.html#bondad-de-ajuste-comando-de-paquete-lmtest",
    "href": "resource/07-resource.html#bondad-de-ajuste-comando-de-paquete-lmtest",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Bondad de ajuste (comando de paquete lmtest)",
    "text": "Bondad de ajuste (comando de paquete lmtest)\n\nRazón de verosimilitudes\n\n\nanova(m1log, m2log, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: demonstr_dummy ~ Unionized + Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      1453     1467.9                          \n2      1448     1442.1  5   25.828 9.635e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(m2log, m3log, test = \"Chisq\") \n\nAnalysis of Deviance Table\n\nModel 1: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    politicization + Wave\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      1448     1442.1                          \n2      1447     1395.8  1    46.21 1.063e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(m1log, m2log) #likelihood ratio test / Prueba de razón de verosimilitud (comparación m1-m2)\n\nLikelihood ratio test\n\nModel 1: demonstr_dummy ~ Unionized + Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 -733.94                         \n2   9 -721.03  5 25.828  9.635e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(m2log, m3log) #likelihood ratio test / Prueba de razón de verosimilitud (comparación m2-m3)\n\nLikelihood ratio test\n\nModel 1: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    politicization + Wave\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)    \n1   9 -721.03                        \n2  10 -697.92  1 46.21  1.063e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nPseudo R2 (McFadden)\n\n\nm1log_R2&lt;-DescTools::PseudoR2(m1log)\nm2log_R2&lt;-DescTools::PseudoR2(m2log)\nm3log_R2&lt;-DescTools::PseudoR2(m3log)\n\n#Misma tabla, en log odds, con Pseudo R2\nhtmlreg(list(m1log,m2log,m3log),\n          custom.model.names = c(\"m1 (log odds)\",\"m2 (log odds)\",\"m3 (log odds)\"),\n          custom.gof.rows=list(\"Pseudo R2\" = c(m1log_R2, m2log_R2,m3log_R2)),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nm1 (log odds)\n\n\nm2 (log odds)\n\n\nm3 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n\n\nUnionized\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n0.282***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n\n\nPseudo R2\n\n\n0.013\n\n\n0.030\n\n\n0.061\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1"
  },
  {
    "objectID": "resource/07-resource.html#efectos-de-interacción",
    "href": "resource/07-resource.html#efectos-de-interacción",
    "title": "Práctica 6 Correlación y regresión",
    "section": "Efectos de interacción",
    "text": "Efectos de interacción\nsindicalizacion - sector privado\n\nm3.1log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector + politicization + Wave + Unionized*private_sector, \n               data = WVS_2005_2022_Chl,family = \"binomial\")\n\nhtmlreg(list(m1log,m2log,m3log,m3.1log),\n          custom.model.names = c(\"M1 (log odds)\",\"M2 (log odds)\",\"M3 (log odds)\",\n                                 \"M3.1 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nM1 (log odds)\n\n\nM2 (log odds)\n\n\nM3 (log odds)\n\n\nM3.1 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n-1.452**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n(0.447)\n\n\n\n\nUnionized\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n0.569\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n(0.353)\n\n\n\n\nWaveWave 6\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n0.496**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n-0.122\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n0.094\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n(0.140)\n\n\n\n\nX003\n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n-0.044\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n0.259\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n-0.360†\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n(0.210)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n0.282***\n\n\n0.281***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n(0.042)\n\n\n\n\nUnionized:private_sector\n\n\n \n\n\n \n\n\n \n\n\n-0.324\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.397)\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n1417.185\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n1475.310\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n-697.592\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n1395.185\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\n\nLa interacción también se puede graficar según probabilidades predichas\n\n\n# ojo que la relación sindicalización x sector privado no es significativa\nFigSindSector_int&lt;-ggeffects::ggpredict(m3.1log, terms = c(\"Unionized\", \"private_sector\")) %&gt;%\n  ggplot(aes(x=x, y=predicted, shape = group, color = group)) +\n  geom_line(aes(group=group,linetype = group),position = position_dodge(.1)) + \n  geom_point(size = 2.5,position = position_dodge(.1))+\n  scale_x_continuous(name = \"\", breaks=c(0,1), labels = c(\"No sindicalizados/as\", \"Sindicalizados/as\")) + \n  scale_shape_discrete(name = \"Sector de empleo\",\n                       limits = c(\"0\", \"1\"),\n                       labels = c(\"Público\", \"Privado\")) +\n  scale_color_manual(name = \"Sector de empleo\",\n                     limits = c(\"0\", \"1\"),\n                     labels = c(\"Público\", \"Privado\"),\n                     values = c(\"black\", \"black\")) +\n  scale_linetype_manual(name = \"Sector de empleo\",\n                        limits = c(\"0\", \"1\"),\n                        labels = c(\"Público\", \"Privado\"),\n                        values = c(\"solid\", \"dashed\")) +\n  scale_y_continuous(limits = c(0,0.40), breaks=seq(0,0.40, by = 0.05),\n                     labels = scales::percent_format(accuracy = 1L)) +\n  theme_bw() +\n  labs(title=\"\", y = \"\") + \n  theme(plot.title = element_text(size = 11),\n        axis.text=element_text(size=11))\n\nFigSindSector_int\n\n\n\n\n\nSector de empleo - politización\n\n\nm3.2log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector \n               + politicization + Wave + private_sector*politicization,\n               data = WVS_2005_2022_Chl,family = \"binomial\")\n\nhtmlreg(list(m1log,m2log,m3log,m3.1log,m3.2log),\n          custom.model.names = c(\"M1 (log odds)\",\"M2 (log odds)\",\"M3 (log odds)\",\n                                 \"M3.1 (log odds)\",\"M3.2 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nM1 (log odds)\n\n\nM2 (log odds)\n\n\nM3 (log odds)\n\n\nM3.1 (log odds)\n\n\nM3.2 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n-1.452**\n\n\n-1.416**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n(0.447)\n\n\n(0.480)\n\n\n\n\nUnionized\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n0.569\n\n\n0.310†\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n(0.353)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n0.496**\n\n\n0.495**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n(0.174)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n-0.122\n\n\n-0.122\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n(0.184)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n0.094\n\n\n0.100\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n(0.140)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n-0.012*\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n-0.044\n\n\n-0.053\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n(0.272)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n0.259\n\n\n0.258\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n(0.289)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n-0.360†\n\n\n-0.396\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n(0.210)\n\n\n(0.315)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n0.282***\n\n\n0.281***\n\n\n0.298**\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n(0.042)\n\n\n(0.093)\n\n\n\n\nUnionized:private_sector\n\n\n \n\n\n \n\n\n \n\n\n-0.324\n\n\n \n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.397)\n\n\n \n\n\n\n\nprivate_sector:politicization\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n-0.019\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.103)\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n1417.185\n\n\n1417.814\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n1475.310\n\n\n1475.939\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n-697.592\n\n\n-697.907\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n1395.185\n\n\n1395.814\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\n\nFigPolitSector_int&lt;-ggeffects::ggpredict(m3.2log, terms = c(\"politicization\", \"private_sector\")) %&gt;%\n  ggplot(aes(x=x, y=predicted, shape = group, color = group)) +\n  geom_line(aes(group=group,linetype = group),position = position_dodge(.1)) + \n  geom_point(size = 2.5,position = position_dodge(.1))+\n  scale_x_continuous(breaks=seq(0,6, by = 1), name = \"\") + \n  scale_shape_discrete(name = \"Sector de empleo\",\n                       limits = c(\"0\", \"1\"),\n                       labels = c(\"Público\", \"Privado\")) +\n  scale_color_manual(name = \"Sector de empleo\",\n                     limits = c(\"0\", \"1\"),\n                     labels = c(\"Público\", \"Privado\"),\n                     values = c(\"black\", \"black\")) +\n  scale_linetype_manual(name = \"Sector de empleo\",\n                        limits = c(\"0\", \"1\"),\n                        labels = c(\"Público\", \"Privado\"),\n                        values = c(\"solid\", \"dashed\")) +\n  scale_y_continuous(limits = c(0,0.8), breaks=seq(0,0.8, by = 0.1),\n                     labels = scales::percent_format(accuracy = 1L)) +\n  theme_bw() +\n  labs(title=\"\", y = \"\") + \n  theme(plot.title = element_text(size = 11),\n        axis.text=element_text(size=11))\nFigPolitSector_int"
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Instrucciones generales",
    "section": "",
    "text": "Los prácticos consisten en el desarrollo de una guía práctica (por lo general cada semana de clases) donde se aplican y profundizan los contenidos de las clases, y donde también se abordan otras temáticas relacionadas al manejo y repote de datos."
  },
  {
    "objectID": "resource/index.html#descripción",
    "href": "resource/index.html#descripción",
    "title": "Instrucciones generales",
    "section": "",
    "text": "Los prácticos consisten en el desarrollo de una guía práctica (por lo general cada semana de clases) donde se aplican y profundizan los contenidos de las clases, y donde también se abordan otras temáticas relacionadas al manejo y repote de datos."
  },
  {
    "objectID": "resource/index.html#trabajo-con-software-r",
    "href": "resource/index.html#trabajo-con-software-r",
    "title": "Instrucciones generales",
    "section": "Trabajo con software R",
    "text": "Trabajo con software R\nPara los análisis estadísticos de este curso usamos el programa R, en parte porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\ntrabajar con la misma y última versión de R, que es la 4.3 (Chequear con sessionInfo())\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables"
  },
  {
    "objectID": "resource/index.html#sobre-errores-y-consultas-respecto-a-problemas-con-r-y-ejecución-de-código",
    "href": "resource/index.html#sobre-errores-y-consultas-respecto-a-problemas-con-r-y-ejecución-de-código",
    "title": "Instrucciones generales",
    "section": "Sobre errores y consultas respecto a problemas con R y ejecución de código",
    "text": "Sobre errores y consultas respecto a problemas con R y ejecución de código\nEn caso de problemas con ejecución de código, se sugiere intentar solucionarlo autónomamente por no más de 10 minutos, si los problemas siguen entonces consultar.\nSe sugiere que las consultas sobre problemas en la ejecución del código y otros se realicen en los foros al final de los prácticos correspondientes, para lo cual se requiere solo habilitar una cuenta en Github. Al hacer la consulta, adjuntar la siguiente información:\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\nSobre el trabajo en hojas de código en RStudio\n\nEl trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File &gt; New File &gt; R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\nLos contenidos de las hojas de código son básicamente 2:\n\ncomandos o funciones: se escriben en la hoja, y para ejecutarlos se debe posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola.\ntexto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #\n\nPara grabar nuestra hoja de código y así respaldar nuestros análisis, File &gt; Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Daniela Olivares Collío\n   FACSO - sala 328\n   danielaolivarescollio@gmail.com\n   Schedule an appointment\n\n\n\n   Kevin Carrasco Quintanilla\n   FACSO - sala 328\n   kevin.carrasco@ug.uchile.cl\n   kevincarrascoq1\n\n\n\n\n\n   Viernes\n   Marzo – Julio, 2025\n   09:00-11:30 hrs.\n   Sala 334, FACSO"
  },
  {
    "objectID": "syllabus.html#resumen",
    "href": "syllabus.html#resumen",
    "title": "Programa",
    "section": "Resumen",
    "text": "Resumen\nEste curso busca dar acercamiento a la investigación social cuantitativa, abarcando el análisis e interpretación de modelos explicativos de investigación social. Asimismo, se busca que los y las estudiantes logren familiarizarse con el uso de Rstudio para el análisis de datos sociales.\nLa metodología incluye clases lectivas y trabajo práctico en R."
  },
  {
    "objectID": "syllabus.html#objetivo-general",
    "href": "syllabus.html#objetivo-general",
    "title": "Programa",
    "section": "Objetivo general",
    "text": "Objetivo general\nAl finalizar el curso, el/la estudiante podrá elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R."
  },
  {
    "objectID": "syllabus.html#objetivos-específicos",
    "href": "syllabus.html#objetivos-específicos",
    "title": "Programa",
    "section": "Objetivos específicos",
    "text": "Objetivos específicos\nAl concluir el curso lo/as estudiantes deberán haber alcanzado los siguientes resultados de aprendizaje:\n\nConocer las etapas de un diseño de investigación social cuantitativa y sus principales elementos.\nFormular diseños de investigación social cuantitativa.\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos.\nInterpretar y analizar los elementos centrales de una base de datos con información social.\nAplicar e interpretar técnicas de estadística descriptiva según las distintas características de los datos.\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para variables con distinta unidad de medida.\nAplicar e interpretar técnicas de regresión lineal y logística para variables numéricas y variables categóricas."
  },
  {
    "objectID": "syllabus.html#contenidos",
    "href": "syllabus.html#contenidos",
    "title": "Programa",
    "section": "Contenidos",
    "text": "Contenidos\n\nMódulo 1: Inferencia y estadística correlacional\n1.1. Inferencia estadística y asociación\n\nÁrea de una distribución, probabilidad en la curva normal, error tipo 1 y tipo 2\nIntervalos de confianza para medias y proporciones usando distribución Z\nConcepto de valor-p\nDistribución t de Student y grados de libertad\n\n1.2. Asociación entre dos variables cuantitativas\n\nConcepto de covarianza y relación/correlación lineal y no-lineal\nCorrelación de Pearson\n\n1.3. Asociación con variables categóricas\n\nTablas de contingencia y determinación de la asociación\nAsociación poblacional mediante chi-cuadrado\n\n\n\nMódulo 3: Regresión lineal y regresión logística\n3.1 Regresión lineal de mínimos cuadrados\n\nAspectos centrales y supuestos de la regresión MCO\nInterpretación de coeficientes (variables cuantitativas y cualitativas) y efectos de interacción\nRepresentación gráfica de coeficientes de regresión lineal\n\n3.2 Regresión logística binaria\n\nAspectos básicos de la regresión logística\nTipos de coeficientes e interpretación\nRepresentación gráfica (cálculo de probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nEl curso se organiza en sesiones semanales, con una parte lectiva seguida de una práctica. En la parte lectiva se transmiten y discuten los conceptos centrales de la investigación cuantitativa. En la parte práctica se aplicarán los conceptos transmitidos en la parte lectiva, además de resolver dudas en el avance de los trabajos de investigación."
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nModalidad:\nUn reporte de investigación en parejas con dos entregas.\nPonderaciones:\n\nPrimera entrega 40%\nSegunda entrega 60%"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7).\nRequisitos de presentación a exámen: Nota entre 3,5 y 4,9\n\nAcerca del plagio: Cualquier información vertida en documentos calificables, que no se indique su debida procedencia, conociéndose de autor externo, y/o cualquier similitud, se considera plagio, conducente a la rendición del examen final."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "Palabras Clave",
    "text": "Palabras Clave\n\nEstadística, investigación cuantitativa, manipulación de datos, visualización de datos, interpretación de coeficientes"
  },
  {
    "objectID": "syllabus.html#bibliografía",
    "href": "syllabus.html#bibliografía",
    "title": "Programa",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, Hadley & Grolemund, Garrett (2017). R for Data Science. Visualize, model, transform, tidy and import data. / Versión en español disponible acá\nMoore, D. S., & Comas, J. (2010). Estadística aplicada básica. Barcelona: Antoni Bosch.\nWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning.\nCamarero, et al (2017) Regresión Logística: Fundamentos y aplicación a la investigación sociológica.\nHair, Joseph F., et al. (2004). Análisis multivariante. 5ta ed. Madrid: Prentice Hall.\nCharte, Francisco (2014). Análisis exploratorio y Visualización de datos con R."
  },
  {
    "objectID": "syllabus.html#recursos-web",
    "href": "syllabus.html#recursos-web",
    "title": "Programa",
    "section": "Recursos web",
    "text": "Recursos web\n\nSitio web del curso\nDescarga de R y Rstudio\nR4DS en español"
  }
]