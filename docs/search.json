[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "La evaluación consistirá en la elaboración de reportes de investigación enfocados en reproducibilidad de la investigación social. La reproducibilidad es entendida como la posiblidad de regenerar de manera independiente los resultados de una investigación usando los mismos materiales originales de una investigación ya publicada (más información en lisa-coes.com)\nLos reportes serán elaborados en parejas. Cada pareja deberá elegir una de las siguientes investigaciones propuestas y seguir las instrucciones según cada evaluación:\n\n\n\nDisi Pavlic, Rodolfo (2018). Sentenced to Debt: Explaining Student Mobilization in Chile. Latin American Research Review 53(3), pp. 448-465, DOI: https://doi.org/10.25222/larr.395 : Análisis de las movilizaciones estudiantiles en Chile utilizando la Encuesta Nacional de Juventud del 2012 (paper en inglés)\nOrtiz-Inostroza, C., & Lopez, E. (2017). Explorando modelos estadísticos para explicar la participación en protestas en Chile. Revista de Sociología 32(1), 13-31. DOI: 10.5354/0719-529x.2017.47883 : Estudio de los factores individuales que influyen en la participación en protestas en Chile, con datos del informe de Desarrollo Humano de 2015 del PNUD.\nCereceda-Marambio, K., & Torres-Solís, A. (2017). Satisfacción con la democracia en Chile: De lo normativo a lo valorativo. Revista de Sociología 32(1), 32-49. doi: 10.5354/0719-529x.2017.47884 : estudio que intenta explicar y predecir la satisfacción con la democracia en Chile con datos del Latinobarómetro del 2015\nSepúlveda-Rodríguez, I., & Garrido-Vergara, L. (2022). Satisfacción con la democracia y legitimidad en Chile. Revista de Sociología, 37(2), 1–15. https://doi.org/10.5354/0719-529X.2022.69099 : Estudio que analiza los factores que influyen en la satisfacción en la democracia en Chile, con especial interés en la legitimidad y confianza en el régimen político. Utiliza datos del latinobarómetro del 2020\nOrtiz, Iván (2016). ACTITUDES DE LOS ESTUDIANTES EN ESCUELAS SEGREGADAS Y EN ESCUELAS INCLUSIVAS, HACIA LA TOLERANCIA SOCIAL Y LA CONVIVENCIA ENTRE PARES. CALIDAD EN LA EDUCACIÓN no 44, pp. 68-97 : Estudio que analiza actitudes tolerantes de los estudiantes, diferenciando por contexto escolar. Utiliza datos del International Civic and Citizenship Education Study (ICCS) del 2009.\n\n\n\n\nEs posible utilizar un estudio distinto a los propuestos y que se acerque a sus temas de interés, pero se deben guiar por estos criterios básicos y confirmar la elección con alguno de los profesores:\n\nDebe ser un estudio de carácter cuantitativo\nLa base de datos debe estar disponible online (gratis)\nDebe ser posible identificar los tres temas básicos del curso: 1) descripción y visualización de datos, 2) análisis bivariado y contraste de hipótesis y 3) explicación de modelos causales (regresión lineal y/o logística). Se deben evitar estudios que posean estrategias de análisis más complejas."
  },
  {
    "objectID": "trabajos.html#evaluación",
    "href": "trabajos.html#evaluación",
    "title": "Trabajos",
    "section": "",
    "text": "La evaluación consistirá en la elaboración de reportes de investigación enfocados en reproducibilidad de la investigación social. La reproducibilidad es entendida como la posiblidad de regenerar de manera independiente los resultados de una investigación usando los mismos materiales originales de una investigación ya publicada (más información en lisa-coes.com)\nLos reportes serán elaborados en parejas. Cada pareja deberá elegir una de las siguientes investigaciones propuestas y seguir las instrucciones según cada evaluación:\n\n\n\nDisi Pavlic, Rodolfo (2018). Sentenced to Debt: Explaining Student Mobilization in Chile. Latin American Research Review 53(3), pp. 448-465, DOI: https://doi.org/10.25222/larr.395 : Análisis de las movilizaciones estudiantiles en Chile utilizando la Encuesta Nacional de Juventud del 2012 (paper en inglés)\nOrtiz-Inostroza, C., & Lopez, E. (2017). Explorando modelos estadísticos para explicar la participación en protestas en Chile. Revista de Sociología 32(1), 13-31. DOI: 10.5354/0719-529x.2017.47883 : Estudio de los factores individuales que influyen en la participación en protestas en Chile, con datos del informe de Desarrollo Humano de 2015 del PNUD.\nCereceda-Marambio, K., & Torres-Solís, A. (2017). Satisfacción con la democracia en Chile: De lo normativo a lo valorativo. Revista de Sociología 32(1), 32-49. doi: 10.5354/0719-529x.2017.47884 : estudio que intenta explicar y predecir la satisfacción con la democracia en Chile con datos del Latinobarómetro del 2015\nSepúlveda-Rodríguez, I., & Garrido-Vergara, L. (2022). Satisfacción con la democracia y legitimidad en Chile. Revista de Sociología, 37(2), 1–15. https://doi.org/10.5354/0719-529X.2022.69099 : Estudio que analiza los factores que influyen en la satisfacción en la democracia en Chile, con especial interés en la legitimidad y confianza en el régimen político. Utiliza datos del latinobarómetro del 2020\nOrtiz, Iván (2016). ACTITUDES DE LOS ESTUDIANTES EN ESCUELAS SEGREGADAS Y EN ESCUELAS INCLUSIVAS, HACIA LA TOLERANCIA SOCIAL Y LA CONVIVENCIA ENTRE PARES. CALIDAD EN LA EDUCACIÓN no 44, pp. 68-97 : Estudio que analiza actitudes tolerantes de los estudiantes, diferenciando por contexto escolar. Utiliza datos del International Civic and Citizenship Education Study (ICCS) del 2009.\n\n\n\n\nEs posible utilizar un estudio distinto a los propuestos y que se acerque a sus temas de interés, pero se deben guiar por estos criterios básicos y confirmar la elección con alguno de los profesores:\n\nDebe ser un estudio de carácter cuantitativo\nLa base de datos debe estar disponible online (gratis)\nDebe ser posible identificar los tres temas básicos del curso: 1) descripción y visualización de datos, 2) análisis bivariado y contraste de hipótesis y 3) explicación de modelos causales (regresión lineal y/o logística). Se deben evitar estudios que posean estrategias de análisis más complejas."
  },
  {
    "objectID": "trabajos.html#reporte-1",
    "href": "trabajos.html#reporte-1",
    "title": "Trabajos",
    "section": "Reporte 1",
    "text": "Reporte 1\n\nSeleccionar una de las investigaciones propuestas\nDescargar la base de datos utilizada en la investigación\nOperacionalización: Manipulación de datos para obtener las mismas variables utilizadas en la investigación. Se espera que l-s estudiantes sean capaces de seleccionar las variables utilizadas en la investigación escogida, agruparlas, reordenarlas y asignarles los nombres y etiquetas según corresponda.\nVisualización de datos: Elaboración de tablas y/o gráficos, en el contexto de un reporte científico de investigación, que intente reproducir o profundizar los principales hallazgos de la investigación. Para esta primera entrega se espera que sean capaces de reproducir la tabla descriptiva que muestre las medidas de tendencia central de las variables utilizadas en la investigación, así como su contraparte de tablas de frecuencias en el caso de variables categóricas. También se espera que sean capaces de elaborar uno o dos gráficos univariados que permitan visualizar la distribución de las principales variables de interés.\nSi la investigación escogida no posee tablas o gráficos descriptivos, deberán elaborar de igual forma una tabla y uno o dos gráficos que permitan visualizar la operacionalización de las variables.\nNo es necesario elaborar un informe teórico sobre el tema de investigación. En la introducción del reporte deben mencionar la investigación que están reproduciendo y la fuente de datos utilizada. El objetivo del trabajo es que sean capaces de operacionalizar variables, escoger la mejor forma de visualizar sus medidas de tendencia central y/o frecuencias e interpretar estas tablas/gráficos.\n\nEntrega:\n\nViernes 21 de Abril a través de UCursos, sección tareas\nFormato Tradicional: archivo .pdf en tamaño carta o A4, letra Times New Roman, tamaño 12, interlineado 1,5, márgenes normales (2,5 cm superior e inferior, 3 cm derecho e izquierdo). Se considerará positivamente la entrega de reportes elaborados en RMarkdown\nNo más de 10 páginas\nincluir referencias de la literatura / bases de datos revisadas\natrasos, 0,5 por día de atraso.\n\nRúbrica de evaluación:\n\n\n\n\n\n\n\n\nÍtem\nObjetivo\nPuntaje\n\n\n\n\n1. Cargar base de datos\nL-s estudiantes son capaces de descargar la base de datos utilizada en la investigación y posteriormente cargarla en R\n2pts\n\n\n2. Selección de variables\nL-s estudiantes son capaces de seleccionar las variables utilizadas en la investigaciónn escogida\n2pts\n\n\n3. Operacionalización de variables\nL-s estudiantes son capaces de operacionalizar correctamente las variables de interés, obteniendo resultados similares a los de la investigación escogida. Las variables deben tener una correcta escala de medición (1pto), correcto paso a NA (1pto), correcto orden de medición (1pto) y etiquetas correctas (1pto)\n4pts\n\n\n4. Visualización de resultados\nL-s estudiantes son capaces de visualizar correctamente las variables de interés. Se espera que el reporte incluya una tabla descriptiva (2ptos) y uno o dos gráficos (2ptos)\n4ptos\n\n\n5. Interpretación de resultados\nL-s estudiantes son capaces de interpretar correctamente las tablas y gráficos presentados\n2pts\n\n\nTotal\n-\n14ptos"
  },
  {
    "objectID": "trabajos.html#entrega-final",
    "href": "trabajos.html#entrega-final",
    "title": "Trabajos",
    "section": "Entrega final",
    "text": "Entrega final\nLa entrega final del curso consiste en realizar un ejercicio de investigación que permita estimar e interpretar asociaciones entre variables (correlación) y causalidad (regresión) entre variables. Además, deben corregir errores y/o observaciones de la primera entrega.\nPara realizar este ejercicio se espera que l-s estudiantes planteen sus propias preguntas de investigación sobre un tema que sea de su interés o que continúen con el trabajo de reproducibilidad de la primera entrega. Ambas opciones son válidas, pero deben cumplir con los mismos criterios de la pauta de evaluación: 1) realizar operacionalización y descripción de variables; 2) reporte e interpretación de inferencia y correlación; 3) estimación, reporte e interpretación de regresión lineal y logística.\nPauta de evaluación:"
  },
  {
    "objectID": "trabajos.html#requisitos-de-aprobación",
    "href": "trabajos.html#requisitos-de-aprobación",
    "title": "Trabajos",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7)."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases teóricas y las actividades prácticas. Las clases se realizarán los días Viernes 09:00 a 10:50 en sala 329\n\nClases ( ): Lecturas, documentos de presentación y video (en caso que la sesión sea grabada)\nPrácticas y evaluaciones (): Actividades prácticas a desarrollar durante la semana.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Prácticas y evaluaciones\n Lecturas y material adicional\n\n\n\n\n Marzo \n\n\n\n\n\nViernes 17\n00. Presentación e 01. introducción\n1. Aproximación inicial a R\n- Leer detalladamente programa del curso\n\n\n\n\nUNIDAD 1: Estadística descriptiva\n\n\n\nViernes 24\n2.Operacionalización de variables \n2.Operacionalización de variables\n- Wickham & Grolemund, (2017). cap. 1 Introducción \n\n\nViernes 31\n3. Visualización de datos\n-\n- Wickham & Grolemund, (2017). cap. 2 Explorar\n\n\n Abril \n\n\n\n\n\nViernes 07\nViernes santo\n\n\n\n\nViernes 14\n1° semana presencial\n\n\n\n\nViernes 21\n\nEvaluación\n\n\n\n\n\n\nUNIDAD 2: Estadística Correlacional\n\n\n\nViernes 28\n4. Introducción a la inferencia estadística\n\n\n\n\n Mayo \n\n\n\n\n\nViernes 05\n1° semana de pausa reflexiva\n\n\n\n\nViernes 12\n5. Correlación\n\n\n\n\nViernes 19\n6. Índices y análisis factorial\n\n\n\n\nViernes 26\n2° semana presencial\n\n\n\n\n\n\n\nUNIDAD 3: Regresión lineal y regresión logística\n\n\n\n Junio \n\n\n\n\n\nViernes 02\n7. Regresión lineal de mínimos cuadrados\n\n\n\n\nViernes 09\n2° semana de pausa reflexiva\n\n\n\n\nViernes 16\n**8. Regresión logística binaria: interpretación de coeficientes y cálculo de probabilidades\n\n\n\n\nViernes 23\n10. Análisis factorial y regresión lineal en R\n\n\n\n\nViernes 30\n11. Supuestos de regresión y valores predichos\n\n\n\n\n Julio \n\n\n\n\n\nViernes 07\n3° semana presencial\n\n\n\n\nViernes 14\n\nEvaluación"
  },
  {
    "objectID": "resource/07-resource.html",
    "href": "resource/07-resource.html",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de repasar en la interpretación de coeficientes de correlación y la construcción de índices, así como también en la interpretación de coeficientes de regresión lineal y logística. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\nLa versión original de este ejercicio proviene del curso de Estadística multivariada versión 2022."
  },
  {
    "objectID": "resource/07-resource.html#explorar-datos",
    "href": "resource/07-resource.html#explorar-datos",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Explorar datos",
    "text": "Explorar datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\n\nview_df(elsoc,max.len = 50)\n\n\nData frame: elsoc\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nsexo\nSexo entrevistado\n0\n1\nHombre\nMujer\n\n\n2\nedad\nEdad entrevistado\nrange: 18-90\n\n\n3\neduc\nNivel educacional\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\n\n\n4\npospol\nAutoubicacion escala izquierda-derecha\n1\n2\n3\n4\nDerecha\nCentro\nIzquierda\nIndep./Ninguno\n\n\n5\npart01\nFrecuencia: Firma carta o peticion apoyando causa\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n6\npart02\nFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n7\npart03\nFrecuencia: Participa en huelga\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n8\npart04\nFrecuencia: Usa redes sociales para opinar en\ntemas publicos\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n9\ninghogar\nIngreso total del hogar\nrange: 30000-17000000\n\n\n10\ninghogar_t\nIngreso total del hogar (en tramos)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nMenos de $220.000 mensuales liquidos\nDe $220.001 a $280.000 mensuales liquidos\nDe $280.001 a $330.000 mensuales liquidos\nDe $330.001 a $380.000 mensuales liquidos\nDe $380.001 a $420.000 mensuales liquidos\nDe $420.001 a $470.000 mensuales liquidos\nDe $470.001 a $510.000 mensuales liquidos\nDe $510.001 a $560.000 mensuales liquidos\nDe $560.001 a $610.000 mensuales liquidos\nDe $610.001 a $670.000 mensuales liquidos\nDe $670.001 a $730.000 mensuales liquidos\nDe $730.001 a $800.000 mensuales liquidos\nDe $800.001 a $890.000 mensuales liquidos\nDe $890.001 a $980.000 mensuales liquidos\nDe $980.001 a $1.100.000 mensuales liquidos\nDe $1.100.001 a $1.260.000 mensuales liquidos\nDe $1.260.001 a $1.490.000 mensuales liquidos\nDe $1.490.001 a $1.850.000 mensuales liquidos\nDe $1.850.001 a $2.700.000 mensuales liquidos\nMas de $2.700.000 a mensuales liquidos\n\n\n11\ntamhogar\nHabitantes del hogar\nrange: 1-14"
  },
  {
    "objectID": "resource/07-resource.html#variable-dependiente-participación-política",
    "href": "resource/07-resource.html#variable-dependiente-participación-política",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Variable dependiente: participación política",
    "text": "Variable dependiente: participación política\n\nplot_stackfrq(elsoc[,c(\"part01\",\"part02\",\"part03\",\"part04\")]) + theme(legend.position=\"bottom\")\n\n\n\n\n\ncorrplot.mixed(cor(select(elsoc,part01,part02,part03,part04),\n                   use = \"complete.obs\"))\n\n\n\n\n\nelsoc &lt;- elsoc %&gt;% mutate(partpol=rowSums(select(., part01,part02,part03,part04)))\nsummary(elsoc$partpol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  4.000   4.000   4.000   5.473   6.000  20.000       8"
  },
  {
    "objectID": "resource/07-resource.html#variable-independiente-ingresos",
    "href": "resource/07-resource.html#variable-independiente-ingresos",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Variable independiente: ingresos",
    "text": "Variable independiente: ingresos\ningresos hogar variable continua\n\nsummary(elsoc$inghogar)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n   30000   300000   500000   678843   800000 17000000      668 \n\n\ningreso hogar en tramos\n\nsjmisc::frq(elsoc$inghogar_t,\n            out = \"txt\",\n            show.na = T) %&gt;% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nval\nlabel\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\n\n1\nMenos de $220.000 mensuales liquidos\n62\n1.65\n13.00\n13.00\n\n\n2\nDe $220.001 a $280.000 mensuales liquidos\n46\n1.23\n9.64\n22.64\n\n\n3\nDe $280.001 a $330.000 mensuales liquidos\n57\n1.52\n11.95\n34.59\n\n\n4\nDe $330.001 a $380.000 mensuales liquidos\n40\n1.07\n8.39\n42.98\n\n\n5\nDe $380.001 a $420.000 mensuales liquidos\n38\n1.01\n7.97\n50.94\n\n\n6\nDe $420.001 a $470.000 mensuales liquidos\n37\n0.99\n7.76\n58.70\n\n\n7\nDe $470.001 a $510.000 mensuales liquidos\n27\n0.72\n5.66\n64.36\n\n\n8\nDe $510.001 a $560.000 mensuales liquidos\n15\n0.40\n3.14\n67.51\n\n\n9\nDe $560.001 a $610.000 mensuales liquidos\n24\n0.64\n5.03\n72.54\n\n\n10\nDe $610.001 a $670.000 mensuales liquidos\n12\n0.32\n2.52\n75.05\n\n\n11\nDe $670.001 a $730.000 mensuales liquidos\n15\n0.40\n3.14\n78.20\n\n\n12\nDe $730.001 a $800.000 mensuales liquidos\n16\n0.43\n3.35\n81.55\n\n\n13\nDe $800.001 a $890.000 mensuales liquidos\n8\n0.21\n1.68\n83.23\n\n\n14\nDe $890.001 a $980.000 mensuales liquidos\n14\n0.37\n2.94\n86.16\n\n\n15\nDe $980.001 a $1.100.000 mensuales liquidos\n14\n0.37\n2.94\n89.10\n\n\n16\nDe $1.100.001 a $1.260.000 mensuales liquidos\n10\n0.27\n2.10\n91.19\n\n\n17\nDe $1.260.001 a $1.490.000 mensuales liquidos\n7\n0.19\n1.47\n92.66\n\n\n18\nDe $1.490.001 a $1.850.000 mensuales liquidos\n11\n0.29\n2.31\n94.97\n\n\n19\nDe $1.850.001 a $2.700.000 mensuales liquidos\n14\n0.37\n2.94\n97.90\n\n\n20\nMas de $2.700.000 a mensuales liquidos\n10\n0.27\n2.10\n100.00\n\n\nNA\nNA\n3271\n87.27\nNA\nNA\n\n\n\n\n\n\n\n\n\n\npodemos obtener la mediana de cada tramo\n\nelsoc$inghogar_t[elsoc$inghogar_t==1] &lt;-(       220000 )    # [1]  \"Menos de $220.000 mensuales liquidos\"          \nelsoc$inghogar_t[elsoc$inghogar_t==2] &lt;-(220001 +280000 )/2 # [2]  \"De $220.001 a $280.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==3] &lt;-(280001 +330000 )/2 # [3]  \"De $280.001 a $330.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==4] &lt;-(330001 +380000 )/2 # [4]  \"De $330.001 a $380.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==5] &lt;-(380001 +420000 )/2 # [5]  \"De $380.001 a $420.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==6] &lt;-(420001 +470000 )/2 # [6]  \"De $420.001 a $470.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==7] &lt;-(470001 +510000 )/2 # [7]  \"De $470.001 a $510.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==8] &lt;-(510001 +560000 )/2 # [8]  \"De $510.001 a $560.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==9] &lt;-(560001 +610000 )/2 # [9]  \"De $560.001 a $610.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==10]&lt;-(610001 +670000 )/2 # [10] \"De $610.001 a $670.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==11]&lt;-(670001 +730000 )/2 # [11] \"De $670.001 a $730.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==12]&lt;-(730001 +800000 )/2 # [12] \"De $730.001 a $800.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==13]&lt;-(800001 +890000 )/2 # [13] \"De $800.001 a $890.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==14]&lt;-(890001 +980000 )/2 # [14] \"De $890.001 a $980.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==15]&lt;-(980001 +1100000)/2 # [15] \"De $980.001 a $1.100.000 mensuales liquidos\"      \nelsoc$inghogar_t[elsoc$inghogar_t==16]&lt;-(1100001+1260000)/2 # [16] \"De $1.100.001 a $1.260.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==17]&lt;-(1260001+1490000)/2 # [17] \"De $1.260.001 a $1.490.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==18]&lt;-(1490001+1850000)/2 # [18] \"De $1.490.001 a $1.850.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==19]&lt;-(1850001+2700000)/2 # [19] \"De $1.850.001 a $2.700.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==20]&lt;-(2700000)           # [20] \"Mas de $2.700.000 a mensuales liquidos\"\n\ny luego imputar este valor medio a los casos NA\n\nelsoc$inghogar_i &lt;- ifelse(test = (is.na(elsoc$inghogar)), #¿existen NA en ingresos?\n                           yes = elsoc$inghogar_t,         #VERDADERO, remplazar con la media del tramo\n                           no = elsoc$inghogar)            #FALSE, mantener la variable original.\n\nelsoc$inghogar_i &lt;- set_label(elsoc$inghogar_i,\"Ingreso total del hogar (imputada)\")\n\n\nelsoc$ing_pcap &lt;- elsoc$inghogar_i/elsoc$tamhogar\nelsoc$ing_pcap &lt;- set_label(elsoc$ing_pcap,\"Ingreso per cápita del hogar\")\n\n\nelsoc$quintile&lt;- dplyr::ntile(x = elsoc$ing_pcap,\n                              n = 5) # n de categorias, para quintiles usamos 5 \nelsoc$quintile &lt;- factor(elsoc$quintile,c(1,2,3,4,5), c(\"Quintil 1\",\"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\")) \nelsoc %&gt;% \n  group_by(quintile) %&gt;% \n  summarise(n=n(),\n            Media=mean(ing_pcap,na.rm = T),\n            Mediana=median(ing_pcap,na.rm = T)) %&gt;% \n  knitr::kable()\n\n\n\n\nquintile\nn\nMedia\nMediana\n\n\n\n\nQuintil 1\n711\n62859.09\n66666.67\n\n\nQuintil 2\n711\n112218.97\n111250.12\n\n\nQuintil 3\n710\n167748.23\n166666.67\n\n\nQuintil 4\n710\n262710.27\n250000.50\n\n\nQuintil 5\n710\n710246.41\n500000.00\n\n\nNA\n196\nNaN\nNA\n\n\n\n\n\n\nelsoc$quintilemiss &lt;- factor(elsoc$quintile,ordered = T)\nelsoc$quintilemiss &lt;- ifelse(test=is.na(elsoc$quintilemiss),yes = 6,no = elsoc$quintilemiss)\nelsoc$quintilemiss &lt;- factor(elsoc$quintilemiss ,levels = c(1,2,3,4,5,6),labels =  c(\"Quintil 1\",\"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Missing\")) \nelsoc %&gt;% group_by(quintilemiss) %&gt;% summarise(n=n())\n\n# A tibble: 6 × 2\n  quintilemiss     n\n  &lt;fct&gt;        &lt;int&gt;\n1 Quintil 1      711\n2 Quintil 2      711\n3 Quintil 3      710\n4 Quintil 4      710\n5 Quintil 5      710\n6 Missing        196"
  },
  {
    "objectID": "resource/07-resource.html#variables-dummy",
    "href": "resource/07-resource.html#variables-dummy",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Variables dummy",
    "text": "Variables dummy\nUna forma de pasar una variable categórica a dummies es con la función dummy_cols del paquete fastDummies\n\nelsoc &lt;- dummy_cols(elsoc, select_columns = \"quintilemiss\")\nhead(elsoc[,16:22])\n\n  quintilemiss quintilemiss_Quintil 1 quintilemiss_Quintil 2\n1    Quintil 1                      1                      0\n2    Quintil 5                      0                      0\n3    Quintil 1                      1                      0\n4    Quintil 5                      0                      0\n5      Missing                      0                      0\n6    Quintil 3                      0                      0\n  quintilemiss_Quintil 3 quintilemiss_Quintil 4 quintilemiss_Quintil 5\n1                      0                      0                      0\n2                      0                      0                      1\n3                      0                      0                      0\n4                      0                      0                      1\n5                      0                      0                      0\n6                      1                      0                      0\n  quintilemiss_Missing\n1                    0\n2                    0\n3                    0\n4                    0\n5                    1\n6                    0\n\n\n¿cómo hacerlo para una variable numérica?\nTambién existen muchas formas, como por ejemplo establecer como punto de corte la media o la mediana, o ver la distribución de las respuestas y tratar de establecer una distribución homogénea entre las dos nuevas categorías.\nSi recordamos la distribución de nuestra variable dependiente antes de construir el índice de participación:\n\nplot_stackfrq(elsoc[,c(\"part01\",\"part02\",\"part03\",\"part04\")]) + theme(legend.position=\"bottom\")\n\n\n\n\ny luego en el índice de participación\n\nsummary(elsoc$partpol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  4.000   4.000   4.000   5.473   6.000  20.000       8 \n\n\nPodemos notar que la mayoría de las respuestas se agrupan en la categoría “nunca” de las variables por separado y luego en el índice la mediana también corresponde al valor mínimo posible de “4” que es la suma de todas las personas que nunca han participado en ninguna de las opciones. Por lo tanto, tenemos dos criterios que nos permiten decidir que nuestra variable dependiente puede ser considera como dummy bajo los valores 0=nunca ha participado; y 1=si ha participado.\nUna forma de hacer esta agrupación de valores es con la función case_when del paquete dplyr (similar a ifelse)\n\nelsoc &lt;- elsoc %&gt;% rowwise() %&gt;%  mutate(partpol_dummy = case_when(partpol==4~0,\n                                                                   partpol&gt;4~1,\n                                                                   TRUE ~ NA))\ntable(elsoc$partpol_dummy)\n\n\n   0    1 \n2074 1666"
  },
  {
    "objectID": "resource/05-resource.html",
    "href": "resource/05-resource.html",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de introducir en los supuestos y robustez del modelo de regresión. Por esta razón, volveremos a algunos de los contenidos previos relacionados con la estimación, análisis de residuos y ajuste. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\nLa versión original de este ejercicio proviene del curso de Estadística multivariada versión 2022."
  },
  {
    "objectID": "resource/05-resource.html#explorar-datos",
    "href": "resource/05-resource.html#explorar-datos",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "Explorar datos",
    "text": "Explorar datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\n\nview(dfSummary(elsoc, headings = FALSE, method = \"render\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nsexo [numeric]\nSexo entrevistado\n\n\n\nMin : 0\n\n\nMean : 0.6\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n1446\n(\n38.6%\n)\n\n\n1\n:\n2302\n(\n61.4%\n)\n\n\n\n\n3748 (100.0%)\n0 (0.0%)\n\n\n2\nedad [numeric]\nEdad entrevistado\n\n\n\nMean (sd) : 47.1 (15.5)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 47 ≤ 90\n\n\nIQR (CV) : 25 (0.3)\n\n\n\n70 distinct values\n\n3748 (100.0%)\n0 (0.0%)\n\n\n3\neduc [factor]\nNivel educacional\n\n\n\n1. 1\n\n\n2. 2\n\n\n3. 3\n\n\n4. 4\n\n\n5. 5\n\n\n\n\n\n\n450\n(\n12.0%\n)\n\n\n370\n(\n9.9%\n)\n\n\n1600\n(\n42.7%\n)\n\n\n598\n(\n16.0%\n)\n\n\n725\n(\n19.4%\n)\n\n\n\n\n3743 (99.9%)\n5 (0.1%)\n\n\n4\npospol [factor]\nAutoubicacion escala izquierda-derecha\n\n\n\n1. 1\n\n\n2. 2\n\n\n3. 3\n\n\n4. 4\n\n\n\n\n\n\n807\n(\n22.0%\n)\n\n\n952\n(\n26.0%\n)\n\n\n734\n(\n20.0%\n)\n\n\n1171\n(\n32.0%\n)\n\n\n\n\n3664 (97.8%)\n84 (2.2%)\n\n\n5\npart01 [numeric]\nFrecuencia: Firma carta o peticion apoyando causa\n\n\n\nMean (sd) : 1.5 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 1 (0.6)\n\n\n\n\n\n\n1\n:\n2717\n(\n72.6%\n)\n\n\n2\n:\n476\n(\n12.7%\n)\n\n\n3\n:\n411\n(\n11.0%\n)\n\n\n4\n:\n117\n(\n3.1%\n)\n\n\n5\n:\n21\n(\n0.6%\n)\n\n\n\n\n3742 (99.8%)\n6 (0.2%)\n\n\n6\npart02 [numeric]\nFrecuencia: Asiste a marcha o manifestacion pacifica\n\n\n\nMean (sd) : 1.2 (0.6)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 0 (0.5)\n\n\n\n\n\n\n1\n:\n3289\n(\n87.8%\n)\n\n\n2\n:\n195\n(\n5.2%\n)\n\n\n3\n:\n191\n(\n5.1%\n)\n\n\n4\n:\n51\n(\n1.4%\n)\n\n\n5\n:\n19\n(\n0.5%\n)\n\n\n\n\n3745 (99.9%)\n3 (0.1%)\n\n\n7\npart03 [numeric]\nFrecuencia: Participa en huelga\n\n\n\nMean (sd) : 1.2 (0.5)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 0 (0.5)\n\n\n\n\n\n\n1\n:\n3407\n(\n91.0%\n)\n\n\n2\n:\n152\n(\n4.1%\n)\n\n\n3\n:\n146\n(\n3.9%\n)\n\n\n4\n:\n29\n(\n0.8%\n)\n\n\n5\n:\n11\n(\n0.3%\n)\n\n\n\n\n3745 (99.9%)\n3 (0.1%)\n\n\n8\npart04 [numeric]\nFrecuencia: Usa redes sociales para opinar en temas publicos\n\n\n\nMean (sd) : 1.6 (1.1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 5\n\n\nIQR (CV) : 1 (0.7)\n\n\n\n\n\n\n1\n:\n2598\n(\n69.4%\n)\n\n\n2\n:\n310\n(\n8.3%\n)\n\n\n3\n:\n514\n(\n13.7%\n)\n\n\n4\n:\n223\n(\n6.0%\n)\n\n\n5\n:\n98\n(\n2.6%\n)\n\n\n\n\n3743 (99.9%)\n5 (0.1%)\n\n\n9\nquintilemiss [factor]\n\n\n\n\n1. Quintil 1\n\n\n2. Quintil 2\n\n\n3. Quintil 3\n\n\n4. Quintil 4\n\n\n5. Quintil 5\n\n\n6. Missing\n\n\n\n\n\n\n711\n(\n19.0%\n)\n\n\n711\n(\n19.0%\n)\n\n\n710\n(\n18.9%\n)\n\n\n710\n(\n18.9%\n)\n\n\n710\n(\n18.9%\n)\n\n\n196\n(\n5.2%\n)\n\n\n\n\n3748 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-04-04\n\n\n\n\nview_df(elsoc,max.len = 50)\n\n\nData frame: elsoc\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nsexo\nSexo entrevistado\n0\n1\nHombre\nMujer\n\n\n2\nedad\nEdad entrevistado\nrange: 18-90\n\n\n3\neduc\nNivel educacional\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\n\n\n4\npospol\nAutoubicacion escala izquierda-derecha\n1\n2\n3\n4\nDerecha\nCentro\nIzquierda\nIndep./Ninguno\n\n\n5\npart01\nFrecuencia: Firma carta o peticion apoyando causa\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n6\npart02\nFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n7\npart03\nFrecuencia: Participa en huelga\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n8\npart04\nFrecuencia: Usa redes sociales para opinar en\ntemas publicos\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n9\nquintilemiss\n\n\nQuintil 1\nQuintil 2\nQuintil 3\nQuintil 4\nQuintil 5\nMissing\n\n\n\n\n\n\nelsoc &lt;- elsoc %&gt;% mutate(partpol=rowSums(select(., part01,part02,part03,part04)))"
  },
  {
    "objectID": "resource/05-resource.html#diágnosticos",
    "href": "resource/05-resource.html#diágnosticos",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "Diágnosticos",
    "text": "Diágnosticos\n\nCasos influyentes\nPara determinar si un outlier es un caso influyente, es decir que su presencia/ausencia genera un cambio importante en la estimación de los coeficientes de regresión, calculamos la Distancia de Cook..\nPosteriormente, se establece un punto de corte de \\(4/(n-k-1)\\):\n\nn&lt;- nobs(fit04) #n de observaciones\nk&lt;- length(coef(fit04)) # n de parametros\ndcook&lt;- 4/(n-k-1) #punt de corte\n\nSi lo graficamos se ve de la siguiente manera:\n\nfinal &lt;- broom::augment_columns(fit04,data = elsoc)\nfinal$id &lt;- as.numeric(row.names(final))\n# identify obs with Cook's D above cutoff\nggplot(final, aes(id, .cooksd)) +\n  geom_bar(stat=\"identity\", position=\"identity\") +\n  xlab(\"Obs. Number\")+ # Modificación nombre eje x\n  ylab(\"Cook's distance\")+ # Modificación nombre eje y\n  geom_hline(yintercept=dcook)+ # Incluir una línea horizontal\n  geom_text(aes(label=ifelse((.cooksd&gt;dcook),id,\"\")), # geom text agrega nombre a los casos, en esta oportunidad solo a los valores mayores a dcook\n            vjust=-0.2, hjust=0.5)\n\n\n\n\nIdentificamos los casos influyentes y filtramos la base de datos:\n\nident&lt;- final %&gt;% filter(.cooksd&gt;dcook)\nelsoc02 &lt;- final %&gt;% filter(!(id %in% ident$id))\n\nEstimación sin casos influyentes:\n\nfit05&lt;- lm(partpol~sexo+edad+quintilemiss+pospol,data=elsoc02)\n\nlabs02 &lt;- c(\"Intercepto\",\"Sexo (mujer=1)\",\"Edad\",\n            \"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Quintil perdido\",\n            \"Izquierda (ref. derecha)\",\"Centro\",\"Idep./Ninguno\")\n\nhtmlreg(list(fit04,fit05), \n        doctype = FALSE,\n        custom.model.names = c(\"Modelo 4\", \"Modelo 5\"),\n        custom.coef.names = labs02)\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo 4\n\n\nModelo 5\n\n\n\n\n\n\nIntercepto\n\n\n7.97***\n\n\n7.05***\n\n\n\n\n \n\n\n(0.16)\n\n\n(0.11)\n\n\n\n\nSexo (mujer=1)\n\n\n0.12\n\n\n0.07\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.05)\n\n\n\n\nEdad\n\n\n-0.04***\n\n\n-0.03***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nQuintil 2\n\n\n0.21\n\n\n0.11\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 3\n\n\n0.51***\n\n\n0.34***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 4\n\n\n0.50***\n\n\n0.32***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nQuintil 5\n\n\n0.88***\n\n\n0.57***\n\n\n\n\n \n\n\n(0.12)\n\n\n(0.08)\n\n\n\n\nQuintil perdido\n\n\n0.59***\n\n\n0.31*\n\n\n\n\n \n\n\n(0.18)\n\n\n(0.13)\n\n\n\n\nIzquierda (ref. derecha)\n\n\n-1.04***\n\n\n-0.65***\n\n\n\n\n \n\n\n(0.10)\n\n\n(0.07)\n\n\n\n\nCentro\n\n\n-1.13***\n\n\n-0.71***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.08)\n\n\n\n\nIdep./Ninguno\n\n\n-1.60***\n\n\n-1.14***\n\n\n\n\n \n\n\n(0.10)\n\n\n(0.07)\n\n\n\n\nR2\n\n\n0.17\n\n\n0.18\n\n\n\n\nAdj. R2\n\n\n0.17\n\n\n0.18\n\n\n\n\nNum. obs.\n\n\n3656\n\n\n3460\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05\n\n\n\n\n\nEn términos generales, el sentido y significación estadística de los coeficientes del Modelo 5 se mantiene respecto al Modelo 4. Adicionalmente, si observamos que el modelo sin casos influyentes presenta una mejora en ajuste. Por lo tanto, los análisis posteriores se realizaran en base a este modelo.\n\n\nLinealidad\nPara analizar la linealidad respecto de un modelo de regresión, debemos analizar la distribución de los residuos con respecto a la recta de regresión.\n\nLos residuos deben ser independientes de los valores predichos (fitted values).\nCualquier correlación entre residuo y valores predichos violarían este supuesto.\nLa presencia de un patrón no lineal, es señal de que el modelo está especificado incorrectamente.\n\n\nggplot(fit05, aes(.fitted, .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_smooth(se = TRUE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nRelación entre residuos y valores predichos\n\n\n\n\nEl gráfico nos indica que existe un patrón en la distribución de los residuos. Para intentar mejorar la estimación podemos realizar una transformación de variables. A continuación presentaremos un ejemplo para la Edad y para los Ingresos.\n\nPolinomio: \\(\\text{Edad}^2\\)\n\n\nelsoc02$edad2 &lt;- elsoc02$edad^2\nfit06&lt;- lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\n\n\nedad&lt;- fit06$model$edad\nfit&lt;- fit06$fitted.values\ndata01 &lt;- as.data.frame(cbind(edad,fit))\n\nggplot(data01, aes(x = edad, y = fit)) +\n  theme_bw() +\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nEfecto cuadrático de la edad (Modelo 5)\n\n\n\n\n\nfit07 &lt;- lm(partpol~sexo+edad+edad2+quintilemiss+pospol,data=elsoc02)\n\nlabs03 &lt;- c(\"Intercepto\",\"Sexo (mujer=1)\",\"Edad\",\n            \"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Quintil perdido\",\n            \"Izquierda (ref. derecha)\",\"Centro\",\"Idep./Ninguno\", \"Edad²\")\n\nhtmlreg(list(fit05, fit06, fit07), doctype = FALSE,\n        custom.model.names = c(\"Modelo 4\", \"Modelo 5\", \"Modelo 6\"), \n          custom.coef.names = labs03)\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo 4\n\n\nModelo 5\n\n\nModelo 6\n\n\n\n\n\n\nIntercepto\n\n\n7.05***\n\n\n7.62***\n\n\n7.62***\n\n\n\n\n \n\n\n(0.11)\n\n\n(0.24)\n\n\n(0.24)\n\n\n\n\nSexo (mujer=1)\n\n\n0.07\n\n\n0.08\n\n\n0.08\n\n\n\n\n \n\n\n(0.05)\n\n\n(0.05)\n\n\n(0.05)\n\n\n\n\nEdad\n\n\n-0.03***\n\n\n-0.06***\n\n\n-0.06***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n\n\nQuintil 2\n\n\n0.11\n\n\n0.11\n\n\n0.11\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 3\n\n\n0.34***\n\n\n0.34***\n\n\n0.34***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 4\n\n\n0.32***\n\n\n0.32***\n\n\n0.32***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil 5\n\n\n0.57***\n\n\n0.57***\n\n\n0.57***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nQuintil perdido\n\n\n0.31*\n\n\n0.31*\n\n\n0.31*\n\n\n\n\n \n\n\n(0.13)\n\n\n(0.13)\n\n\n(0.13)\n\n\n\n\nIzquierda (ref. derecha)\n\n\n-0.65***\n\n\n-0.65***\n\n\n-0.65***\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.07)\n\n\n(0.07)\n\n\n\n\nCentro\n\n\n-0.71***\n\n\n-0.70***\n\n\n-0.70***\n\n\n\n\n \n\n\n(0.08)\n\n\n(0.08)\n\n\n(0.08)\n\n\n\n\nIdep./Ninguno\n\n\n-1.14***\n\n\n-1.13***\n\n\n-1.13***\n\n\n\n\n \n\n\n(0.07)\n\n\n(0.07)\n\n\n(0.07)\n\n\n\n\nEdad²\n\n\n \n\n\n0.00**\n\n\n0.00**\n\n\n\n\n \n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nR2\n\n\n0.18\n\n\n0.19\n\n\n0.19\n\n\n\n\nAdj. R2\n\n\n0.18\n\n\n0.18\n\n\n0.18\n\n\n\n\nNum. obs.\n\n\n3460\n\n\n3460\n\n\n3460\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05"
  },
  {
    "objectID": "resource/05-resource.html#referencias",
    "href": "resource/05-resource.html#referencias",
    "title": "Práctica 5 Supuestos de regresión lineal",
    "section": "Referencias",
    "text": "Referencias\nDarlington & Hayes 2016 Cap16 Detecting and Managing Irregularities\nDarlington & Hayes 2016 Cap12 Nonlinear relationships"
  },
  {
    "objectID": "resource/02-resource.html",
    "href": "resource/02-resource.html",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .\n\n\n\n\nLatinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad)."
  },
  {
    "objectID": "resource/02-resource.html#objetivo-de-la-práctica",
    "href": "resource/02-resource.html#objetivo-de-la-práctica",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro ."
  },
  {
    "objectID": "resource/02-resource.html#antecedentes-de-los-datos-a-utilizar",
    "href": "resource/02-resource.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "",
    "text": "Latinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad)."
  },
  {
    "objectID": "resource/02-resource.html#librerias",
    "href": "resource/02-resource.html#librerias",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva"
  },
  {
    "objectID": "resource/02-resource.html#cargar-base-de-datos",
    "href": "resource/02-resource.html#cargar-base-de-datos",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: latinobarometro2020.RData. Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos &lt;- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\n#cargamos la base de datos desde internet\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/external_data/latinobarometro2020.RData\"))\n\no de manera local:\n\nlatinobarometro2020 &lt;- read_dta(\"../files/data/external_data/latinobarometro2020.dta\", encoding = \"UTF-8\")\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (elsoc_2016):\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 20204 casos y 408 variables).\n\ndim(latinobarometro2020) # dimension de la base\n\n[1] 20204   408\n\n\nY si se quiere revisar en formato de planilla de datos:\n\nView(latinobarometro2020)"
  },
  {
    "objectID": "resource/02-resource.html#selección-de-variables-a-utilizar",
    "href": "resource/02-resource.html#selección-de-variables-a-utilizar",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto Confianza:\n\n\nfind_var(data = latinobarometro2020,\"Confianza\")\n\n   col.nr   var.name\n1      36    p9stgbs\n2      41 P13STGBS_A\n3      42 P13STGBS_B\n4      43    p13st_c\n5      44    p13st_d\n6      45    p13st_e\n7      46    p13st_f\n8      47    p13st_g\n9      48    p13st_h\n10     49    p13st_i\n11     51    p15st_a\n12     52    p15st_b\n13     53    p15st_c\n14     54    p15st_d\n15     55    p15st_e\n16     56    p15st_f\n17     57    p15st_g\n18     58     p15n_h\n19     59     p15n_i\n20     60     p15n_j\n21     61     p15n_k\n22    154     p36n_a\n23    155     p36n_b\n24    160  P36STMB_A\n25    161  P36STMB_B\n26    162  P36STMB_C\n27    163  P36STMB_D\n                                                                          var.label\n1                                                   P9STGBS Confianza Interpersonal\n2                                       P13STGBS.A Confianza en las Fuerzas Armadas\n3                                  P13STGBS.B Confianza en la Policía / Carabineros\n4                                                   P13ST.C Confianza en la Iglesia\n5                                                  P13ST.D Confianza en el Congreso\n6                                                  P13ST.E Confianza en el Gobierno\n7                                            P13ST.F Confianza en el Poder Judicial\n8                                       P13ST.G Confianza en los Partidos Políticos\n9                           P13ST.H Confianza en: La institución Electoral del país\n10                                              P13ST.I Confianza en: El presidente\n11 P15ST.A Confianza en que las instituciones operan para mejorar nuestra calidad d\n12 P15ST.B Confianza en que las instituciones operan para mejorar nuestra calidad d\n13 P15ST.C Confianza en que las instituciones operan para mejorar nuestra calidad d\n14 P15ST.D Confianza en que las instituciones operan para mejorar nuestra calidad d\n15 P15ST.E Confianza en que las instituciones operan para mejorar nuestra calidad d\n16 P15ST.F Confianza en que las instituciones operan para mejorar nuestra calidad d\n17 P15ST.G Confianza en que las instituciones operan para mejorar nuestra calidad d\n18 P15N.H Confianza en que las instituciones operan para mejorar nuestra calidad de\n19 P15N.I Confianza en que las instituciones operan para mejorar nuestra calidad de\n20 P15N.J Confianza en que las instituciones operan para mejorar nuestra calidad de\n21 P15N.K Confianza en que las instituciones operan para mejorar nuestra calidad de\n22                        P36N.A Confianza en las Fuerzas Armadas de Estados Unidos\n23                                   P36N.B Confianza en las fuerzas Armadas Chinas\n24                    P36STMB.A Confianza en el FMI (Fondo Monetario Internacional)\n25               P36STMB.B Confianza en el BID (Banco Interamericano de Desarrollo)\n26            P36STMB.C Confianza en el CAF (Banco de Desarrollo de América Latina)\n27                                          P36STMB.D Confianza en el Banco Mundial\n\n\nNos informa que hay una serie de variables relacionadas con confianza interpersonal y con instituciones. Probemos con la variable p13st_e.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\nproc_data &lt;- latinobarometro2020 %&gt;% select(p13st_e, # Confianza en el Gobierno\n                          p13st_d, # Confianza en el congreso\n                          p13st_f, # Confianza en el Poder Judicial\n                          p13st_g, # Confianza en los partidos políticos\n                          reeduc_1,# nivel educacional\n                          sexo,# sexo\n                          edad,# edad\n                          idenpa) # pais \n\n# Comprobar\nnames(proc_data)\n\n[1] \"p13st_e\"  \"p13st_d\"  \"p13st_f\"  \"p13st_g\"  \"reeduc_1\" \"sexo\"     \"edad\"    \n[8] \"idenpa\"  \n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                                             p13st_e \n                                  \"P13ST.E Confianza en el Gobierno\" \n                                                             p13st_d \n                                  \"P13ST.D Confianza en el Congreso\" \n                                                             p13st_f \n                            \"P13ST.F Confianza en el Poder Judicial\" \n                                                             p13st_g \n                       \"P13ST.G Confianza en los Partidos Políticos\" \n                                                            reeduc_1 \n\"REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\" \n                                                                sexo \n                                                         \"SEXO Sexo\" \n                                                                edad \n                                                         \"EDAD Edad\" \n                                                              idenpa \n                                    \"IDENPA Identificación del País\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.\nPara facilitar el análisis, vamos a filtrar la base de datos para quedarnos solo con los casos de Chile. Para esto utilizamos la función filter de dplyr. Si revisamos el libro de códigos, el identificador de Chile es 152\n\nproc_data &lt;- proc_data %&gt;% dplyr::filter(idenpa==152)"
  },
  {
    "objectID": "resource/02-resource.html#procesamiento-de-variables",
    "href": "resource/02-resource.html#procesamiento-de-variables",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Confianza en el Gobierno\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n[p13st_e]: “P13ST.E Confianza en el Gobierno” (1 = Mucha; 4 = Ninguna)\n[p13st_d]: “P13ST.D Confianza en el Congreso” (1 = Mucha; 4 = Ninguna)\n[p13st_f]: “P13ST.F Confianza en el Poder Judicial” (1 = Mucha; 4 = Ninguna)\n[p13st_g]: “P13ST.G Confianza en los Partidos Políticos” (1 = Mucha; 4 = Ninguna)\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$p13st_e)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=3.27 sd=0.99\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n   -2 |   8 |  0.67 |    0.67 |   0.67\n   -1 |  11 |  0.92 |    0.92 |   1.58\n    1 |  23 |  1.92 |    1.92 |   3.50\n    2 | 176 | 14.67 |   14.67 |  18.17\n    3 | 358 | 29.83 |   29.83 |  48.00\n    4 | 624 | 52.00 |   52.00 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-2) y “No sabe” (-1), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos confianza), así que en la recodificiación nos haremos cargo de los casos perdidos y de reordenar las categorías.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\n\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"c(-2,-1)=NA\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"c(-2,-1)=NA\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"c(-2,-1)=NA\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"c(-2,-1)=NA\")\n\nnota: con la función set_na de la librería sjmisc podemos recodificar toda la base de datos con un solo código, pero debemos estar completamente segur-s de que estos valores no tienen otra categoría asociada en otra variable.\n\nproc_data &lt;- proc_data %&gt;% set_na(., na = c(-2, -1))\n\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"1=3; 2=2; 3=1; 4=0\")\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data &lt;- proc_data %&gt;% rename(\"conf_gob\"=p13st_e, # Confianza en el gobierno\n                                  \"conf_cong\"=p13st_d, # Confianza en el congreso\n                                  \"conf_jud\"=p13st_f, # Confianza en el Poder Judicial\n                                  \"conf_partpol\"=p13st_g) # Confianza en los partidos políticos \n\nnota: recodificación más rápida si estamos segur-s de todos los valores\n\nproc_data &lt;- proc_data %&gt;% mutate_at(vars(starts_with(\"conf\")), ~(4-.))\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nproc_data$conf_gob &lt;- set_label(x = proc_data$conf_gob,label = \"Confianza: Gobierno\")\nget_label(proc_data$conf_gob)\n\n[1] \"Confianza: Gobierno\"\n\nproc_data$conf_cong  &lt;- set_label(x = proc_data$conf_cong, label = \"Confianza: Congreso\")\nget_label(proc_data$conf_cong)\n\n[1] \"Confianza: Congreso\"\n\nproc_data$conf_jud  &lt;- set_label(x = proc_data$conf_jud, label = \"Confianza: Poder judicial\")\nget_label(proc_data$conf_jud)\n\n[1] \"Confianza: Poder judicial\"\n\nproc_data$conf_partpol  &lt;- set_label(x = proc_data$conf_partpol, label = \"Confianza: Partidos politicos\")\nget_label(proc_data$conf_partpol)\n\n[1] \"Confianza: Partidos politicos\"\n\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea la suma de los cuatro items de confianza.\n\nproc_data$conf_inst &lt;- (proc_data$conf_gob+proc_data$conf_cong+proc_data$conf_jud+proc_data$conf_partpol)\nsummary(proc_data$conf_inst)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    2.00    2.42    4.00   12.00      38 \n\n\n\nget_label(proc_data$conf_inst)\n\n[1] \"Confianza: Gobierno\"\n\n\nVemos que una etiqueta de la variable anterior.\n\nproc_data$conf_inst  &lt;- set_label(x = proc_data$conf_inst, label = \"Confianza en instituciones\")\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 624 | 52.00 |   52.84 |  52.84\n    1 | 358 | 29.83 |   30.31 |  83.15\n    2 | 176 | 14.67 |   14.90 |  98.05\n    3 |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 628 | 52.33 |   53.31 |  53.31\n    1 | 408 | 34.00 |   34.63 |  87.95\n    2 | 134 | 11.17 |   11.38 |  99.32\n    3 |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_inst)\n\nConfianza en instituciones (x) &lt;numeric&gt; \n# total N=1200 valid N=1162 mean=2.42 sd=2.49\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 397 | 33.08 |   34.17 |  34.17\n    1 | 141 | 11.75 |   12.13 |  46.30\n    2 | 130 | 10.83 |   11.19 |  57.49\n    3 | 111 |  9.25 |    9.55 |  67.04\n    4 | 169 | 14.08 |   14.54 |  81.58\n    5 |  71 |  5.92 |    6.11 |  87.69\n    6 |  41 |  3.42 |    3.53 |  91.22\n    7 |  41 |  3.42 |    3.53 |  94.75\n    8 |  44 |  3.67 |    3.79 |  98.54\n    9 |  11 |  0.92 |    0.95 |  99.48\n   10 |   4 |  0.33 |    0.34 |  99.83\n   11 |   1 |  0.08 |    0.09 |  99.91\n   12 |   1 |  0.08 |    0.09 | 100.00\n &lt;NA&gt; |  38 |  3.17 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\nproc_data$conf_gob &lt;- set_labels(proc_data$conf_gob,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_cong &lt;- set_labels(proc_data$conf_cong,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_jud &lt;- set_labels(proc_data$conf_jud,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_partpol &lt;- set_labels(proc_data$conf_partpol,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\ny volvemos a revisar\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 624 | 52.00 |   52.84 |  52.84\n    1 |    Poca | 358 | 29.83 |   30.31 |  83.15\n    2 |    Algo | 176 | 14.67 |   14.90 |  98.05\n    3 |   Mucha |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 628 | 52.33 |   53.31 |  53.31\n    1 |    Poca | 408 | 34.00 |   34.63 |  87.95\n    2 |    Algo | 134 | 11.17 |   11.38 |  99.32\n    3 |   Mucha |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Educación\n\n[reeduc_1] = REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\n\na. Descriptivo\n\nfrq(proc_data$reeduc_1)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=5.05 sd=1.22\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |   8 |  0.67 |    0.67 |   0.67\n    2 |  53 |  4.42 |    4.42 |   5.08\n    3 |  36 |  3.00 |    3.00 |   8.08\n    4 | 161 | 13.42 |   13.42 |  21.50\n    5 | 643 | 53.58 |   53.58 |  75.08\n    6 | 109 |  9.08 |    9.08 |  84.17\n    7 | 190 | 15.83 |   15.83 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\n\nVemos que no hay datos perdidos\nValores\n\nPara hacer más fácil el análisis, recodificamos en tres categorías (en este caso decisión arbitraria. Se debería tener una razón teórica para recodificar)\n1.  Analfabeto                                =   Educacion basica    =   1\n2   Básica incompleta                         =   Educacion basica    =   1\n3.  Básica completa                           =   Educacion basica    =   1\n4.  Secundaria, media, técnica incompleta     =   Educacion media     =   2\n5.  Secundaria, media, técnica completa       =   Educacion media     =   2\n6.  Superior incompleta                       =   Educacion superior  =   3\n7.  Superior completa                         =   Educacion superior  =   3\n\n\n# recodificacion usando funcion 'recode' de la libreria car\nproc_data$reeduc_1 &lt;- car::recode(proc_data$reeduc_1, \"c(1,2,3)=1; c(4,5)=2; c(6,7)=3\")\n\nComprobar con un nuevo descriptivo:\n\nfrq(proc_data$reeduc_1)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=2.17 sd=0.55\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  97 |  8.08 |    8.08 |   8.08\n    2 | 804 | 67.00 |   67.00 |  75.08\n    3 | 299 | 24.92 |   24.92 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 3), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\nproc_data$reeduc_1 &lt;- set_labels(proc_data$reeduc_1,\n            labels=c( \"Educacion basica\"=1,\n                      \"Educacion media\"=2,\n                      \"Educacion superior\"=3))\n\nLuego renombramos la variable con un nombre más sustantivo\n\nproc_data &lt;- rename(proc_data,\"educacion\"=reeduc_1)\n\nAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$educacion)\n\nNULL\n\nproc_data$educacion &lt;- set_label(x = proc_data$educacion,label = \"Educación\")\n\n\n\n\n4.3. Sexo\n\n[sexo] = SEXO Sexo\n\na. Descriptivo\n\nfrq(proc_data$sexo)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 555 | 46.25 |   46.25 |  46.25\n    2 | 645 | 53.75 |   53.75 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\n\nproc_data$sexo &lt;- car::recode(proc_data$sexo, \"1=0;2=1\")\n\nc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\n\nproc_data$sexo &lt;- set_labels(proc_data$sexo,\n            labels=c( \"Hombre\"=0,\n                      \"Mujer\"=1))\n\nTambién queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$sexo)\n\nNULL\n\nproc_data$sexo &lt;- set_label(x = proc_data$sexo,label = \"Sexo\")\n\nRevisar con un nuevo descriptivo:\n\nfrq(proc_data$sexo)\n\nSexo (x) &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=0.54 sd=0.50\n\nValue |  Label |   N | Raw % | Valid % | Cum. %\n-----------------------------------------------\n    0 | Hombre | 555 | 46.25 |   46.25 |  46.25\n    1 |  Mujer | 645 | 53.75 |   53.75 | 100.00\n &lt;NA&gt; |   &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n4.4 Edad\n\n[edad] = EDAD Edad.\n\na. Descriptivo\n\nfrq(proc_data$edad)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=44.49 sd=17.01\n\nValue |  N | Raw % | Valid % | Cum. %\n-------------------------------------\n   18 | 31 |  2.58 |    2.58 |   2.58\n   19 | 29 |  2.42 |    2.42 |   5.00\n   20 | 25 |  2.08 |    2.08 |   7.08\n   21 | 23 |  1.92 |    1.92 |   9.00\n   22 | 21 |  1.75 |    1.75 |  10.75\n   23 | 26 |  2.17 |    2.17 |  12.92\n   24 | 28 |  2.33 |    2.33 |  15.25\n   25 | 19 |  1.58 |    1.58 |  16.83\n   26 | 21 |  1.75 |    1.75 |  18.58\n   27 | 23 |  1.92 |    1.92 |  20.50\n   28 | 19 |  1.58 |    1.58 |  22.08\n   29 | 22 |  1.83 |    1.83 |  23.92\n   30 | 34 |  2.83 |    2.83 |  26.75\n   31 | 21 |  1.75 |    1.75 |  28.50\n   32 | 26 |  2.17 |    2.17 |  30.67\n   33 | 21 |  1.75 |    1.75 |  32.42\n   34 | 14 |  1.17 |    1.17 |  33.58\n   35 | 22 |  1.83 |    1.83 |  35.42\n   36 | 28 |  2.33 |    2.33 |  37.75\n   37 | 14 |  1.17 |    1.17 |  38.92\n   38 | 24 |  2.00 |    2.00 |  40.92\n   39 | 23 |  1.92 |    1.92 |  42.83\n   40 | 32 |  2.67 |    2.67 |  45.50\n   41 | 21 |  1.75 |    1.75 |  47.25\n   42 | 16 |  1.33 |    1.33 |  48.58\n   43 | 22 |  1.83 |    1.83 |  50.42\n   44 | 16 |  1.33 |    1.33 |  51.75\n   45 | 25 |  2.08 |    2.08 |  53.83\n   46 | 19 |  1.58 |    1.58 |  55.42\n   47 | 15 |  1.25 |    1.25 |  56.67\n   48 | 26 |  2.17 |    2.17 |  58.83\n   49 | 19 |  1.58 |    1.58 |  60.42\n   50 | 35 |  2.92 |    2.92 |  63.33\n   51 |  6 |  0.50 |    0.50 |  63.83\n   52 | 24 |  2.00 |    2.00 |  65.83\n   53 |  7 |  0.58 |    0.58 |  66.42\n   54 | 13 |  1.08 |    1.08 |  67.50\n   55 | 27 |  2.25 |    2.25 |  69.75\n   56 | 18 |  1.50 |    1.50 |  71.25\n   57 | 17 |  1.42 |    1.42 |  72.67\n   58 | 34 |  2.83 |    2.83 |  75.50\n   59 | 17 |  1.42 |    1.42 |  76.92\n   60 | 24 |  2.00 |    2.00 |  78.92\n   61 | 18 |  1.50 |    1.50 |  80.42\n   62 | 21 |  1.75 |    1.75 |  82.17\n   63 | 15 |  1.25 |    1.25 |  83.42\n   64 | 20 |  1.67 |    1.67 |  85.08\n   65 | 12 |  1.00 |    1.00 |  86.08\n   66 | 24 |  2.00 |    2.00 |  88.08\n   67 |  9 |  0.75 |    0.75 |  88.83\n   68 | 12 |  1.00 |    1.00 |  89.83\n   69 | 15 |  1.25 |    1.25 |  91.08\n   70 | 30 |  2.50 |    2.50 |  93.58\n   71 |  9 |  0.75 |    0.75 |  94.33\n   72 | 10 |  0.83 |    0.83 |  95.17\n   73 |  8 |  0.67 |    0.67 |  95.83\n   74 |  8 |  0.67 |    0.67 |  96.50\n   75 |  8 |  0.67 |    0.67 |  97.17\n   76 | 12 |  1.00 |    1.00 |  98.17\n   77 |  5 |  0.42 |    0.42 |  98.58\n   78 |  2 |  0.17 |    0.17 |  98.75\n   79 |  2 |  0.17 |    0.17 |  98.92\n   80 |  4 |  0.33 |    0.33 |  99.25\n   82 |  1 |  0.08 |    0.08 |  99.33\n   84 |  2 |  0.17 |    0.17 |  99.50\n   85 |  3 |  0.25 |    0.25 |  99.75\n   86 |  1 |  0.08 |    0.08 |  99.83\n   87 |  1 |  0.08 |    0.08 |  99.92\n   89 |  1 |  0.08 |    0.08 | 100.00\n &lt;NA&gt; |  0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio la etiqueta de la variable.\n\nget_label(proc_data$edad)\n\nNULL\n\nproc_data$edad &lt;- set_label(x = proc_data$edad,label = \"Edad\")"
  },
  {
    "objectID": "resource/02-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "resource/02-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\nproc_data &lt;-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n===========================================\nStatistic      N    Mean   St. Dev. Min Max\n-------------------------------------------\nconf_gob     1,181  0.660   0.800    0   3 \nconf_cong    1,178  0.594   0.714    0   3 \nconf_jud     1,186  0.717   0.789    0   3 \nconf_partpol 1,178  0.451   0.673    0   3 \neducacion    1,200  2.168   0.549    1   3 \nsexo         1,200  0.537   0.499    0   1 \nedad         1,200 44.491   17.008  18  89 \nidenpa       1,200 152.000  0.000   152 152\nconf_inst    1,162  2.420   2.489    0  12 \n-------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save:\n\nsave(proc_data,file = \"[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\")\n\nEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\nsave(proc_data,file = \"files/data/latinobarometro_proc.RData\")\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado al principio de este práctico. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos."
  },
  {
    "objectID": "resource/02-resource.html#descriptivos-básicos-de-las-variables",
    "href": "resource/02-resource.html#descriptivos-básicos-de-las-variables",
    "title": "Práctica 2. Operacionalización de variables",
    "section": "Descriptivos básicos de las variables",
    "text": "Descriptivos básicos de las variables\nPodemos conocer ciertas medidas de tendencia central utilizando algunas funciones de dplyr\n\nMedia por grupos\n\nproc_data %&gt;% dplyr::group_by(sexo) %&gt;% summarise(mean(conf_inst, na.rm=TRUE))\n\n# A tibble: 2 × 2\n   sexo `mean(conf_inst, na.rm = TRUE)`\n  &lt;dbl&gt;                           &lt;dbl&gt;\n1     0                            2.48\n2     1                            2.36\n\n\n\nproc_data %&gt;% dplyr::group_by(educacion) %&gt;% summarise(mean(conf_inst, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  educacion `mean(conf_inst, na.rm = TRUE)`\n      &lt;dbl&gt;                           &lt;dbl&gt;\n1         1                            2.96\n2         2                            2.38\n3         3                            2.36\n\n\n\n\nRepresentación\n\nlibrary(sjPlot)\n\nWarning: package 'sjPlot' was built under R version 4.3.3\n\nsjt.xtab(proc_data$educacion, proc_data$conf_inst, encoding = \"UTF-8\")\n\n\n\n \n Educación\n Confianza eninstituciones\n Total\n \n \n\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 10\n 11\n 12\n \n \n \nEducacion basica\n30\n11\n6\n6\n12\n6\n4\n4\n7\n3\n0\n0\n1\n90 \n\n \n \nEducacion media\n268\n95\n83\n79\n121\n45\n24\n29\n28\n3\n4\n1\n0\n780 \n\n \n \nEducacion superior\n99\n35\n41\n26\n36\n20\n13\n8\n9\n5\n0\n0\n0\n292 \n\n \n \nTotal\n397\n141\n130\n111\n169\n71\n41\n41\n44\n11\n4\n1\n1\n1162 \n\nχ2=37.850 · df=24 · Cramer's V=0.128 · Fisher's p=0.127"
  },
  {
    "objectID": "resource/01-resource.html",
    "href": "resource/01-resource.html",
    "title": "Práctico 1. Correlación de Pearson",
    "section": "",
    "text": "El objetivo de esta guía práctica es aprender a calcular y graficar la correlación entre dos variables utilizando R.\nEn detalle, aprenderemos:\n\nQué es una correlación\nCuál es la correlación de Pearson\nCómo calcular una correlación de Pearson y graficarla"
  },
  {
    "objectID": "resource/01-resource.html#diagrama-de-dispersión-nube-de-puntos-o-scatterplot",
    "href": "resource/01-resource.html#diagrama-de-dispersión-nube-de-puntos-o-scatterplot",
    "title": "Práctico 1. Correlación de Pearson",
    "section": "Diagrama de dispersión (nube de puntos o scatterplot)",
    "text": "Diagrama de dispersión (nube de puntos o scatterplot)\nSiempre es recomendable acompañar el valor de la correlación con una exploración gráfica de la distribución bivariada de los datos. El gráfico o diagrama de dispersión es una buena herramienta, ya que muestra la forma, la dirección y la fuerza de la relación entre dos variables cuantitativas.\nEste tipo de gráfico lo podemos realizar usando la librería ggplot2.\n\npacman::p_load(ggplot2)\nplot1 &lt;- ggplot(data, \n                aes(x=educ, y=ing)) + \n                geom_point(colour = \"red\", \n                size = 5)\nplot1\n\n\n\n\nEn el gráfico podemos ver como se crea una nube de puntos en las intersecciones de los valores para ambas variables de cada caso."
  },
  {
    "objectID": "resource/01-resource.html#el-cuarteto-de-anscombe-y-las-limitaciones-de-la-correlación-lineal",
    "href": "resource/01-resource.html#el-cuarteto-de-anscombe-y-las-limitaciones-de-la-correlación-lineal",
    "title": "Práctico 1. Correlación de Pearson",
    "section": "El cuarteto de Anscombe y las limitaciones de la correlación lineal",
    "text": "El cuarteto de Anscombe y las limitaciones de la correlación lineal\nAhora, revisaremos un muy buen ejemplo de la importancia de la exploración gráfica de los datos mediante un ejemplo de Anscombe (1973), que permite visualizar las limitaciones del coeficiente de correlación.\nPrimero, crearemos la base de datos:\n\nanscombe &lt;- data.frame(\n  x1 = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5),\n  y1 = c(8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68),\n  x2 = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5),\n  y2 = c(9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74),\n  x3 = c(10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5),\n  y3 = c(7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73),\n  x4 = c(8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8),\n  y4 = c(6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89)\n)\n\nCalculamos la correlación pares de datos\n\ncor(anscombe$x1, anscombe$y1)\n\n[1] 0.8164205\n\ncor(anscombe$x2, anscombe$y2)\n\n[1] 0.8162365\n\ncor(anscombe$x3, anscombe$y3)\n\n[1] 0.8162867\n\ncor(anscombe$x4, anscombe$y4)\n\n[1] 0.8165214\n\n\nPodemos observar que los valores de las correlaciones son equivalentes, por lo tanto podríamos pensar que todos los pares de columnas se encuentran correlacionados de manera similar.\nPero, ¿será suficiente con esa información? Pasemos a revisar los gráficos de dispersión de cada par de variables.\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n  geom_point(colour = \"red\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso I\")\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n  geom_point(colour = \"green\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso II\")\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n  geom_point(colour = \"yellow\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso III\")\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n  geom_point(colour = \"orange\", \n             size = 5) +\n  geom_smooth(method = \"lm\", se = FALSE, color=\"blue\", size=0.5) +\n  labs(title = \"Caso IV\")\n\n\n\n\nComo vemos, con distintas distribuciones las correlaciones pueden ser las mismas, principalmente porque Pearson es una medida que solo captura relaciones lineales (rectas), además de verse influido fuertemente por valores extremos. Por lo mismo, es relevante siempre una buena visualización de la distribución bivariada de los datos como complemento al cálculo del coeficiente de correlación."
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Presentaciones, lecturas y actividades",
    "section": "",
    "text": "En esta sección se encuentran los documentos de presentación correspondientes a cada clase, lecturas y también actividades prácticas."
  },
  {
    "objectID": "content/10-content.html#lecturas",
    "href": "content/10-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/08-content.html#lecturas",
    "href": "content/08-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/06-content.html#lecturas",
    "href": "content/06-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/02-content.html#lecturas",
    "href": "content/02-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in thsi course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/05-content.html#lecturas",
    "href": "content/05-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science"
  },
  {
    "objectID": "content/07-content.html#lecturas",
    "href": "content/07-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nBrown (2015)The Common Factor Model and Exploratory Factor Analysis"
  },
  {
    "objectID": "content/09-content.html#lecturas",
    "href": "content/09-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/11-content.html#lecturas",
    "href": "content/11-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nPráctica en R"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Metodología Cuantitativa Avanzada\n        ",
    "section": "",
    "text": "Metodología Cuantitativa Avanzada\n        \n        \n            Magister en Ciencias Sociales, mención Sociología de la Modernización\n        \n        \n            MCS7113 • Primer Semestre 2024Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n        \n    \n\n\n\n\n\nProfesores\n\n   Pablo Perez Ahumada\n   Departamento de Sociología FACSO - sala 319\n   pabloperez@uchile.cl\n   pablo_perez_a\n\n\n\n   Kevin Carrasco Quintanilla\n   Departamento de Sociología FACSO - sala 328\n   kevin.carrasco@ug.uchile.cl\n   kevincarrascoq1\n\n\n\n   Daniela Olivares Collío\n   Departamento de Sociología FACSO - sala 328\n   danielaolivarescollio@gmail.com\n   \n\n\n\nInformación del curso\n\n   Viernes\n   Marzo – Julio, 2024\n   09:00-11:45 AM\n   Sala 35. FACSO \n\n\n\nContacto\nA través de correo"
  },
  {
    "objectID": "resource/02-2-resource.html",
    "href": "resource/02-2-resource.html",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \n\n\n\n\n\nRproject: Archivo con extensión .Rproj que permite agrupar todo tu trabajo en una carpeta que contiene todos los archivos vinculados al mismo, facilitando el manejo a través de carpetas.\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado en la sección anterior. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de formación ciudadana y variables de caracterización sociodemográfica utilizando los datos de la encuesta International Civic and Citizenship Education Study ICCS 2016 .\n\n\n\nICCS 2016 fue el cuarto proyecto realizado por la IEA en educación cívica, donde monitoreó las tendencias en el conocimiento y compromiso cívico durante siete años en los países que participaron en ICCS 2009.\nICCS evalúa a estudiantes de octavo grado, siempre que la edad promedio en este nivel de año sea de 13.5 años o más. En países donde la edad promedio de los estudiantes en el grado 8 era inferior a 13.5, el grado 9 se definió como la población objetivo.\nEl presente ejercicio tiene por objetivo procesar los datos para obtener las variables relevantes para el estudio de la Participación cívica, entendida como el grado en que los estudiantes participan en distintas instancias de toma de decisiones políticas, como la intención de voto, discusión de temas políticos y sociales o el centro de estudiantes, etc. Para ello, junto con variables de participación, consideraremos también el sexo de los estudiantes."
  },
  {
    "objectID": "resource/02-2-resource.html#objetivo-de-la-práctica",
    "href": "resource/02-2-resource.html#objetivo-de-la-práctica",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios)"
  },
  {
    "objectID": "resource/02-2-resource.html#proyectos-rutas-estructura-de-carpetas-y-otros",
    "href": "resource/02-2-resource.html#proyectos-rutas-estructura-de-carpetas-y-otros",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "",
    "text": "Rproject: Archivo con extensión .Rproj que permite agrupar todo tu trabajo en una carpeta que contiene todos los archivos vinculados al mismo, facilitando el manejo a través de carpetas.\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado en la sección anterior. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos."
  },
  {
    "objectID": "resource/02-2-resource.html#operacionalización-de-variables",
    "href": "resource/02-2-resource.html#operacionalización-de-variables",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "",
    "text": "El documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de formación ciudadana y variables de caracterización sociodemográfica utilizando los datos de la encuesta International Civic and Citizenship Education Study ICCS 2016 ."
  },
  {
    "objectID": "resource/02-2-resource.html#antecedentes-de-los-datos-a-utilizar",
    "href": "resource/02-2-resource.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "",
    "text": "ICCS 2016 fue el cuarto proyecto realizado por la IEA en educación cívica, donde monitoreó las tendencias en el conocimiento y compromiso cívico durante siete años en los países que participaron en ICCS 2009.\nICCS evalúa a estudiantes de octavo grado, siempre que la edad promedio en este nivel de año sea de 13.5 años o más. En países donde la edad promedio de los estudiantes en el grado 8 era inferior a 13.5, el grado 9 se definió como la población objetivo.\nEl presente ejercicio tiene por objetivo procesar los datos para obtener las variables relevantes para el estudio de la Participación cívica, entendida como el grado en que los estudiantes participan en distintas instancias de toma de decisiones políticas, como la intención de voto, discusión de temas políticos y sociales o el centro de estudiantes, etc. Para ello, junto con variables de participación, consideraremos también el sexo de los estudiantes."
  },
  {
    "objectID": "resource/02-2-resource.html#librerias",
    "href": "resource/02-2-resource.html#librerias",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'stargazer' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\Rtmp6zqlPs\\downloaded_packages\n\n\n\nstargazer installed\n\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva\nhaven: Cargar y exportar bases de datos"
  },
  {
    "objectID": "resource/02-2-resource.html#cargar-base-de-datos",
    "href": "resource/02-2-resource.html#cargar-base-de-datos",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo local en formato .sav: Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos &lt;- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\niccs &lt;- read_sav(\"input/data/original/ISGCHLC3.sav\", encoding = \"UTF-8\")\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (iccs):\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 5081 casos y 351 variables).\n\ndim(iccs) # dimension de la base\n\n[1] 5081  351\n\n\nY si se quiere revisar en formato de planilla de datos:\n\nView(iccs)"
  },
  {
    "objectID": "resource/02-2-resource.html#selección-de-variables-a-utilizar",
    "href": "resource/02-2-resource.html#selección-de-variables-a-utilizar",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto votar:\n\n\nfind_var(data = iccs,\"Vote\")\n\n  col.nr var.name\n1    179  IS3G31A\n2    180  IS3G31B\n3    189  IS3G31K\n4    190  IS3G31L\n5    191  IS3G32A\n                                                                                                               var.label\n1                        Participating in Society/When an adult, what do you think you will do/Vote in &lt;local elections&gt;\n2                     Participating in Society/When an adult, what do you think you will do/Vote in &lt;national elections&gt;\n3              Participating in Society/When an adult, what do you think you will do/Vote in &lt;state, province elections&gt;\n4                       Participating in Society/When an adult, what do you think you will do/Vote in European elections\n5 Participating in Society/How likely participate/Vote school election of &lt;class representatives&gt; or &lt;school parliament&gt;\n\n\nNos informa que hay una serie de variables relacionadas con votar.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\nproc_data &lt;- iccs %&gt;% select(IS3G31B, # Intención de Voto en elecciones nacionales\n                          IS3G31E, # Intención de unirse a un partido político\n                          IS3G31G, # Intencion candidato en elecciones locales\n                          S_GENDER) # genero \n\n# Comprobar\nnames(proc_data)\n\n[1] \"IS3G31B\"  \"IS3G31E\"  \"IS3G31G\"  \"S_GENDER\"\n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                                                                                          IS3G31B \n             \"Participating in Society/When an adult, what do you think you will do/Vote in &lt;national elections&gt;\" \n                                                                                                          IS3G31E \n                   \"Participating in Society/When an adult, what do you think you will do/Join a political party\" \n                                                                                                          IS3G31G \n\"Participating in Society/When an adult, what do you think you will do/Stand as a candidate in &lt;local elections&gt;\" \n                                                                                                         S_GENDER \n                                                                                                 \"Student gender\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación."
  },
  {
    "objectID": "resource/02-2-resource.html#procesamiento-de-variables",
    "href": "resource/02-2-resource.html#procesamiento-de-variables",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Intención de participación\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n\n\n\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$IS3G31B)\n\nParticipating in Society/When an adult, what do you think you will do/Vote in &lt;national elections&gt; (x) &lt;numeric&gt; \n# total N=5081 valid N=4944 mean=1.77 sd=0.92\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this | 2441 | 48.04 |   49.37 |  49.37\n    2 |      I would probably do this | 1589 | 31.27 |   32.14 |  81.51\n    3 |  I would probably not do this |  534 | 10.51 |   10.80 |  92.31\n    4 | I would certainly not do this |  380 |  7.48 |    7.69 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                          &lt;NA&gt; |  137 |  2.70 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “invalid” (7), “Not administered” (8) y “ommited” (9), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA), pero vienen recodificados como NA en la base (hay 137 NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos intención de voto), así que en la recodificiación nos haremos cargo de reordenar las categorías.\nb. Recodificación\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\nproc_data$IS3G31B &lt;- recode(proc_data$IS3G31B, \"1=4; 2=3; 3=2; 4=1\")\nproc_data$IS3G31E &lt;- recode(proc_data$IS3G31E, \"1=4; 2=3; 3=2; 4=1\")\nproc_data$IS3G31G &lt;- recode(proc_data$IS3G31G, \"1=4; 2=3; 3=2; 4=1\")\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data &lt;- proc_data %&gt;% rename(\"voto\"=IS3G31B, # Intencion de voto\n                                  \"candidato\"=IS3G31E, # Intencion de ser candidato\n                                  \"partido\"=IS3G31G) # Intencion de unirse a partido politico\n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nget_label(proc_data$voto)\n\n[1] \"Participating in Society/When an adult, what do you think you will do/Vote in &lt;national elections&gt;\"\n\nproc_data$voto &lt;- set_label(x = proc_data$voto,label = \"Intencion de voto\")\n\nget_label(proc_data$candidato)\n\n[1] \"Participating in Society/When an adult, what do you think you will do/Join a political party\"\n\nproc_data$candidato  &lt;- set_label(x = proc_data$candidato, label = \"Intencion de ser candidato\")\n\nget_label(proc_data$partido)\n\n[1] \"Participating in Society/When an adult, what do you think you will do/Stand as a candidate in &lt;local elections&gt;\"\n\nproc_data$partido  &lt;- set_label(x = proc_data$partido, label = \"Intencion de unirse a partido politico\")\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea el promedio de los tres items de intención de participación\n\nproc_data &lt;- proc_data %&gt;% rowwise() %&gt;% mutate(int_part = mean(c(voto, candidato, partido), na.rm = T))\nsummary(proc_data$int_part)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   2.000   2.333   2.428   3.000   4.000     125 \n\n\n\nget_label(proc_data$int_part)\n\nNULL\n\n\nVemos que no tiene etiqueta.\n\nproc_data$int_part  &lt;- set_label(x = proc_data$int_part, label = \"Intención de participación\")\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$voto)\n\nIntencion de voto (x) &lt;numeric&gt; \n# total N=5081 valid N=4944 mean=3.23 sd=0.92\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this |  380 |  7.48 |    7.69 |   7.69\n    2 |      I would probably do this |  534 | 10.51 |   10.80 |  18.49\n    3 |  I would probably not do this | 1589 | 31.27 |   32.14 |  50.63\n    4 | I would certainly not do this | 2441 | 48.04 |   49.37 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                          &lt;NA&gt; |  137 |  2.70 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$candidato)\n\nIntencion de ser candidato (x) &lt;numeric&gt; \n# total N=5081 valid N=4922 mean=2.07 sd=0.93\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this | 1479 | 29.11 |   30.05 |  30.05\n    2 |      I would probably do this | 2102 | 41.37 |   42.71 |  72.75\n    3 |  I would probably not do this |  859 | 16.91 |   17.45 |  90.21\n    4 | I would certainly not do this |  482 |  9.49 |    9.79 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                          &lt;NA&gt; |  159 |  3.13 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$partido)\n\nIntencion de unirse a partido politico (x) &lt;numeric&gt; \n# total N=5081 valid N=4939 mean=1.98 sd=0.93\n\nValue |                         Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------\n    1 |     I would certainly do this | 1741 | 34.26 |   35.25 |  35.25\n    2 |      I would probably do this | 2015 | 39.66 |   40.80 |  76.05\n    3 |  I would probably not do this |  739 | 14.54 |   14.96 |  91.01\n    4 | I would certainly not do this |  444 |  8.74 |    8.99 | 100.00\n    7 |                       Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 |              Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |                       Omitted |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |                          &lt;NA&gt; |  142 |  2.79 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled. Aprovechamos también de pasarlas a español\n\nproc_data$voto &lt;- set_labels(proc_data$voto,\n            labels=c( \"Ciertamente no lo haria\"=1,\n                      \"Probablemente no lo haria\"=2,\n                      \"Probablemente lo haria\"=3,\n                      \"Ciertamente lo haria\"=4))\n\nproc_data$candidato &lt;- set_labels(proc_data$candidato,\n            labels=c( \"Ciertamente no lo haria\"=1,\n                      \"Probablemente no lo haria\"=2,\n                      \"Probablemente lo haria\"=3,\n                      \"Ciertamente lo haria\"=4))\n\nproc_data$partido &lt;- set_labels(proc_data$partido,\n            labels=c( \"Ciertamente no lo haria\"=1,\n                      \"Probablemente no lo haria\"=2,\n                      \"Probablemente lo haria\"=3,\n                      \"Ciertamente lo haria\"=4))\n\ny volvemos a revisar\n\nfrq(proc_data$voto)\n\nIntencion de voto (x) &lt;numeric&gt; \n# total N=5081 valid N=4944 mean=3.23 sd=0.92\n\nValue |                     Label |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------------------------\n    1 |   Ciertamente no lo haria |  380 |  7.48 |    7.69 |   7.69\n    2 | Probablemente no lo haria |  534 | 10.51 |   10.80 |  18.49\n    3 |    Probablemente lo haria | 1589 | 31.27 |   32.14 |  50.63\n    4 |      Ciertamente lo haria | 2441 | 48.04 |   49.37 | 100.00\n &lt;NA&gt; |                      &lt;NA&gt; |  137 |  2.70 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$partido)\n\nIntencion de unirse a partido politico (x) &lt;numeric&gt; \n# total N=5081 valid N=4939 mean=1.98 sd=0.93\n\nValue |                     Label |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------------------------\n    1 |   Ciertamente no lo haria | 1741 | 34.26 |   35.25 |  35.25\n    2 | Probablemente no lo haria | 2015 | 39.66 |   40.80 |  76.05\n    3 |    Probablemente lo haria |  739 | 14.54 |   14.96 |  91.01\n    4 |      Ciertamente lo haria |  444 |  8.74 |    8.99 | 100.00\n &lt;NA&gt; |                      &lt;NA&gt; |  142 |  2.79 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Sexo\n\n[S_GENDER] = Sexo\n\na. Descriptivo\n\nfrq(proc_data$S_GENDER)\n\nStudent gender (x) &lt;numeric&gt; \n# total N=5081 valid N=5081 mean=0.49 sd=0.50\n\nValue |            Label |    N | Raw % | Valid % | Cum. %\n----------------------------------------------------------\n    0 |              Boy | 2577 | 50.72 |   50.72 |  50.72\n    1 |             Girl | 2504 | 49.28 |   49.28 | 100.00\n    7 |          Invalid |    0 |  0.00 |    0.00 | 100.00\n    8 | Not administered |    0 |  0.00 |    0.00 | 100.00\n    9 |          Omitted |    0 |  0.00 |    0.00 | 100.00\n &lt;NA&gt; |             &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\nEsta variable generalmente no tiene problemas de etiquetado, viene también con niños=0 y niñas=1\nc. Etiquetado\nCambio de nombre de la variable\n\nproc_data &lt;- proc_data %&gt;% rename(\"sexo\"=S_GENDER)\n\nPodemos pasar las categorías a español:\n\nproc_data$sexo &lt;- set_labels(proc_data$sexo,\n            labels=c( \"Ninios\"=0,\n                      \"Ninias\"=1))\n\nTambién queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$sexo)\n\n[1] \"Student gender\"\n\nproc_data$sexo &lt;- set_label(x = proc_data$sexo,label = \"Sexo\")\n\nRevisar con un nuevo descriptivo:\n\nfrq(proc_data$sexo)\n\nSexo (x) &lt;numeric&gt; \n# total N=5081 valid N=5081 mean=0.49 sd=0.50\n\nValue |  Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninios | 2577 | 50.72 |   50.72 |  50.72\n    1 | Ninias | 2504 | 49.28 |   49.28 | 100.00\n &lt;NA&gt; |   &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;"
  },
  {
    "objectID": "resource/02-2-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "resource/02-2-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\nproc_data &lt;-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n==========================================\nStatistic   N   Mean  St. Dev.  Min   Max \n------------------------------------------\nvoto      4,944 3.232  0.925     1     4  \ncandidato 4,922 2.070  0.928     1     4  \npartido   4,939 1.977  0.928     1     4  \nsexo      5,081 0.493  0.500     0     1  \nint_part  4,956 2.428  0.726   1.000 4.000\n------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save. En este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\nsave(proc_data,file = \"input/data/proc/iccs_proc.RData\")"
  },
  {
    "objectID": "resource/02-2-resource.html#descriptivos-básicos-de-las-variables",
    "href": "resource/02-2-resource.html#descriptivos-básicos-de-las-variables",
    "title": "Práctica 2.2 Organización de trabajo y operacionalización de variables",
    "section": "Descriptivos básicos de las variables",
    "text": "Descriptivos básicos de las variables\nPodemos conocer ciertas medidas de tendencia central utilizando algunas funciones de dplyr\n\nMedia por grupos\n\nproc_data %&gt;% dplyr::group_by(sexo) %&gt;% summarise(mean(int_part, na.rm=TRUE))\n\n# A tibble: 2 × 2\n  sexo       `mean(int_part, na.rm = TRUE)`\n  &lt;dbl+lbl&gt;                           &lt;dbl&gt;\n1 0 [Ninios]                           2.46\n2 1 [Ninias]                           2.40\n\n\n\n\nRepresentación\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:sjlabelled':\n\n    as_label\n\nproc_data %&gt;% na.omit() %&gt;% \n  ggplot(aes(x=as_factor(voto))) +\n  geom_bar()+\n  theme_bw()"
  },
  {
    "objectID": "resource/04-resource.html",
    "href": "resource/04-resource.html",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "El informe “Chile: la sombra de Pinochet”, en su medición de febrero de 2023, arrojó que un 36% de los encuestados considera que las Fuerzas Armadas “tenían razón para dar el golpe de Estado”, mientras que un 42% responde que “nunca hay razón”. Fuente: El Mostrador\n¿Qué factores podrían influir en que las personas apoyen en mayor medida un gobierno autoritario?\n\n\nEl desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de correlaciones y regresiones con R, que son necesarios para luego poder analizar e interpretar estas relaciones.\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: disponible acá.\nAnálisis: este documento\n\n\n\n\n\n\n\npacman::p_load(dplyr,\n  ggpubr, #graficos\n               stargazer, # Reporte\n               texreg,\n               ggplot2,\n               gridExtra, #unir graficos\nsjPlot, sjmisc, # reporte y gráficos\nsjlabelled, # etiquetas\ncorrplot, # grafico correlaciones\nxtable, # Reporte\nsummarytools, #reporte\nHmisc, # varias funciones\npsych, # fa y principal factors\npsy, # scree plot function\nnFactors, # parallel\nGPArotation) # rotación\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'corrplot', 'ggsci', 'cowplot', 'ggsignif', 'polynom', 'rstatix'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'corrplot' successfully unpacked and MD5 sums checked\npackage 'ggsci' successfully unpacked and MD5 sums checked\npackage 'cowplot' successfully unpacked and MD5 sums checked\npackage 'ggsignif' successfully unpacked and MD5 sums checked\npackage 'polynom' successfully unpacked and MD5 sums checked\npackage 'rstatix' successfully unpacked and MD5 sums checked\npackage 'ggpubr' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nggpubr installed\n\n\nWarning: package 'ggpubr' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'texreg' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\ntexreg installed\n\n\nWarning: package 'texreg' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'xtable' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nxtable installed\n\n\nWarning: package 'xtable' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'lobstr', 'plyr', 'reshape2', 'checkmate', 'magick', 'pander', 'pryr', 'rapportools'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'lobstr' successfully unpacked and MD5 sums checked\npackage 'plyr' successfully unpacked and MD5 sums checked\npackage 'reshape2' successfully unpacked and MD5 sums checked\npackage 'checkmate' successfully unpacked and MD5 sums checked\npackage 'magick' successfully unpacked and MD5 sums checked\npackage 'pander' successfully unpacked and MD5 sums checked\npackage 'pryr' successfully unpacked and MD5 sums checked\npackage 'rapportools' successfully unpacked and MD5 sums checked\npackage 'summarytools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nsummarytools installed\n\n\nWarning: package 'summarytools' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'htmlwidgets', 'htmlTable', 'Formula'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'htmlwidgets' successfully unpacked and MD5 sums checked\npackage 'htmlTable' successfully unpacked and MD5 sums checked\npackage 'Formula' successfully unpacked and MD5 sums checked\npackage 'Hmisc' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nHmisc installed\n\n\nWarning: package 'Hmisc' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'psy' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\npsy installed\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'nFactors' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nnFactors installed\n\n\nWarning: package 'nFactors' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'GPArotation' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nGPArotation installed\n\n\nWarning: package 'GPArotation' was built under R version 4.3.3\n\n\n\n\n\nLectura de datos\n\nload(\"files/data/latinobarometro_pract4.RData\")\n\no directo de la página\n\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/latinobarometro_pract4.RData\"))\n\n\n\n\n\n\n\n\nview(dfSummary(proc_data,\n               plain.ascii = FALSE,\n               style = \"grid\",\n               tmp.img.dir = \"/tmp\",\n               graph.magnif = 0.75,\n               headings = F,  # encabezado\n               varnumbers = F, # num variable\n               labels.col = T, # etiquetas\n               na.col = T,    # missing\n               graph.col = F, # plot\n               valid.col = T, # n valido\n               col.widths = c(1000,10,10,10,10,10)), method=\"render\")\n\n\n\n\n\n\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nValid\nMissing\n\n\n\n\napoyo_autoritarismo [numeric]\n\n\n\n\nMean (sd) : 2.2 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.4)\n\n\n\n\n\n\n1\n:\n289\n(\n26.2%\n)\n\n\n2\n:\n453\n(\n41.1%\n)\n\n\n3\n:\n265\n(\n24.0%\n)\n\n\n4\n:\n96\n(\n8.7%\n)\n\n\n\n1103 (91.9%)\n97 (8.1%)\n\n\nconf_fa [numeric]\nConfianza: Fuerzas armadas\n\n\n\nMean (sd) : 2.1 (1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.5)\n\n\n\n\n\n\n1\n:\n372\n(\n31.7%\n)\n\n\n2\n:\n412\n(\n35.1%\n)\n\n\n3\n:\n278\n(\n23.7%\n)\n\n\n4\n:\n113\n(\n9.6%\n)\n\n\n\n1175 (97.9%)\n25 (2.1%)\n\n\nconf_pol [numeric]\nConfianza: Policías\n\n\n\nMean (sd) : 2 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.5)\n\n\n\n\n\n\n1\n:\n457\n(\n38.8%\n)\n\n\n2\n:\n363\n(\n30.8%\n)\n\n\n3\n:\n280\n(\n23.8%\n)\n\n\n4\n:\n77\n(\n6.5%\n)\n\n\n\n1177 (98.1%)\n23 (1.9%)\n\n\nconf_iglesia [numeric]\nConfianza: Iglesia\n\n\n\nMean (sd) : 2 (1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.5)\n\n\n\n\n\n\n1\n:\n463\n(\n40.2%\n)\n\n\n2\n:\n339\n(\n29.5%\n)\n\n\n3\n:\n263\n(\n22.8%\n)\n\n\n4\n:\n86\n(\n7.5%\n)\n\n\n\n1151 (95.9%)\n49 (4.1%)\n\n\nconf_cong [numeric]\nConfianza: Congreso\n\n\n\nMean (sd) : 1.6 (0.7)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.4)\n\n\n\n\n\n\n1\n:\n628\n(\n53.3%\n)\n\n\n2\n:\n408\n(\n34.6%\n)\n\n\n3\n:\n134\n(\n11.4%\n)\n\n\n4\n:\n8\n(\n0.7%\n)\n\n\n\n1178 (98.2%)\n22 (1.8%)\n\n\nconf_gob [numeric]\nConfianza: Gobierno\n\n\n\nMean (sd) : 1.7 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n624\n(\n52.8%\n)\n\n\n2\n:\n358\n(\n30.3%\n)\n\n\n3\n:\n176\n(\n14.9%\n)\n\n\n4\n:\n23\n(\n1.9%\n)\n\n\n\n1181 (98.4%)\n19 (1.6%)\n\n\nconf_jud [numeric]\nConfianza: Poder judicial\n\n\n\nMean (sd) : 1.7 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n556\n(\n46.9%\n)\n\n\n2\n:\n438\n(\n36.9%\n)\n\n\n3\n:\n164\n(\n13.8%\n)\n\n\n4\n:\n28\n(\n2.4%\n)\n\n\n\n1186 (98.8%)\n14 (1.2%)\n\n\nconf_partpol [numeric]\nConfianza: Partidos politicos\n\n\n\nMean (sd) : 1.5 (0.7)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n760\n(\n64.5%\n)\n\n\n2\n:\n313\n(\n26.6%\n)\n\n\n3\n:\n97\n(\n8.2%\n)\n\n\n4\n:\n8\n(\n0.7%\n)\n\n\n\n1178 (98.2%)\n22 (1.8%)\n\n\nconf_presi [numeric]\nConfianza: Presidente\n\n\n\nMean (sd) : 1.7 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n639\n(\n54.2%\n)\n\n\n2\n:\n337\n(\n28.6%\n)\n\n\n3\n:\n173\n(\n14.7%\n)\n\n\n4\n:\n29\n(\n2.5%\n)\n\n\n\n1178 (98.2%)\n22 (1.8%)\n\n\nreeduc_1 [numeric]\n\n\n\n\nMean (sd) : 5.1 (1.2)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 5 ≤ 7\n\n\nIQR (CV) : 0 (0.2)\n\n\n\n\n\n\n1\n:\n8\n(\n0.7%\n)\n\n\n2\n:\n53\n(\n4.4%\n)\n\n\n3\n:\n36\n(\n3.0%\n)\n\n\n4\n:\n161\n(\n13.4%\n)\n\n\n5\n:\n643\n(\n53.6%\n)\n\n\n6\n:\n109\n(\n9.1%\n)\n\n\n7\n:\n190\n(\n15.8%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\nsexo [numeric]\nSexo\n\n\n\nMin : 0\n\n\nMean : 0.5\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n555\n(\n46.2%\n)\n\n\n1\n:\n645\n(\n53.8%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 44.5 (17)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 43 ≤ 89\n\n\nIQR (CV) : 28 (0.4)\n\n\n\n69 distinct values\n1200 (100.0%)\n0 (0.0%)\n\n\nidenpa [numeric]\n\n1 distinct value\n\n\n\n152\n:\n1200\n(\n100.0%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\neducacion [character]\nEducación\n\n\n\n1. Educacion basica\n\n\n2. Educacion media\n\n\n3. Educacion superior\n\n\n\n\n\n\n97\n(\n8.1%\n)\n\n\n804\n(\n67.0%\n)\n\n\n299\n(\n24.9%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-04-04\n\n\n\n\nproc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi) %&gt;%\n  plot_stackfrq(sort.frq = \"first.desc\", geom.colors = \"OrRd\") + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\ncorMat  &lt;- proc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi) %&gt;%\n  cor(use = \"complete.obs\")  # estimar matriz pearson\noptions(digits=2)\ncorMat\n\n             conf_fa conf_pol conf_iglesia conf_gob conf_cong conf_jud\nconf_fa         1.00     0.79         0.51     0.60      0.44     0.49\nconf_pol        0.79     1.00         0.58     0.64      0.46     0.50\nconf_iglesia    0.51     0.58         1.00     0.57      0.49     0.43\nconf_gob        0.60     0.64         0.57     1.00      0.65     0.60\nconf_cong       0.44     0.46         0.49     0.65      1.00     0.53\nconf_jud        0.49     0.50         0.43     0.60      0.53     1.00\nconf_partpol    0.34     0.37         0.42     0.58      0.67     0.55\nconf_presi      0.60     0.63         0.54     0.80      0.55     0.52\n             conf_partpol conf_presi\nconf_fa              0.34       0.60\nconf_pol             0.37       0.63\nconf_iglesia         0.42       0.54\nconf_gob             0.58       0.80\nconf_cong            0.67       0.55\nconf_jud             0.55       0.52\nconf_partpol         1.00       0.52\nconf_presi           0.52       1.00\n\n\n\n\n\nproc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi) %&gt;%\n  tab_corr(triangle = \"lower\")\n\n\n\n\n \nConfianza: Fuerzas armadas\nConfianza: Policías\nConfianza: Iglesia\nConfianza: Gobierno\nConfianza: Congreso\nConfianza: Poder judicial\nConfianza: Partidos politicos\nConfianza: Presidente\n\n\nConfianza: Fuerzas armadas\n \n \n \n \n \n \n \n \n\n\nConfianza: Policías\n0.790***\n \n \n \n \n \n \n \n\n\nConfianza: Iglesia\n0.512***\n0.580***\n \n \n \n \n \n \n\n\nConfianza: Gobierno\n0.599***\n0.641***\n0.571***\n \n \n \n \n \n\n\nConfianza: Congreso\n0.437***\n0.464***\n0.495***\n0.652***\n \n \n \n \n\n\nConfianza: Poder judicial\n0.492***\n0.503***\n0.431***\n0.600***\n0.535***\n \n \n \n\n\nConfianza: Partidos politicos\n0.335***\n0.373***\n0.422***\n0.576***\n0.670***\n0.552***\n \n \n\n\nConfianza: Presidente\n0.597***\n0.634***\n0.538***\n0.801***\n0.547***\n0.524***\n0.520***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\n\n\n\ncorrplot(corMat, type=\"lower\")\n\n\n\n\n\n\n\n\nM=corMat\ndiag(M) = NA\nrownames(M) &lt;- c(\"A. Confianza: Fuerzas armadas\",\n                         \"B. Confianza: Policías\",\n                         \"C. Confianza: Iglesia\",\n                         \"D. Confianza: Gobierno\",\n                         \"E. Confianza: Congreso\",\n                         \"F. Confianza: Poder judicial\",\n                         \"G. Confianza: Part. políticos\",\n                         \"H. Confianza: Presidente\")\ncolnames(M) &lt;-c(\"(A)\", \"(B)\",\"(C)\", \"(D)\", \"(E)\", \"(F)\", \"(G)\", \"(H)\")\n\ncorrplot::corrplot(M,\n  method = \"color\",\n  addCoef.col = \"#000390\",\n  type = \"upper\",\n  tl.col = \"black\",\n  col=colorRampPalette(c(\"white\",\"#0068DC\"))(12),\n  bg = \"white\",\n  na.label = \"-\")\n\n\n\n\n\n\n\n\n¿Qué se puede deducir de la matriz de correlaciones en relación a la estructura subyacente en términos de variables latentes? No hay claridad de grupos de indicadores asociados entre sí.\n\n\nKMO (Kaiser, Meyer, Olkin Measure of Sampling Adequacy):\n\nVaría entre 0 y 1. Contrasta si las correlaciones parciales entre las variables son pequeñas\nValores pequeños (menores a 0.5) indican que los datos no serían adecuados para AFE, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables.\n\n\nKMO(corMat)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = corMat)\nOverall MSA =  0.88\nMSA for each item = \n     conf_fa     conf_pol conf_iglesia     conf_gob    conf_cong     conf_jud \n        0.85         0.85         0.96         0.87         0.89         0.94 \nconf_partpol   conf_presi \n        0.87         0.88 \n\n\nEn este caso las correlaciones son altas, por lo que los datos sí son adecuados para AFE.\n\n\n\nSe utiliza para evluar la hipótesis que la matriz de correlaciones es una matriz identidad (diagonal 1 y bajo la diagonal 0)\n\nSe busca significación (p &lt; 0.05) ya que se espera que las variables estén correlacionadas\n\n\ncortest.bartlett(corMat, n = 1200)\n\n$chisq\n[1] 6064\n\n$p.value\n[1] 0\n\n$df\n[1] 28\n\n\nEn este caso el valor p es 0, así que hay significación estadística\n\n\n\n\nconfianza &lt;- proc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi)\nscree.plot(confianza)\n\n\n\n\n\nfa.parallel(corMat, n.obs=1200)\n\n\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  1 \n\n\n\nlibrary(nFactors)\nev &lt;- eigen(corMat) # get eigenvalues\nap &lt;- parallel(subject=1200,var=8,\n  rep=100,cent=.05)\nnS &lt;- nScree(x=ev$values, aparallel=ap$eigen$qevpea)\nplotnScree(nS)\n\n\n\n\n\n\n\nejes principales\n\nfac_pa &lt;- fa(r = confianza, nfactors = 3, fm= \"pa\")\n\nmaximum iteration exceeded\n\n#summary(fac_pa)\nfac_pa\n\nFactor Analysis using method =  pa\nCall: fa(r = confianza, nfactors = 3, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n               PA1   PA3   PA2   h2    u2 com\nconf_fa       0.83  0.03 -0.01 0.72 0.280 1.0\nconf_pol      0.94 -0.02  0.00 0.87 0.134 1.0\nconf_iglesia  0.39  0.18  0.18 0.43 0.565 1.9\nconf_gob     -0.04  1.01  0.00 0.97 0.035 1.0\nconf_cong     0.09  0.14  0.63 0.63 0.373 1.1\nconf_jud      0.24  0.11  0.45 0.49 0.511 1.7\nconf_partpol -0.05 -0.04  0.93 0.78 0.222 1.0\nconf_presi    0.20  0.63  0.05 0.69 0.315 1.2\n\n                       PA1  PA3  PA2\nSS loadings           2.09 1.75 1.72\nProportion Var        0.26 0.22 0.22\nCumulative Var        0.26 0.48 0.70\nProportion Explained  0.38 0.31 0.31\nCumulative Proportion 0.38 0.69 1.00\n\n With factor correlations of \n     PA1  PA3  PA2\nPA1 1.00 0.72 0.51\nPA3 0.72 1.00 0.71\nPA2 0.51 0.71 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  8.1  with prob &lt;  0.32 \nThe total n.obs was  1200  with Likelihood Chi Square =  38  with prob &lt;  3.7e-06 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.06  and the 90 % confidence intervals are  0.042 0.08\nBIC =  -12\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA3  PA2\nCorrelation of (regression) scores with factors   0.96 0.98 0.93\nMultiple R square of scores with factors          0.91 0.97 0.87\nMinimum correlation of possible factor scores     0.83 0.94 0.73\n\n\nMaximum likelihood\nMaximiza la posibilidad de que los parámetros reproduzcan los datos observados\n\nfac_ml &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\")\nsummary(fac_ml)\n\n\nFactor analysis with Call: fa(r = confianza, nfactors = 3, fm = \"ml\")\n\nTest of the hypothesis that 3 factors are sufficient.\nThe degrees of freedom for the model is 7  and the objective function was  0.03 \nThe number of observations was  1200  with Chi Square =  32  with prob &lt;  3.4e-05 \n\nThe root mean square of the residuals (RMSA) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 10 % confidence intervals are  0.037 0.075\nBIC =  -17\n With factor correlations of \n     ML2  ML1  ML3\nML2 1.00 0.71 0.50\nML1 0.71 1.00 0.68\nML3 0.50 0.68 1.00\n\n\n\n\n\nVarimax (ortogonal)\n\nfac_ml_var &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\nFactor Analysis using method =  ml\nCall: fa(r = confianza, nfactors = 3, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n              ML2  ML3  ML1   h2    u2 com\nconf_fa      0.80 0.20 0.24 0.73 0.266 1.3\nconf_pol     0.86 0.22 0.25 0.85 0.155 1.3\nconf_iglesia 0.49 0.33 0.28 0.44 0.565 2.4\nconf_gob     0.40 0.41 0.82 1.00 0.005 2.0\nconf_cong    0.28 0.66 0.32 0.61 0.387 1.9\nconf_jud     0.37 0.52 0.29 0.49 0.510 2.5\nconf_partpol 0.15 0.87 0.19 0.81 0.190 1.2\nconf_presi   0.48 0.38 0.56 0.68 0.322 2.8\n\n                       ML2  ML3  ML1\nSS loadings           2.24 1.96 1.41\nProportion Var        0.28 0.24 0.18\nCumulative Var        0.28 0.52 0.70\nProportion Explained  0.40 0.35 0.25\nCumulative Proportion 0.40 0.75 1.00\n\nMean item complexity =  1.9\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  9.3  with prob &lt;  0.23 \nThe total n.obs was  1200  with Likelihood Chi Square =  32  with prob &lt;  3.4e-05 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 90 % confidence intervals are  0.037 0.075\nBIC =  -17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2 ML3  ML1\nCorrelation of (regression) scores with factors   0.92 0.9 0.96\nMultiple R square of scores with factors          0.85 0.8 0.92\nMinimum correlation of possible factor scores     0.69 0.6 0.85\n\n\nPromax (oblicua)\n\nfac_ml_pro &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\nFactor Analysis using method =  ml\nCall: fa(r = confianza, nfactors = 3, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n               ML2   ML3   ML1   h2    u2 com\nconf_fa       0.93 -0.07 -0.04 0.73 0.266 1.0\nconf_pol      1.00 -0.07 -0.06 0.85 0.155 1.0\nconf_iglesia  0.43  0.17  0.12 0.44 0.565 1.5\nconf_gob     -0.09 -0.04  1.10 1.00 0.005 1.0\nconf_cong     0.02  0.65  0.14 0.61 0.387 1.1\nconf_jud      0.21  0.45  0.11 0.49 0.510 1.5\nconf_partpol -0.13  1.07 -0.13 0.81 0.190 1.1\nconf_presi    0.21  0.06  0.60 0.68 0.322 1.3\n\n                       ML2  ML3  ML1\nSS loadings           2.14 1.78 1.67\nProportion Var        0.27 0.22 0.21\nCumulative Var        0.27 0.49 0.70\nProportion Explained  0.38 0.32 0.30\nCumulative Proportion 0.38 0.70 1.00\n\n With factor correlations of \n     ML2  ML3  ML1\nML2 1.00 0.65 0.78\nML3 0.65 1.00 0.77\nML1 0.78 0.77 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  9.3  with prob &lt;  0.23 \nThe total n.obs was  1200  with Likelihood Chi Square =  32  with prob &lt;  3.4e-05 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 90 % confidence intervals are  0.037 0.075\nBIC =  -17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML3  ML1\nCorrelation of (regression) scores with factors   0.96 0.95 1.00\nMultiple R square of scores with factors          0.92 0.90 1.00\nMinimum correlation of possible factor scores     0.84 0.80 0.99\n\n\n\n\n\n\ntab_fa(confianza, rotation = \"varimax\",show.comm = TRUE, title = \"Análisis factorial confianza instituciones\")\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  NA \n\n\n\nAnálisis factorial confianza instituciones\n\n\n \nFactor 1\nFactor 2\nFactor 3\nCommunality\n\n\nConfianza: Fuerzas armadas\n0.80\n0.20\n0.24\n0.73\n\n\nConfianza: Policías\n0.86\n0.22\n0.25\n0.85\n\n\nConfianza: Iglesia\n0.49\n0.33\n0.28\n0.44\n\n\nConfianza: Gobierno\n0.40\n0.41\n0.82\n0.99\n\n\nConfianza: Congreso\n0.28\n0.66\n0.32\n0.61\n\n\nConfianza: Poder judicial\n0.37\n0.52\n0.29\n0.49\n\n\nConfianza: Partidos politicos\n0.15\n0.87\n0.19\n0.81\n\n\nConfianza: Presidente\n0.48\n0.38\n0.56\n0.68\n\n\nTotal Communalities\n\n5.60\n\n\nCronbach's α\n0.83\n0.81\n0.89\n\n\n\n\n\n\nLuego de realizar el Análisis factorial exploratorio existen varias alternativas sobre los pasos a seguir. Por ejemplo, es posible estimar un promedio simple entre cada una de las variables de los factores. Otra opción es estimar puntajes factoriales.\n\n\n\nLos puntajes factoriales son “estimaciones” (predicciones) de puntajes en los factores para cada observación en los datos.\n\nEstos puntajes pueden utilizarse en análisis posteriores\nSe pueden calcular puntajes para cada observación en cada factor utilizando un método de regresión\nEstas nuevas variables se estandarizan con media 0 y desviación estándar 1\n\n\nfac_ml &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\", scores=\"regression\")\nfac_ml # ojo que ML2 es el factor 1; ML1=factor 3 y ML3=factor 2 de la tabla que da sjPlot\n\nFactor Analysis using method =  ml\nCall: fa(r = confianza, nfactors = 3, scores = \"regression\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n               ML2   ML1   ML3   h2    u2 com\nconf_fa       0.86  0.00 -0.01 0.73 0.266 1.0\nconf_pol      0.93 -0.01  0.00 0.85 0.155 1.0\nconf_iglesia  0.42  0.15  0.18 0.44 0.565 1.6\nconf_gob     -0.03  1.02  0.00 1.00 0.005 1.0\nconf_cong     0.08  0.19  0.59 0.61 0.387 1.2\nconf_jud      0.24  0.15  0.42 0.49 0.510 1.8\nconf_partpol -0.04 -0.04  0.94 0.81 0.190 1.0\nconf_presi    0.23  0.58  0.09 0.68 0.322 1.4\n\n                       ML2  ML1  ML3\nSS loadings           2.15 1.75 1.70\nProportion Var        0.27 0.22 0.21\nCumulative Var        0.27 0.49 0.70\nProportion Explained  0.38 0.31 0.30\nCumulative Proportion 0.38 0.70 1.00\n\n With factor correlations of \n     ML2  ML1  ML3\nML2 1.00 0.71 0.50\nML1 0.71 1.00 0.68\nML3 0.50 0.68 1.00\n\nMean item complexity =  1.3\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  9.3  with prob &lt;  0.23 \nThe total n.obs was  1200  with Likelihood Chi Square =  32  with prob &lt;  3.4e-05 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 90 % confidence intervals are  0.037 0.075\nBIC =  -17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML1  ML3\nCorrelation of (regression) scores with factors   0.95 1.00 0.93\nMultiple R square of scores with factors          0.91 1.00 0.87\nMinimum correlation of possible factor scores     0.82 0.99 0.75\n\nproc_data &lt;- cbind(proc_data, fac_ml$scores)\nhead(proc_data)\n\n  apoyo_autoritarismo conf_fa conf_pol conf_iglesia conf_cong conf_gob conf_jud\n1                   1       2        2            3         1        1        3\n2                   1       1        1            1         1        1        2\n3                   1       1        1            1         1        1        1\n4                   1       2        2            1         1        1        3\n5                   1       1        2            3         2        1        2\n6                   1       2        3            3         1        1        3\n  conf_partpol conf_presi reeduc_1 sexo edad idenpa          educacion    ML2\n1            1          1        1    1   54    152   Educacion basica  0.016\n2            1          1        5    0   51    152    Educacion media -1.066\n3            1          1        5    0   39    152    Educacion media -1.118\n4            1          1        6    1   30    152 Educacion superior -0.126\n5            2          1        5    1   24    152    Educacion media -0.365\n6            1          1        5    1   50    152    Educacion media  0.596\n    ML1   ML3\n1 -0.80 -0.48\n2 -0.84 -0.66\n3 -0.84 -0.79\n4 -0.81 -0.56\n5 -0.80  0.61\n6 -0.78 -0.50\n\n\n\nsummary(proc_data$ML1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     -1      -1      -1       0       0       3      84 \n\nsummary(proc_data$ML2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     -1      -1       0       0       1       2      84 \n\nsummary(proc_data$ML3)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     -1      -1       0       0       1       4      84 \n\n\ncambiar nombre de los factores a uno más intuitivo\n\nproc_data &lt;- proc_data %&gt;% rename(\"inst_civiles\"=ML2, # Instituciones civiles para referirnos a FFAA, policías e iglesia\n                                  \"inst_politicas\"=ML3, # Instituciones políticas para referirnos a poder judicial y legislativo\n                                  \"inst_ejecutivo\"=ML1) # Instituciones ejecutivo para referirnos a gobierno y presidente"
  },
  {
    "objectID": "resource/04-resource.html#objetivo-de-la-práctica",
    "href": "resource/04-resource.html#objetivo-de-la-práctica",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos para la estimación de correlaciones y regresiones con R, que son necesarios para luego poder analizar e interpretar estas relaciones.\nPor temas de orden y reproducibilidad, en este curso hemos separado en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: disponible acá.\nAnálisis: este documento"
  },
  {
    "objectID": "resource/04-resource.html#librerías-y-datos",
    "href": "resource/04-resource.html#librerías-y-datos",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "pacman::p_load(dplyr,\n  ggpubr, #graficos\n               stargazer, # Reporte\n               texreg,\n               ggplot2,\n               gridExtra, #unir graficos\nsjPlot, sjmisc, # reporte y gráficos\nsjlabelled, # etiquetas\ncorrplot, # grafico correlaciones\nxtable, # Reporte\nsummarytools, #reporte\nHmisc, # varias funciones\npsych, # fa y principal factors\npsy, # scree plot function\nnFactors, # parallel\nGPArotation) # rotación\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'corrplot', 'ggsci', 'cowplot', 'ggsignif', 'polynom', 'rstatix'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'corrplot' successfully unpacked and MD5 sums checked\npackage 'ggsci' successfully unpacked and MD5 sums checked\npackage 'cowplot' successfully unpacked and MD5 sums checked\npackage 'ggsignif' successfully unpacked and MD5 sums checked\npackage 'polynom' successfully unpacked and MD5 sums checked\npackage 'rstatix' successfully unpacked and MD5 sums checked\npackage 'ggpubr' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nggpubr installed\n\n\nWarning: package 'ggpubr' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'texreg' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\ntexreg installed\n\n\nWarning: package 'texreg' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'xtable' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nxtable installed\n\n\nWarning: package 'xtable' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'lobstr', 'plyr', 'reshape2', 'checkmate', 'magick', 'pander', 'pryr', 'rapportools'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'lobstr' successfully unpacked and MD5 sums checked\npackage 'plyr' successfully unpacked and MD5 sums checked\npackage 'reshape2' successfully unpacked and MD5 sums checked\npackage 'checkmate' successfully unpacked and MD5 sums checked\npackage 'magick' successfully unpacked and MD5 sums checked\npackage 'pander' successfully unpacked and MD5 sums checked\npackage 'pryr' successfully unpacked and MD5 sums checked\npackage 'rapportools' successfully unpacked and MD5 sums checked\npackage 'summarytools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nsummarytools installed\n\n\nWarning: package 'summarytools' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nalso installing the dependencies 'htmlwidgets', 'htmlTable', 'Formula'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'htmlwidgets' successfully unpacked and MD5 sums checked\npackage 'htmlTable' successfully unpacked and MD5 sums checked\npackage 'Formula' successfully unpacked and MD5 sums checked\npackage 'Hmisc' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nHmisc installed\n\n\nWarning: package 'Hmisc' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'psy' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\npsy installed\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'nFactors' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nnFactors installed\n\n\nWarning: package 'nFactors' was built under R version 4.3.3\n\n\nInstalling package into 'C:/Users/danie/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'GPArotation' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\danie\\AppData\\Local\\Temp\\RtmpYDUVai\\downloaded_packages\n\n\n\nGPArotation installed\n\n\nWarning: package 'GPArotation' was built under R version 4.3.3\n\n\n\n\n\nLectura de datos\n\nload(\"files/data/latinobarometro_pract4.RData\")\n\no directo de la página\n\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/latinobarometro_pract4.RData\"))"
  },
  {
    "objectID": "resource/04-resource.html#exploración-de-datos",
    "href": "resource/04-resource.html#exploración-de-datos",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "view(dfSummary(proc_data,\n               plain.ascii = FALSE,\n               style = \"grid\",\n               tmp.img.dir = \"/tmp\",\n               graph.magnif = 0.75,\n               headings = F,  # encabezado\n               varnumbers = F, # num variable\n               labels.col = T, # etiquetas\n               na.col = T,    # missing\n               graph.col = F, # plot\n               valid.col = T, # n valido\n               col.widths = c(1000,10,10,10,10,10)), method=\"render\")\n\n\n\n\n\n\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nValid\nMissing\n\n\n\n\napoyo_autoritarismo [numeric]\n\n\n\n\nMean (sd) : 2.2 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.4)\n\n\n\n\n\n\n1\n:\n289\n(\n26.2%\n)\n\n\n2\n:\n453\n(\n41.1%\n)\n\n\n3\n:\n265\n(\n24.0%\n)\n\n\n4\n:\n96\n(\n8.7%\n)\n\n\n\n1103 (91.9%)\n97 (8.1%)\n\n\nconf_fa [numeric]\nConfianza: Fuerzas armadas\n\n\n\nMean (sd) : 2.1 (1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.5)\n\n\n\n\n\n\n1\n:\n372\n(\n31.7%\n)\n\n\n2\n:\n412\n(\n35.1%\n)\n\n\n3\n:\n278\n(\n23.7%\n)\n\n\n4\n:\n113\n(\n9.6%\n)\n\n\n\n1175 (97.9%)\n25 (2.1%)\n\n\nconf_pol [numeric]\nConfianza: Policías\n\n\n\nMean (sd) : 2 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.5)\n\n\n\n\n\n\n1\n:\n457\n(\n38.8%\n)\n\n\n2\n:\n363\n(\n30.8%\n)\n\n\n3\n:\n280\n(\n23.8%\n)\n\n\n4\n:\n77\n(\n6.5%\n)\n\n\n\n1177 (98.1%)\n23 (1.9%)\n\n\nconf_iglesia [numeric]\nConfianza: Iglesia\n\n\n\nMean (sd) : 2 (1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 2 (0.5)\n\n\n\n\n\n\n1\n:\n463\n(\n40.2%\n)\n\n\n2\n:\n339\n(\n29.5%\n)\n\n\n3\n:\n263\n(\n22.8%\n)\n\n\n4\n:\n86\n(\n7.5%\n)\n\n\n\n1151 (95.9%)\n49 (4.1%)\n\n\nconf_cong [numeric]\nConfianza: Congreso\n\n\n\nMean (sd) : 1.6 (0.7)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.4)\n\n\n\n\n\n\n1\n:\n628\n(\n53.3%\n)\n\n\n2\n:\n408\n(\n34.6%\n)\n\n\n3\n:\n134\n(\n11.4%\n)\n\n\n4\n:\n8\n(\n0.7%\n)\n\n\n\n1178 (98.2%)\n22 (1.8%)\n\n\nconf_gob [numeric]\nConfianza: Gobierno\n\n\n\nMean (sd) : 1.7 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n624\n(\n52.8%\n)\n\n\n2\n:\n358\n(\n30.3%\n)\n\n\n3\n:\n176\n(\n14.9%\n)\n\n\n4\n:\n23\n(\n1.9%\n)\n\n\n\n1181 (98.4%)\n19 (1.6%)\n\n\nconf_jud [numeric]\nConfianza: Poder judicial\n\n\n\nMean (sd) : 1.7 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n556\n(\n46.9%\n)\n\n\n2\n:\n438\n(\n36.9%\n)\n\n\n3\n:\n164\n(\n13.8%\n)\n\n\n4\n:\n28\n(\n2.4%\n)\n\n\n\n1186 (98.8%)\n14 (1.2%)\n\n\nconf_partpol [numeric]\nConfianza: Partidos politicos\n\n\n\nMean (sd) : 1.5 (0.7)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n760\n(\n64.5%\n)\n\n\n2\n:\n313\n(\n26.6%\n)\n\n\n3\n:\n97\n(\n8.2%\n)\n\n\n4\n:\n8\n(\n0.7%\n)\n\n\n\n1178 (98.2%)\n22 (1.8%)\n\n\nconf_presi [numeric]\nConfianza: Presidente\n\n\n\nMean (sd) : 1.7 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1 ≤ 4\n\n\nIQR (CV) : 1 (0.5)\n\n\n\n\n\n\n1\n:\n639\n(\n54.2%\n)\n\n\n2\n:\n337\n(\n28.6%\n)\n\n\n3\n:\n173\n(\n14.7%\n)\n\n\n4\n:\n29\n(\n2.5%\n)\n\n\n\n1178 (98.2%)\n22 (1.8%)\n\n\nreeduc_1 [numeric]\n\n\n\n\nMean (sd) : 5.1 (1.2)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 5 ≤ 7\n\n\nIQR (CV) : 0 (0.2)\n\n\n\n\n\n\n1\n:\n8\n(\n0.7%\n)\n\n\n2\n:\n53\n(\n4.4%\n)\n\n\n3\n:\n36\n(\n3.0%\n)\n\n\n4\n:\n161\n(\n13.4%\n)\n\n\n5\n:\n643\n(\n53.6%\n)\n\n\n6\n:\n109\n(\n9.1%\n)\n\n\n7\n:\n190\n(\n15.8%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\nsexo [numeric]\nSexo\n\n\n\nMin : 0\n\n\nMean : 0.5\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n555\n(\n46.2%\n)\n\n\n1\n:\n645\n(\n53.8%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 44.5 (17)\n\n\nmin ≤ med ≤ max:\n\n\n18 ≤ 43 ≤ 89\n\n\nIQR (CV) : 28 (0.4)\n\n\n\n69 distinct values\n1200 (100.0%)\n0 (0.0%)\n\n\nidenpa [numeric]\n\n1 distinct value\n\n\n\n152\n:\n1200\n(\n100.0%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\neducacion [character]\nEducación\n\n\n\n1. Educacion basica\n\n\n2. Educacion media\n\n\n3. Educacion superior\n\n\n\n\n\n\n97\n(\n8.1%\n)\n\n\n804\n(\n67.0%\n)\n\n\n299\n(\n24.9%\n)\n\n\n\n1200 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-04-04\n\n\n\n\nproc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi) %&gt;%\n  plot_stackfrq(sort.frq = \"first.desc\", geom.colors = \"OrRd\") + theme(legend.position=\"bottom\")"
  },
  {
    "objectID": "resource/04-resource.html#análisis-de-correlaciones",
    "href": "resource/04-resource.html#análisis-de-correlaciones",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "corMat  &lt;- proc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi) %&gt;%\n  cor(use = \"complete.obs\")  # estimar matriz pearson\noptions(digits=2)\ncorMat\n\n             conf_fa conf_pol conf_iglesia conf_gob conf_cong conf_jud\nconf_fa         1.00     0.79         0.51     0.60      0.44     0.49\nconf_pol        0.79     1.00         0.58     0.64      0.46     0.50\nconf_iglesia    0.51     0.58         1.00     0.57      0.49     0.43\nconf_gob        0.60     0.64         0.57     1.00      0.65     0.60\nconf_cong       0.44     0.46         0.49     0.65      1.00     0.53\nconf_jud        0.49     0.50         0.43     0.60      0.53     1.00\nconf_partpol    0.34     0.37         0.42     0.58      0.67     0.55\nconf_presi      0.60     0.63         0.54     0.80      0.55     0.52\n             conf_partpol conf_presi\nconf_fa              0.34       0.60\nconf_pol             0.37       0.63\nconf_iglesia         0.42       0.54\nconf_gob             0.58       0.80\nconf_cong            0.67       0.55\nconf_jud             0.55       0.52\nconf_partpol         1.00       0.52\nconf_presi           0.52       1.00\n\n\n\n\n\nproc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi) %&gt;%\n  tab_corr(triangle = \"lower\")\n\n\n\n\n \nConfianza: Fuerzas armadas\nConfianza: Policías\nConfianza: Iglesia\nConfianza: Gobierno\nConfianza: Congreso\nConfianza: Poder judicial\nConfianza: Partidos politicos\nConfianza: Presidente\n\n\nConfianza: Fuerzas armadas\n \n \n \n \n \n \n \n \n\n\nConfianza: Policías\n0.790***\n \n \n \n \n \n \n \n\n\nConfianza: Iglesia\n0.512***\n0.580***\n \n \n \n \n \n \n\n\nConfianza: Gobierno\n0.599***\n0.641***\n0.571***\n \n \n \n \n \n\n\nConfianza: Congreso\n0.437***\n0.464***\n0.495***\n0.652***\n \n \n \n \n\n\nConfianza: Poder judicial\n0.492***\n0.503***\n0.431***\n0.600***\n0.535***\n \n \n \n\n\nConfianza: Partidos politicos\n0.335***\n0.373***\n0.422***\n0.576***\n0.670***\n0.552***\n \n \n\n\nConfianza: Presidente\n0.597***\n0.634***\n0.538***\n0.801***\n0.547***\n0.524***\n0.520***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\n\n\n\ncorrplot(corMat, type=\"lower\")\n\n\n\n\n\n\n\n\nM=corMat\ndiag(M) = NA\nrownames(M) &lt;- c(\"A. Confianza: Fuerzas armadas\",\n                         \"B. Confianza: Policías\",\n                         \"C. Confianza: Iglesia\",\n                         \"D. Confianza: Gobierno\",\n                         \"E. Confianza: Congreso\",\n                         \"F. Confianza: Poder judicial\",\n                         \"G. Confianza: Part. políticos\",\n                         \"H. Confianza: Presidente\")\ncolnames(M) &lt;-c(\"(A)\", \"(B)\",\"(C)\", \"(D)\", \"(E)\", \"(F)\", \"(G)\", \"(H)\")\n\ncorrplot::corrplot(M,\n  method = \"color\",\n  addCoef.col = \"#000390\",\n  type = \"upper\",\n  tl.col = \"black\",\n  col=colorRampPalette(c(\"white\",\"#0068DC\"))(12),\n  bg = \"white\",\n  na.label = \"-\")"
  },
  {
    "objectID": "resource/04-resource.html#análisis-factorial-exploratorio",
    "href": "resource/04-resource.html#análisis-factorial-exploratorio",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "¿Qué se puede deducir de la matriz de correlaciones en relación a la estructura subyacente en términos de variables latentes? No hay claridad de grupos de indicadores asociados entre sí.\n\n\nKMO (Kaiser, Meyer, Olkin Measure of Sampling Adequacy):\n\nVaría entre 0 y 1. Contrasta si las correlaciones parciales entre las variables son pequeñas\nValores pequeños (menores a 0.5) indican que los datos no serían adecuados para AFE, ya que las correlaciones entre pares de variables no pueden ser explicadas por otras variables.\n\n\nKMO(corMat)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = corMat)\nOverall MSA =  0.88\nMSA for each item = \n     conf_fa     conf_pol conf_iglesia     conf_gob    conf_cong     conf_jud \n        0.85         0.85         0.96         0.87         0.89         0.94 \nconf_partpol   conf_presi \n        0.87         0.88 \n\n\nEn este caso las correlaciones son altas, por lo que los datos sí son adecuados para AFE.\n\n\n\nSe utiliza para evluar la hipótesis que la matriz de correlaciones es una matriz identidad (diagonal 1 y bajo la diagonal 0)\n\nSe busca significación (p &lt; 0.05) ya que se espera que las variables estén correlacionadas\n\n\ncortest.bartlett(corMat, n = 1200)\n\n$chisq\n[1] 6064\n\n$p.value\n[1] 0\n\n$df\n[1] 28\n\n\nEn este caso el valor p es 0, así que hay significación estadística\n\n\n\n\nconfianza &lt;- proc_data %&gt;% \n  select(conf_fa, conf_pol, conf_iglesia, conf_gob, conf_cong, conf_jud, conf_partpol, conf_presi)\nscree.plot(confianza)\n\n\n\n\n\nfa.parallel(corMat, n.obs=1200)\n\n\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  1 \n\n\n\nlibrary(nFactors)\nev &lt;- eigen(corMat) # get eigenvalues\nap &lt;- parallel(subject=1200,var=8,\n  rep=100,cent=.05)\nnS &lt;- nScree(x=ev$values, aparallel=ap$eigen$qevpea)\nplotnScree(nS)\n\n\n\n\n\n\n\nejes principales\n\nfac_pa &lt;- fa(r = confianza, nfactors = 3, fm= \"pa\")\n\nmaximum iteration exceeded\n\n#summary(fac_pa)\nfac_pa\n\nFactor Analysis using method =  pa\nCall: fa(r = confianza, nfactors = 3, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n               PA1   PA3   PA2   h2    u2 com\nconf_fa       0.83  0.03 -0.01 0.72 0.280 1.0\nconf_pol      0.94 -0.02  0.00 0.87 0.134 1.0\nconf_iglesia  0.39  0.18  0.18 0.43 0.565 1.9\nconf_gob     -0.04  1.01  0.00 0.97 0.035 1.0\nconf_cong     0.09  0.14  0.63 0.63 0.373 1.1\nconf_jud      0.24  0.11  0.45 0.49 0.511 1.7\nconf_partpol -0.05 -0.04  0.93 0.78 0.222 1.0\nconf_presi    0.20  0.63  0.05 0.69 0.315 1.2\n\n                       PA1  PA3  PA2\nSS loadings           2.09 1.75 1.72\nProportion Var        0.26 0.22 0.22\nCumulative Var        0.26 0.48 0.70\nProportion Explained  0.38 0.31 0.31\nCumulative Proportion 0.38 0.69 1.00\n\n With factor correlations of \n     PA1  PA3  PA2\nPA1 1.00 0.72 0.51\nPA3 0.72 1.00 0.71\nPA2 0.51 0.71 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  8.1  with prob &lt;  0.32 \nThe total n.obs was  1200  with Likelihood Chi Square =  38  with prob &lt;  3.7e-06 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.06  and the 90 % confidence intervals are  0.042 0.08\nBIC =  -12\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA3  PA2\nCorrelation of (regression) scores with factors   0.96 0.98 0.93\nMultiple R square of scores with factors          0.91 0.97 0.87\nMinimum correlation of possible factor scores     0.83 0.94 0.73\n\n\nMaximum likelihood\nMaximiza la posibilidad de que los parámetros reproduzcan los datos observados\n\nfac_ml &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\")\nsummary(fac_ml)\n\n\nFactor analysis with Call: fa(r = confianza, nfactors = 3, fm = \"ml\")\n\nTest of the hypothesis that 3 factors are sufficient.\nThe degrees of freedom for the model is 7  and the objective function was  0.03 \nThe number of observations was  1200  with Chi Square =  32  with prob &lt;  3.4e-05 \n\nThe root mean square of the residuals (RMSA) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 10 % confidence intervals are  0.037 0.075\nBIC =  -17\n With factor correlations of \n     ML2  ML1  ML3\nML2 1.00 0.71 0.50\nML1 0.71 1.00 0.68\nML3 0.50 0.68 1.00\n\n\n\n\n\nVarimax (ortogonal)\n\nfac_ml_var &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\nFactor Analysis using method =  ml\nCall: fa(r = confianza, nfactors = 3, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n              ML2  ML3  ML1   h2    u2 com\nconf_fa      0.80 0.20 0.24 0.73 0.266 1.3\nconf_pol     0.86 0.22 0.25 0.85 0.155 1.3\nconf_iglesia 0.49 0.33 0.28 0.44 0.565 2.4\nconf_gob     0.40 0.41 0.82 1.00 0.005 2.0\nconf_cong    0.28 0.66 0.32 0.61 0.387 1.9\nconf_jud     0.37 0.52 0.29 0.49 0.510 2.5\nconf_partpol 0.15 0.87 0.19 0.81 0.190 1.2\nconf_presi   0.48 0.38 0.56 0.68 0.322 2.8\n\n                       ML2  ML3  ML1\nSS loadings           2.24 1.96 1.41\nProportion Var        0.28 0.24 0.18\nCumulative Var        0.28 0.52 0.70\nProportion Explained  0.40 0.35 0.25\nCumulative Proportion 0.40 0.75 1.00\n\nMean item complexity =  1.9\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  9.3  with prob &lt;  0.23 \nThe total n.obs was  1200  with Likelihood Chi Square =  32  with prob &lt;  3.4e-05 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 90 % confidence intervals are  0.037 0.075\nBIC =  -17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2 ML3  ML1\nCorrelation of (regression) scores with factors   0.92 0.9 0.96\nMultiple R square of scores with factors          0.85 0.8 0.92\nMinimum correlation of possible factor scores     0.69 0.6 0.85\n\n\nPromax (oblicua)\n\nfac_ml_pro &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\nFactor Analysis using method =  ml\nCall: fa(r = confianza, nfactors = 3, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n               ML2   ML3   ML1   h2    u2 com\nconf_fa       0.93 -0.07 -0.04 0.73 0.266 1.0\nconf_pol      1.00 -0.07 -0.06 0.85 0.155 1.0\nconf_iglesia  0.43  0.17  0.12 0.44 0.565 1.5\nconf_gob     -0.09 -0.04  1.10 1.00 0.005 1.0\nconf_cong     0.02  0.65  0.14 0.61 0.387 1.1\nconf_jud      0.21  0.45  0.11 0.49 0.510 1.5\nconf_partpol -0.13  1.07 -0.13 0.81 0.190 1.1\nconf_presi    0.21  0.06  0.60 0.68 0.322 1.3\n\n                       ML2  ML3  ML1\nSS loadings           2.14 1.78 1.67\nProportion Var        0.27 0.22 0.21\nCumulative Var        0.27 0.49 0.70\nProportion Explained  0.38 0.32 0.30\nCumulative Proportion 0.38 0.70 1.00\n\n With factor correlations of \n     ML2  ML3  ML1\nML2 1.00 0.65 0.78\nML3 0.65 1.00 0.77\nML1 0.78 0.77 1.00\n\nMean item complexity =  1.2\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  9.3  with prob &lt;  0.23 \nThe total n.obs was  1200  with Likelihood Chi Square =  32  with prob &lt;  3.4e-05 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 90 % confidence intervals are  0.037 0.075\nBIC =  -17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML3  ML1\nCorrelation of (regression) scores with factors   0.96 0.95 1.00\nMultiple R square of scores with factors          0.92 0.90 1.00\nMinimum correlation of possible factor scores     0.84 0.80 0.99\n\n\n\n\n\n\ntab_fa(confianza, rotation = \"varimax\",show.comm = TRUE, title = \"Análisis factorial confianza instituciones\")\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  NA \n\n\n\nAnálisis factorial confianza instituciones\n\n\n \nFactor 1\nFactor 2\nFactor 3\nCommunality\n\n\nConfianza: Fuerzas armadas\n0.80\n0.20\n0.24\n0.73\n\n\nConfianza: Policías\n0.86\n0.22\n0.25\n0.85\n\n\nConfianza: Iglesia\n0.49\n0.33\n0.28\n0.44\n\n\nConfianza: Gobierno\n0.40\n0.41\n0.82\n0.99\n\n\nConfianza: Congreso\n0.28\n0.66\n0.32\n0.61\n\n\nConfianza: Poder judicial\n0.37\n0.52\n0.29\n0.49\n\n\nConfianza: Partidos politicos\n0.15\n0.87\n0.19\n0.81\n\n\nConfianza: Presidente\n0.48\n0.38\n0.56\n0.68\n\n\nTotal Communalities\n\n5.60\n\n\nCronbach's α\n0.83\n0.81\n0.89\n\n\n\n\n\n\nLuego de realizar el Análisis factorial exploratorio existen varias alternativas sobre los pasos a seguir. Por ejemplo, es posible estimar un promedio simple entre cada una de las variables de los factores. Otra opción es estimar puntajes factoriales.\n\n\n\nLos puntajes factoriales son “estimaciones” (predicciones) de puntajes en los factores para cada observación en los datos.\n\nEstos puntajes pueden utilizarse en análisis posteriores\nSe pueden calcular puntajes para cada observación en cada factor utilizando un método de regresión\nEstas nuevas variables se estandarizan con media 0 y desviación estándar 1\n\n\nfac_ml &lt;- fa(r = confianza, nfactors = 3, fm= \"ml\", scores=\"regression\")\nfac_ml # ojo que ML2 es el factor 1; ML1=factor 3 y ML3=factor 2 de la tabla que da sjPlot\n\nFactor Analysis using method =  ml\nCall: fa(r = confianza, nfactors = 3, scores = \"regression\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n               ML2   ML1   ML3   h2    u2 com\nconf_fa       0.86  0.00 -0.01 0.73 0.266 1.0\nconf_pol      0.93 -0.01  0.00 0.85 0.155 1.0\nconf_iglesia  0.42  0.15  0.18 0.44 0.565 1.6\nconf_gob     -0.03  1.02  0.00 1.00 0.005 1.0\nconf_cong     0.08  0.19  0.59 0.61 0.387 1.2\nconf_jud      0.24  0.15  0.42 0.49 0.510 1.8\nconf_partpol -0.04 -0.04  0.94 0.81 0.190 1.0\nconf_presi    0.23  0.58  0.09 0.68 0.322 1.4\n\n                       ML2  ML1  ML3\nSS loadings           2.15 1.75 1.70\nProportion Var        0.27 0.22 0.21\nCumulative Var        0.27 0.49 0.70\nProportion Explained  0.38 0.31 0.30\nCumulative Proportion 0.38 0.70 1.00\n\n With factor correlations of \n     ML2  ML1  ML3\nML2 1.00 0.71 0.50\nML1 0.71 1.00 0.68\nML3 0.50 0.68 1.00\n\nMean item complexity =  1.3\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  28  with the objective function =  5 with Chi Square =  6017\ndf of  the model are 7  and the objective function was  0.03 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  1163 with the empirical chi square  9.3  with prob &lt;  0.23 \nThe total n.obs was  1200  with Likelihood Chi Square =  32  with prob &lt;  3.4e-05 \n\nTucker Lewis Index of factoring reliability =  0.98\nRMSEA index =  0.055  and the 90 % confidence intervals are  0.037 0.075\nBIC =  -17\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML1  ML3\nCorrelation of (regression) scores with factors   0.95 1.00 0.93\nMultiple R square of scores with factors          0.91 1.00 0.87\nMinimum correlation of possible factor scores     0.82 0.99 0.75\n\nproc_data &lt;- cbind(proc_data, fac_ml$scores)\nhead(proc_data)\n\n  apoyo_autoritarismo conf_fa conf_pol conf_iglesia conf_cong conf_gob conf_jud\n1                   1       2        2            3         1        1        3\n2                   1       1        1            1         1        1        2\n3                   1       1        1            1         1        1        1\n4                   1       2        2            1         1        1        3\n5                   1       1        2            3         2        1        2\n6                   1       2        3            3         1        1        3\n  conf_partpol conf_presi reeduc_1 sexo edad idenpa          educacion    ML2\n1            1          1        1    1   54    152   Educacion basica  0.016\n2            1          1        5    0   51    152    Educacion media -1.066\n3            1          1        5    0   39    152    Educacion media -1.118\n4            1          1        6    1   30    152 Educacion superior -0.126\n5            2          1        5    1   24    152    Educacion media -0.365\n6            1          1        5    1   50    152    Educacion media  0.596\n    ML1   ML3\n1 -0.80 -0.48\n2 -0.84 -0.66\n3 -0.84 -0.79\n4 -0.81 -0.56\n5 -0.80  0.61\n6 -0.78 -0.50\n\n\n\nsummary(proc_data$ML1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     -1      -1      -1       0       0       3      84 \n\nsummary(proc_data$ML2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     -1      -1       0       0       1       2      84 \n\nsummary(proc_data$ML3)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     -1      -1       0       0       1       4      84 \n\n\ncambiar nombre de los factores a uno más intuitivo\n\nproc_data &lt;- proc_data %&gt;% rename(\"inst_civiles\"=ML2, # Instituciones civiles para referirnos a FFAA, policías e iglesia\n                                  \"inst_politicas\"=ML3, # Instituciones políticas para referirnos a poder judicial y legislativo\n                                  \"inst_ejecutivo\"=ML1) # Instituciones ejecutivo para referirnos a gobierno y presidente"
  },
  {
    "objectID": "resource/06-resource.html",
    "href": "resource/06-resource.html",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "",
    "text": "La Encuesta Mundial de Valores (EMV) o World Values Survey WVS es un proyecto global de investigación social que explora los valores y opiniones de la gente, cómo estos cambian con el tiempo, y su impacto social y político. Desde 1981 una red mundial de científicos sociales y politólogos llevan a cabo esta investigación, haciendo encuestas nacionales representativas en casi 100 países. La WVS es la única fuente de datos empíricos sobre actitudes y valores humanos que abarca a la mayoría de la población mundial (casi el 90%).\n\n\nEn el ejemplo de esta práctica, que utiliza solo casos para Chile entre 2005 y 2022, se intentará responder la pregunta ¿existe una relación entre la afiliación a sindicatos y la participación en marchas?\nDebido a la naturaleza de la variable dependiente participación en marchas (si/no), el objetivo de esta práctica es estimar modelos de regresión logística binaria."
  },
  {
    "objectID": "resource/06-resource.html#objetivo",
    "href": "resource/06-resource.html#objetivo",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "",
    "text": "En el ejemplo de esta práctica, que utiliza solo casos para Chile entre 2005 y 2022, se intentará responder la pregunta ¿existe una relación entre la afiliación a sindicatos y la participación en marchas?\nDebido a la naturaleza de la variable dependiente participación en marchas (si/no), el objetivo de esta práctica es estimar modelos de regresión logística binaria."
  },
  {
    "objectID": "resource/06-resource.html#explorar-datos",
    "href": "resource/06-resource.html#explorar-datos",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Explorar datos",
    "text": "Explorar datos\n\nsummary(WVS_2005_2022_Chl) #con comando de paquete haven\n\n   Unionized      demonstr_dummy   petition_dummy       Wave    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Wave 5:373  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   Wave 6:516  \n Median :0.0000   Median :0.0000   Median :0.0000   Wave 7:568  \n Mean   :0.1984   Mean   :0.2073   Mean   :0.1846               \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000               \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000               \n                                                                \n           pol_pos     pol_pos_left    politicization civic_involvement\n left          :360   Min.   :0.0000   Min.   :0.00   Min.   :0.0000   \n center        :509   1st Qu.:0.0000   1st Qu.:1.00   1st Qu.:0.0000   \n right         :215   Median :0.0000   Median :2.00   Median :0.0000   \n Not identified:  0   Mean   :0.2471   Mean   :1.95   Mean   :0.6905   \n NA's          :373   3rd Qu.:0.0000   3rd Qu.:3.00   3rd Qu.:1.0000   \n                      Max.   :1.0000   Max.   :6.00   Max.   :3.0000   \n                                                                       \n      X003       age         Female       Educ    private_sector  \n Min.   :18.00   1:128   Min.   :0.0000   1:123   Min.   :0.0000  \n 1st Qu.:31.00   2:341   1st Qu.:0.0000   2:924   1st Qu.:1.0000  \n Median :41.00   3:400   Median :0.0000   3:410   Median :1.0000  \n Mean   :41.44   4:352   Mean   :0.4084           Mean   :0.8593  \n 3rd Qu.:50.00   5:188   3rd Qu.:1.0000           3rd Qu.:1.0000  \n Max.   :80.00   6: 48   Max.   :1.0000           Max.   :1.0000  \n                                                                  \n    gvt_resp         tax_rich        unempl_aid      state_inc_eq   \n Min.   : 1.000   Min.   : 1.000   Min.   : 1.000   Min.   : 1.000  \n 1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000   1st Qu.: 5.000  \n Median : 6.000   Median : 7.000   Median : 7.000   Median : 7.000  \n Mean   : 6.457   Mean   : 6.446   Mean   : 7.103   Mean   : 6.689  \n 3rd Qu.: 9.000   3rd Qu.: 9.000   3rd Qu.:10.000   3rd Qu.: 9.000  \n Max.   :10.000   Max.   :10.000   Max.   :10.000   Max.   :10.000  \n NA's   :16       NA's   :87       NA's   :62       NA's   :439     \n\ndescribe(WVS_2005_2022_Chl) #con comando de paquete psych\n\n                  vars    n  mean    sd median trimmed   mad min max range\nUnionized            1 1457  0.20  0.40      0    0.12  0.00   0   1     1\ndemonstr_dummy       2 1457  0.21  0.41      0    0.13  0.00   0   1     1\npetition_dummy       3 1457  0.18  0.39      0    0.11  0.00   0   1     1\nWave*                4 1457  2.13  0.79      2    2.17  1.48   1   3     2\npol_pos*             5 1084  1.87  0.72      2    1.83  1.48   1   3     2\npol_pos_left         6 1457  0.25  0.43      0    0.18  0.00   0   1     1\npoliticization       7 1457  1.95  1.61      2    1.81  1.48   0   6     6\ncivic_involvement    8 1457  0.69  0.98      0    0.49  0.00   0   3     3\nX003                 9 1457 41.44 12.25     41   41.13 13.34  18  80    62\nage*                10 1457  3.19  1.27      3    3.18  1.48   1   6     5\nFemale              11 1457  0.41  0.49      0    0.39  0.00   0   1     1\nEduc*               12 1457  2.20  0.57      2    2.23  0.00   1   3     2\nprivate_sector      13 1457  0.86  0.35      1    0.95  0.00   0   1     1\ngvt_resp            14 1441  6.46  2.58      6    6.61  2.97   1  10     9\ntax_rich            15 1370  6.45  2.72      7    6.64  2.97   1  10     9\nunempl_aid          16 1395  7.10  2.53      7    7.37  2.97   1  10     9\nstate_inc_eq        17 1018  6.69  2.60      7    6.90  2.97   1  10     9\n                   skew kurtosis   se\nUnionized          1.51     0.28 0.01\ndemonstr_dummy     1.44     0.08 0.01\npetition_dummy     1.62     0.64 0.01\nWave*             -0.24    -1.37 0.02\npol_pos*           0.20    -1.04 0.02\npol_pos_left       1.17    -0.63 0.01\npoliticization     0.56    -0.43 0.04\ncivic_involvement  1.31     0.51 0.03\nX003               0.21    -0.63 0.32\nage*               0.15    -0.66 0.03\nFemale             0.37    -1.86 0.01\nEduc*             -0.02    -0.28 0.01\nprivate_sector    -2.06     2.26 0.01\ngvt_resp          -0.32    -0.71 0.07\ntax_rich          -0.34    -0.81 0.07\nunempl_aid        -0.62    -0.43 0.07\nstate_inc_eq      -0.40    -0.61 0.08"
  },
  {
    "objectID": "resource/06-resource.html#tabla-de-contingencia-bivariado-sindicalización-participación-en-marchas",
    "href": "resource/06-resource.html#tabla-de-contingencia-bivariado-sindicalización-participación-en-marchas",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Tabla de contingencia bivariado: sindicalización / participación en marchas",
    "text": "Tabla de contingencia bivariado: sindicalización / participación en marchas\n\nWVS_2005_2022_Chl &lt;- WVS_2005_2022_Chl %&gt;%\n  mutate(Unionized = labelled(.$Unionized,c(\"No\"=0,\"Sí\"=1)),\n         demonstr_dummy = labelled(.$demonstr_dummy,c(\"No\"=0,\"Sí\"=1)))\n\nWVS_2005_2022_Chl &lt;- as.data.frame(WVS_2005_2022_Chl) #para que la base quede como data frame (necesario para las figuras)\n\nfrq(WVS_2005_2022_Chl$Unionized)\n\nx &lt;numeric&gt; \n# total N=1457 valid N=1457 mean=0.20 sd=0.40\n\nValue | Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------\n    0 |    No | 1168 | 80.16 |   80.16 |  80.16\n    1 |    Sí |  289 | 19.84 |   19.84 | 100.00\n &lt;NA&gt; |  &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(WVS_2005_2022_Chl$demonstr_dummy)\n\nx &lt;integer&gt; \n# total N=1457 valid N=1457 mean=0.21 sd=0.41\n\nValue | Label |    N | Raw % | Valid % | Cum. %\n-----------------------------------------------\n    0 |    No | 1155 | 79.27 |   79.27 |  79.27\n    1 |    Sí |  302 | 20.73 |   20.73 | 100.00\n &lt;NA&gt; |  &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjPlot::tab_xtab(var.col = WVS_2005_2022_Chl$Unionized, \n                 var.row = WVS_2005_2022_Chl$demonstr_dummy, \n                 title = \"Participación en marchas según afiliación sindical\", \n                 show.col.prc = TRUE,\n                 value.labels = TRUE,\n                 encoding = \"UTF-8\")\n\nWarning: `valueLables` needs to be a `list`-object.\n\n\n\n\nParticipación en marchas según afiliación sindical\n \n demonstr_dummy\n Unionized\n Total\n \n \n\n No\n Sí\n \n \n \nNo\n94180.6 %\n21474 %\n115579.3 % \n\n \n \nSí\n22719.4 %\n7526 %\n30220.7 % \n\n \n \nTotal\n1168100 %\n289100 %\n1457100 % \n\nχ2=5.598 · df=1 · φ=0.064 · p=0.018 \n\n \n\n\n\n\nOdds\n\\[Odds_{participar} = \\frac{0.207}{0.793} = 0.26\\]\nLas chances de participar en una marcha son de 0,26, respecto a las chances de no participar\n\nEn otras palabras: por cada 1 persona, hay sólo 0,26 personas que participan en marchas.\nO más intuitivamente, por cada 100 personas, hay sólo 26 personas que participan\n\n¿Cambian las chances de participar según se esté afiliado/a a un sindicato\n\\[Odds_{sindical} = \\frac{0.26}{0.74} = 0.35\\]\n\\[Odds_{no.sindical} = \\frac{0.194}{0.806} = 0.24\\]\n¿Cómo se interpretan los odds?\n\nValores bajo 1 indican que las chances de que ocurra un evento son negativas\nValores iguales a 1 indican chances iguales\nValores sobre 1 indican chances positivas\n\n\n\nOdds ratios (razones de chances)\n\nCálculo que permite reflejar asociación entre dos variables dicotómicas, a partir de una comparación entre chances\nSiguiendo con el ejemplo anterior, ¿tienen los/as sindicalizados más chances de participar en marchas que quienes no están sindicalizados/as?\n\n\\[OR = \\frac{P_{sindical}/(1-P_{sindical})}{P_{no.sindical}/(1-P_{no.sindical})}\\]\n\\[OR = \\frac{0.26/0.74}{0.194/0.806} = \\frac{0.35}{0.24} = 1.46\\]\nLas chances de participar en marchas de los/as sindicalizados/as son 1,5 veces más que las de quienes no están sindicalizados/as\n\nImplicancias:\n\nEl odds ratio o razones de chances es útil porque nos permite expresar en un número la relación entre dos variables categóricas\nEn las regresiones logísticas, el odds ratio es la primera manera de aproximarnos a relación entre variables\nSin embargo, falta un paso más necesario para construir modelos de regresión logística"
  },
  {
    "objectID": "resource/06-resource.html#logit",
    "href": "resource/06-resource.html#logit",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Logit",
    "text": "Logit\n\nEs una unidad de medida de la relación entre dos variables (VD: dicotómica), que en regresión logística se calcula a partir del logaritmo natural de los odds\nEsta transformación logarítmica es la base de la estimación de parámetros en la regresión logística:\n\nLa mejor combinación lineal de predictores no se obtiene a través de MCO, sino a través del procedimiento de máxima verosimilitud\n\nA diferencia de los odds ratio, los coeficientes logit tienen valores que van de –a +"
  },
  {
    "objectID": "resource/06-resource.html#modelo-de-probabilidad-lineal",
    "href": "resource/06-resource.html#modelo-de-probabilidad-lineal",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Modelo de probabilidad lineal",
    "text": "Modelo de probabilidad lineal\nPrimero, solo para comparación, estimamos un modelo de probabilidad lineal.\n\nm1mpl &lt;- lm(demonstr_dummy ~ Unionized + Wave, data = WVS_2005_2022_Chl)\n\nhtmlreg(m1mpl,\n          custom.model.names = \"Modelo de Prob Lineal\",\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModelo de Prob Lineal\n\n\n\n\n\n\n(Intercept)\n\n\n0.167***\n\n\n\n\n \n\n\n(0.022)\n\n\n\n\nUnionized\n\n\n0.072**\n\n\n\n\n \n\n\n(0.027)\n\n\n\n\nWaveWave 6\n\n\n0.079**\n\n\n\n\n \n\n\n(0.027)\n\n\n\n\nWaveWave 7\n\n\n-0.005\n\n\n\n\n \n\n\n(0.027)\n\n\n\n\nR2\n\n\n0.013\n\n\n\n\nAdj. R2\n\n\n0.011\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1"
  },
  {
    "objectID": "resource/06-resource.html#modelo-de-regresión-logística",
    "href": "resource/06-resource.html#modelo-de-regresión-logística",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Modelo de regresión logística",
    "text": "Modelo de regresión logística\n\nm0log &lt;- glm(demonstr_dummy~ Unionized, data = WVS_2005_2022_Chl, family = \"binomial\"(link = \"logit\"))\nm1log &lt;- glm(demonstr_dummy~ Unionized + Wave, data = WVS_2005_2022_Chl, family = \"binomial\"(link = \"logit\"))\n#nota: \"logit\" viene por defecto en la opción \"binomial\", por eso no es necesario \n#incluirla explícitamente en el código (tal como lo hago en los modelos sgtes)\nm2log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector + Wave, data = WVS_2005_2022_Chl,family = \"binomial\")\nm3log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector + politicization + Wave, data = WVS_2005_2022_Chl,family = \"binomial\")\n\nhtmlreg(list(m1mpl, m1log,m2log,m3log),\n          custom.model.names = c(\"M1 (m prob lineal)\",\"M1 (log odds)\",\"M2 (log odds)\",\"M3 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nM1 (m prob lineal)\n\n\nM1 (log odds)\n\n\nM2 (log odds)\n\n\nM3 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n0.167***\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n\n\n \n\n\n(0.022)\n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n\n\nUnionized\n\n\n0.072**\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n\n\n \n\n\n(0.027)\n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n0.079**\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n\n\n \n\n\n(0.027)\n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.005\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n\n\n \n\n\n(0.027)\n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n \n\n\n0.282***\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n\n\nR2\n\n\n0.013\n\n\n \n\n\n \n\n\n \n\n\n\n\nAdj. R2\n\n\n0.011\n\n\n \n\n\n \n\n\n \n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\nAIC\n\n\n \n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n\n\nBIC\n\n\n \n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n\n\nLog Likelihood\n\n\n \n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n\n\nDeviance\n\n\n \n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\nEn el Modelo 1 (M1), el log-odds de participación en marchas para afiliados a sindicatos aumenta en 0.418 en comparación con los no sindicalizados (p&lt;0.01). Este resultado mantiene su significación estadística en el Modelo 2 y baja su significación a p&lt;0.1 en el Modelo 3, al controlar por las demás variables independientes.\nEn el Modelo 2, En comparación a los/as trabajadores/as del sector público (categoría de referencia), el log-odds de participación en marchas para los/as del sector privado disminuye en 0,52 (p &lt; 0,01), manteniendo el resto de variables constantes.\nEn el Modelo 3, por cada unidad de aumento en la escala de politización, el log-odds de participación en marchas aumenta en 0,28 (p &lt; 0,001), manteniendo el resto de las variables constantes.\n\nProblemas de interpretación\nA pesar de sus ventajas, los coeficientes logit son difíciles de interpretar:\n\nLos coef. logit son el resultado de una transformación de la escala original\nEllos no muestran directamente probabilidades\nEntonces: Volver a la escala original de odds ratio mediante la exponenciación de los coeficientes (la función exponencial es la inversa del logaritmo)\n\n\\[logit_x = log(odds)\\]\n\\[e^{logit} = odds_x\\]\n\\[e^{0.39} = odds_x = 1.477\\]\nLas chances (odds) de participar en marchas de los/as sindicalizados/as son 1,5 veces más que las de quienes no están sindicalizados/as, controlando por las otras variables incluidas en el modelo"
  },
  {
    "objectID": "resource/06-resource.html#estimación-de-odds-ratios",
    "href": "resource/06-resource.html#estimación-de-odds-ratios",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Estimación de odds ratios",
    "text": "Estimación de odds ratios\n\nexp(coef(m1log)) #comando básico\n\n(Intercept)   Unionized  WaveWave 6  WaveWave 7 \n  0.2016888   1.5185264   1.5996549   0.9694021 \n\n### Cálculo de OR para cada modelo\nm0log_OR &lt;- exp(coef(m0log))\nm1log_OR &lt;- exp(coef(m1log))\nm2log_OR &lt;- exp(coef(m2log))\nm3log_OR &lt;- exp(coef(m3log))\n\n##Odds ratios en tabla de texreg\nhtmlreg(list(m1log,m2log,m3log), \n          override.coef = list(m1log_OR,m2log_OR,m3log_OR), # Sobreescribir coeficientes\n          custom.model.names = c(\"m1 (OR)\",\"m2 (OR)\",\"m3 (OR)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nm1 (OR)\n\n\nm2 (OR)\n\n\nm3 (OR)\n\n\n\n\n\n\n(Intercept)\n\n\n0.202***\n\n\n0.359*\n\n\n0.252**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n\n\nUnionized\n\n\n1.519**\n\n\n1.477*\n\n\n1.366†\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n1.600**\n\n\n1.646**\n\n\n1.642**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n0.969\n\n\n0.903\n\n\n0.886\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n0.980\n\n\n1.106\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n0.993\n\n\n0.988*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n1.042\n\n\n0.949\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n1.684†\n\n\n1.296\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n0.597**\n\n\n0.641*\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n1.326***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\n#Nota: errores estándares en esta tabla NO tienen  sentido (no están calculados a partir de OR, sino de log odds)\n#Es mejor no reportarlos si solo se van a presentar odds ratios\nSin embargo, los coeficientes de un modelo de reg. logística (log-odds u odds-ratios) no son comparables con los coeficientes de otro modelo"
  },
  {
    "objectID": "resource/06-resource.html#cálculo-de-probabilidades-predichas",
    "href": "resource/06-resource.html#cálculo-de-probabilidades-predichas",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Cálculo de probabilidades predichas",
    "text": "Cálculo de probabilidades predichas\n# Tabla básica: sólo sindicalizacion como vble independ\nhtmlreg(m0log,\n          custom.model.names = c(\"m0 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nm0 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.422***\n\n\n\n\n \n\n\n(0.074)\n\n\n\n\nUnionized\n\n\n0.374*\n\n\n\n\n \n\n\n(0.153)\n\n\n\n\nAIC\n\n\n1485.340\n\n\n\n\nBIC\n\n\n1495.908\n\n\n\n\nLog Likelihood\n\n\n-740.670\n\n\n\n\nDeviance\n\n\n1481.340\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\nA partir de este modelo se pueden predecir log-odds y, más importante aún, probabilidades para personas con distintos atributos controlados en el modelo (ej., sindicalizadas o no)\n\\[logit(prob.marcha) = 𝛼+ 𝛽_1X_1 \\]\n\\[logit(prob.marcha)_{sindical} = -1.422 + (0.374 * Unionized=1) = -1.048 \\]\n\\[logit(prob.marcha)_{no.sindical} = -1.422 + (0.374 * Unionized=0) = -1.422 \\]\nEste “puntaje predicho” (log-odds) no tiene interpretación, por lo que hay que pasarlo a Odds\n\\[Odds_x = e^{𝛼+𝛽_jX_j}\\]\n\\[Odds_{sindicalizados} = e^{-1.048} = 0.35\\]\n\\[Odds_{no.sindicalizados} = e^{-1.422} = 0.24\\]\nFinalmente, habiendo calculado los odds para cada tipo de persona se pueden calcular sus probabilidades predichas\n\\[p = \\frac{e^{𝛼+𝛽_jX_j}}{1+e^{𝛼+𝛽_jX_j}} = \\frac{odds_{xj}}{1+odds_{xj}}\\]\n\\[p_{sindicalizados} = \\frac{0.35}{1+0.35} = \\frac{0.35}{1.35} = 0.26\\]\n\\[p_{no.sindicalizados} = \\frac{0.24}{1+0.24} = \\frac{0.24}{1.24} = 0.19\\]\nLa probabilidad de que un/a sindicalizado participe en marchas es del 26%, mientras que la probabilidad de que alguien que no esté sindicalizado/a es del 19%"
  },
  {
    "objectID": "resource/06-resource.html#cálculo-de-probabilidades-predichas-en-r",
    "href": "resource/06-resource.html#cálculo-de-probabilidades-predichas-en-r",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Cálculo de probabilidades predichas en R",
    "text": "Cálculo de probabilidades predichas en R\n\nPaquete ggeffects de R: últil para estimar probabilidades predichas a partir de modelos de regresión logísticas\nCombinado con ggplot2, se pueden generar gráficos que muestran de modo más intuitivo la relación entre variables\n\nGráfico de probabilidades predichas para sindicalizados/as y no sindicalizados/as\n\nFigSind_1_Prob &lt;- ggeffects::ggpredict(m3log, terms = c(\"Unionized\")) %&gt;%\n  ggplot(aes(x=x, y=predicted)) +\n  geom_bar(stat=\"identity\", color=\"grey\", fill=\"grey\")+\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width=.1) +\n  labs(title=\"Sindicalización\", x = \"\", y = \"\") +\n  theme_bw() +\n  theme(plot.title = element_text(size = 12), \n        axis.text.x = element_text(angle = 0, vjust = 0.5, size = 12),\n        axis.text.y = element_text(vjust = 0.5, size = 10)) +\n  scale_x_continuous(name = \"\",\n                     breaks = c(0,1),\n                     labels = c(\"Non-union members\", \"Union members\")) +\n  scale_y_continuous(limits = c(0,0.35), \n                     breaks = seq(0,0.35, by = 0.05),\n                     labels = scales::percent_format(accuracy = 1L))\n\nFigSind_1_Prob\n\n\n\n\nGráfico de probabilidades predichas para variable politización\n\nFigPolit_1_Prob&lt;- ggeffects::ggpredict(m3log, terms=\"politicization\") %&gt;%\n  ggplot(mapping=aes(x = x, y=predicted)) +\n  labs(title=\"Politización\", x = \"\", y = \"\")+\n  theme_bw() +\n  geom_smooth()+\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = .2, fill = \"black\") +\n  theme(plot.title = element_text(size = 12), \n        axis.text.x = element_text(angle = 0, vjust = 0.5, size = 10),\n        axis.text.y = element_text(vjust = 0.5, size = 10))+\n  scale_x_continuous(breaks = seq(0,6, by = 1))+\n  scale_y_continuous(limits = c(0,0.6), breaks=seq(0,0.6, by = 0.1),\n                     labels = scales::percent_format(accuracy = 1L))\n\nFigPolit_1_Prob\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "resource/06-resource.html#bondad-de-ajuste-comando-de-paquete-lmtest",
    "href": "resource/06-resource.html#bondad-de-ajuste-comando-de-paquete-lmtest",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Bondad de ajuste (comando de paquete lmtest)",
    "text": "Bondad de ajuste (comando de paquete lmtest)\n\nRazón de verosimilitudes\n\n\nanova(m1log, m2log, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: demonstr_dummy ~ Unionized + Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      1453     1467.9                          \n2      1448     1442.1  5   25.828 9.635e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(m2log, m3log, test = \"Chisq\") \n\nAnalysis of Deviance Table\n\nModel 1: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    politicization + Wave\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      1448     1442.1                          \n2      1447     1395.8  1    46.21 1.063e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(m1log, m2log) #likelihood ratio test / Prueba de razón de verosimilitud (comparación m1-m2)\n\nLikelihood ratio test\n\nModel 1: demonstr_dummy ~ Unionized + Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   4 -733.94                         \n2   9 -721.03  5 25.828  9.635e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(m2log, m3log) #likelihood ratio test / Prueba de razón de verosimilitud (comparación m2-m3)\n\nLikelihood ratio test\n\nModel 1: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    Wave\nModel 2: demonstr_dummy ~ Unionized + Female + X003 + Educ + private_sector + \n    politicization + Wave\n  #Df  LogLik Df Chisq Pr(&gt;Chisq)    \n1   9 -721.03                        \n2  10 -697.92  1 46.21  1.063e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nPseudo R2 (McFadden)\n\n\nm1log_R2&lt;-DescTools::PseudoR2(m1log)\nm2log_R2&lt;-DescTools::PseudoR2(m2log)\nm3log_R2&lt;-DescTools::PseudoR2(m3log)\n\n#Misma tabla, en log odds, con Pseudo R2\nhtmlreg(list(m1log,m2log,m3log),\n          custom.model.names = c(\"m1 (log odds)\",\"m2 (log odds)\",\"m3 (log odds)\"),\n          custom.gof.rows=list(\"Pseudo R2\" = c(m1log_R2, m2log_R2,m3log_R2)),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nm1 (log odds)\n\n\nm2 (log odds)\n\n\nm3 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n\n\nUnionized\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n0.282***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n\n\nPseudo R2\n\n\n0.013\n\n\n0.030\n\n\n0.061\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1"
  },
  {
    "objectID": "resource/06-resource.html#efectos-de-interacción",
    "href": "resource/06-resource.html#efectos-de-interacción",
    "title": "Práctica 6 Regresión logística y Probabilidades predichas",
    "section": "Efectos de interacción",
    "text": "Efectos de interacción\nsindicalizacion - sector privado\n\nm3.1log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector + politicization + Wave + Unionized*private_sector, \n               data = WVS_2005_2022_Chl,family = \"binomial\")\n\nhtmlreg(list(m1log,m2log,m3log,m3.1log),\n          custom.model.names = c(\"M1 (log odds)\",\"M2 (log odds)\",\"M3 (log odds)\",\n                                 \"M3.1 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nM1 (log odds)\n\n\nM2 (log odds)\n\n\nM3 (log odds)\n\n\nM3.1 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n-1.452**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n(0.447)\n\n\n\n\nUnionized\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n0.569\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n(0.353)\n\n\n\n\nWaveWave 6\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n0.496**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n-0.122\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n0.094\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n(0.140)\n\n\n\n\nX003\n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n-0.044\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n0.259\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n-0.360†\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n(0.210)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n0.282***\n\n\n0.281***\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n(0.042)\n\n\n\n\nUnionized:private_sector\n\n\n \n\n\n \n\n\n \n\n\n-0.324\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.397)\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n1417.185\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n1475.310\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n-697.592\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n1395.185\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\n\nLa interacción también se puede graficar según probabilidades predichas\n\n\n# ojo que la relación sindicalización x sector privado no es significativa\nFigSindSector_int&lt;-ggeffects::ggpredict(m3.1log, terms = c(\"Unionized\", \"private_sector\")) %&gt;%\n  ggplot(aes(x=x, y=predicted, shape = group, color = group)) +\n  geom_line(aes(group=group,linetype = group),position = position_dodge(.1)) + \n  geom_point(size = 2.5,position = position_dodge(.1))+\n  scale_x_continuous(name = \"\", breaks=c(0,1), labels = c(\"No sindicalizados/as\", \"Sindicalizados/as\")) + \n  scale_shape_discrete(name = \"Sector de empleo\",\n                       limits = c(\"0\", \"1\"),\n                       labels = c(\"Público\", \"Privado\")) +\n  scale_color_manual(name = \"Sector de empleo\",\n                     limits = c(\"0\", \"1\"),\n                     labels = c(\"Público\", \"Privado\"),\n                     values = c(\"black\", \"black\")) +\n  scale_linetype_manual(name = \"Sector de empleo\",\n                        limits = c(\"0\", \"1\"),\n                        labels = c(\"Público\", \"Privado\"),\n                        values = c(\"solid\", \"dashed\")) +\n  scale_y_continuous(limits = c(0,0.40), breaks=seq(0,0.40, by = 0.05),\n                     labels = scales::percent_format(accuracy = 1L)) +\n  theme_bw() +\n  labs(title=\"\", y = \"\") + \n  theme(plot.title = element_text(size = 11),\n        axis.text=element_text(size=11))\n\nFigSindSector_int\n\n\n\n\n\nSector de empleo - politización\n\n\nm3.2log &lt;- glm(demonstr_dummy~ Unionized + Female + X003 + Educ + private_sector \n               + politicization + Wave + private_sector*politicization,\n               data = WVS_2005_2022_Chl,family = \"binomial\")\n\nhtmlreg(list(m1log,m2log,m3log,m3.1log,m3.2log),\n          custom.model.names = c(\"M1 (log odds)\",\"M2 (log odds)\",\"M3 (log odds)\",\n                                 \"M3.1 (log odds)\",\"M3.2 (log odds)\"),\n          digits = 3, \n          stars = c(0.001, 0.01, 0.05, 0.1),symbol = \"†\")\n\n\n\nStatistical models\n\n\n\n\n \n\n\nM1 (log odds)\n\n\nM2 (log odds)\n\n\nM3 (log odds)\n\n\nM3.1 (log odds)\n\n\nM3.2 (log odds)\n\n\n\n\n\n\n(Intercept)\n\n\n-1.601***\n\n\n-1.023*\n\n\n-1.379**\n\n\n-1.452**\n\n\n-1.416**\n\n\n\n\n \n\n\n(0.140)\n\n\n(0.424)\n\n\n(0.437)\n\n\n(0.447)\n\n\n(0.480)\n\n\n\n\nUnionized\n\n\n0.418**\n\n\n0.390*\n\n\n0.312†\n\n\n0.569\n\n\n0.310†\n\n\n\n\n \n\n\n(0.155)\n\n\n(0.157)\n\n\n(0.161)\n\n\n(0.353)\n\n\n(0.161)\n\n\n\n\nWaveWave 6\n\n\n0.470**\n\n\n0.498**\n\n\n0.496**\n\n\n0.496**\n\n\n0.495**\n\n\n\n\n \n\n\n(0.168)\n\n\n(0.171)\n\n\n(0.174)\n\n\n(0.174)\n\n\n(0.174)\n\n\n\n\nWaveWave 7\n\n\n-0.031\n\n\n-0.102\n\n\n-0.121\n\n\n-0.122\n\n\n-0.122\n\n\n\n\n \n\n\n(0.174)\n\n\n(0.181)\n\n\n(0.184)\n\n\n(0.184)\n\n\n(0.184)\n\n\n\n\nFemale\n\n\n \n\n\n-0.020\n\n\n0.100\n\n\n0.094\n\n\n0.100\n\n\n\n\n \n\n\n \n\n\n(0.136)\n\n\n(0.139)\n\n\n(0.140)\n\n\n(0.139)\n\n\n\n\nX003\n\n\n \n\n\n-0.007\n\n\n-0.012*\n\n\n-0.012*\n\n\n-0.012*\n\n\n\n\n \n\n\n \n\n\n(0.006)\n\n\n(0.006)\n\n\n(0.006)\n\n\n(0.006)\n\n\n\n\nEduc2\n\n\n \n\n\n0.042\n\n\n-0.053\n\n\n-0.044\n\n\n-0.053\n\n\n\n\n \n\n\n \n\n\n(0.268)\n\n\n(0.272)\n\n\n(0.272)\n\n\n(0.272)\n\n\n\n\nEduc3\n\n\n \n\n\n0.521†\n\n\n0.259\n\n\n0.259\n\n\n0.258\n\n\n\n\n \n\n\n \n\n\n(0.283)\n\n\n(0.289)\n\n\n(0.289)\n\n\n(0.289)\n\n\n\n\nprivate_sector\n\n\n \n\n\n-0.516**\n\n\n-0.445*\n\n\n-0.360†\n\n\n-0.396\n\n\n\n\n \n\n\n \n\n\n(0.175)\n\n\n(0.180)\n\n\n(0.210)\n\n\n(0.315)\n\n\n\n\npoliticization\n\n\n \n\n\n \n\n\n0.282***\n\n\n0.281***\n\n\n0.298**\n\n\n\n\n \n\n\n \n\n\n \n\n\n(0.042)\n\n\n(0.042)\n\n\n(0.093)\n\n\n\n\nUnionized:private_sector\n\n\n \n\n\n \n\n\n \n\n\n-0.324\n\n\n \n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.397)\n\n\n \n\n\n\n\nprivate_sector:politicization\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n-0.019\n\n\n\n\n \n\n\n \n\n\n \n\n\n \n\n\n \n\n\n(0.103)\n\n\n\n\nAIC\n\n\n1475.887\n\n\n1460.059\n\n\n1415.850\n\n\n1417.185\n\n\n1417.814\n\n\n\n\nBIC\n\n\n1497.024\n\n\n1507.616\n\n\n1468.691\n\n\n1475.310\n\n\n1475.939\n\n\n\n\nLog Likelihood\n\n\n-733.944\n\n\n-721.030\n\n\n-697.925\n\n\n-697.592\n\n\n-697.907\n\n\n\n\nDeviance\n\n\n1467.887\n\n\n1442.059\n\n\n1395.850\n\n\n1395.185\n\n\n1395.814\n\n\n\n\nNum. obs.\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n1457\n\n\n\n\n\n\n***p &lt; 0.001; **p &lt; 0.01; *p &lt; 0.05; †p &lt; 0.1\n\n\n\n\n\n\nFigPolitSector_int&lt;-ggeffects::ggpredict(m3.2log, terms = c(\"politicization\", \"private_sector\")) %&gt;%\n  ggplot(aes(x=x, y=predicted, shape = group, color = group)) +\n  geom_line(aes(group=group,linetype = group),position = position_dodge(.1)) + \n  geom_point(size = 2.5,position = position_dodge(.1))+\n  scale_x_continuous(breaks=seq(0,6, by = 1), name = \"\") + \n  scale_shape_discrete(name = \"Sector de empleo\",\n                       limits = c(\"0\", \"1\"),\n                       labels = c(\"Público\", \"Privado\")) +\n  scale_color_manual(name = \"Sector de empleo\",\n                     limits = c(\"0\", \"1\"),\n                     labels = c(\"Público\", \"Privado\"),\n                     values = c(\"black\", \"black\")) +\n  scale_linetype_manual(name = \"Sector de empleo\",\n                        limits = c(\"0\", \"1\"),\n                        labels = c(\"Público\", \"Privado\"),\n                        values = c(\"solid\", \"dashed\")) +\n  scale_y_continuous(limits = c(0,0.8), breaks=seq(0,0.8, by = 0.1),\n                     labels = scales::percent_format(accuracy = 1L)) +\n  theme_bw() +\n  labs(title=\"\", y = \"\") + \n  theme(plot.title = element_text(size = 11),\n        axis.text=element_text(size=11))\nFigPolitSector_int"
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos",
    "section": "",
    "text": "En esta sección se presentan una serie de recursos como ejemplos de investigaciones, construcción de instrumentos, muestreo, análisis y reporte.\n[en construcción]"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Pablo Perez Ahumada\n   Departamento de Sociología FACSO - sala 319\n   pabloperez@uchile.cl\n   pablo_perez_a\n   Schedule an appointment\n\n\n\n\n\n   Viernes\n   Marzo – Julio, 2024\n   09:00-11:45 AM\n   Sala 35. FACSO\n   Slack"
  },
  {
    "objectID": "syllabus.html#resumen",
    "href": "syllabus.html#resumen",
    "title": "Programa",
    "section": "Resumen",
    "text": "Resumen\nEste curso busca dar un primer acercamiento a la investigación social cuantitativa, abarcando desde aspectos iniciales básicos de estadística descriptiva y visualización de datos, hasta análisis e interpretación de modelos explicativos de investigación social. Asimismo, se busca que los y las estudiantes logren familiarizarse con el uso de Rstudio para el análisis de datos sociales.\nLa metodología incluye clases lectivas y trabajo práctico en R."
  },
  {
    "objectID": "syllabus.html#objetivo-general",
    "href": "syllabus.html#objetivo-general",
    "title": "Programa",
    "section": "Objetivo general",
    "text": "Objetivo general\nAl finalizar el curso, el/la estudiante podrá elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R."
  },
  {
    "objectID": "syllabus.html#objetivos-específicos",
    "href": "syllabus.html#objetivos-específicos",
    "title": "Programa",
    "section": "Objetivos específicos",
    "text": "Objetivos específicos\nAl concluir el curso lo/as estudiantes deberán haber alcanzado los siguientes resultados de aprendizaje:\n\nConocer las etapas de un diseño de investigación social cuantitativa y sus principales elementos\nFormular diseños de investigación social cuantitativa\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos\nInterpretar y analizar los elementos centrales de una base de datos con información social\nAplicar e interpretar técnicas de estadística descriptiva según las distintas características de los datos\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para variables con distinta unidad de medida\nAplicar e interpretar técnicas de regresión lineal y logística para variables numéricas y variables categóricas"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / contenidos",
    "text": "Saberes / contenidos\n\nMódulo 1: Estadística descriptiva\n1.1 Elementos básicos de la investigación social\n\nEtapas de la investigación Social\nTipos de diseños\nDiseño de instrumentos de medición\nBases de datos: datos de corte transversal, series de tiempo, cohortes, panel o longitudinal\n\n1.2 Operacionalización y análisis de datos\n\nOperacionalización y niveles de medición\nTidy data: unir, dividir, filtrar y ordenar datos en R\nRecodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\nAgrupación de datos y construcción de variables a partir de datos existentes\nConstrucción de índices y validez de escalas\n\n1.3 Visualización de datos en R\n\nTablas descriptivas y tablas de contingencia\nggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\n\nMódulo 2: Inferencia y estadística correlacional\n2.1 Inferencia estadística\n2.2 Pruebas de hipótesis\n2.3 Correlación\n\n\nMódulo 3: Regresión lineal y regresión logística\n3.1 Regresión lineal de mínimos cuadrados\n\nAspectos centrales y supuestos de la regresión MCO\nInterpretación de coeficientes (variables cuantitativas y cualitativas) y efectos de interacción\nRepresentación gráfica de coeficientes de regresión lineal\n\n3.2 Regresión logística binaria\n\nAspectos básicos de la regresión logística\nTipos de coeficientes e interpretación\nRepresentación gráfica (cálculo de probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#bibliografía",
    "href": "syllabus.html#bibliografía",
    "title": "Programa",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, Hadley & Grolemund, Garrett (2017). R for Data Science. Visualize, model, transform, tidy and import data. / Versión en español disponible acá\nMoore, D. S., & Comas, J. (2010). Estadística aplicada básica. Barcelona: Antoni Bosch.\nWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning.\nCamarero, et al (2017) Regresión Logística: Fundamentos y aplicación a la investigación sociológica.\nHair, Joseph F., et al. (2004). Análisis multivariante. 5ta ed. Madrid: Prentice Hall.\nCharte, Francisco (2014). Análisis exploratorio y Visualización de datos con R."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nEl curso se organiza en sesiones semanales, con una parte lectiva seguida de una práctica. En la parte lectiva se transmiten y discuten los conceptos centrales de la investigación cuantitativa. En la parte práctica se aplicarán los conceptos transmitidos en la parte lectiva, además de resolver dudas en el avance de los trabajos de investigación"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nLa evaluación consistirá en"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7)."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "Palabras Clave",
    "text": "Palabras Clave\n\nEstadística, investigación cuantitativa, manipulación de datos, visualización de datos, interpretación de coeficientes"
  }
]