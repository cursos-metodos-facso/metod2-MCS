---
title: "Práctico 6. Asociación con variables categóricas"
subtitle: "Metodología Cuantitativa Avanzada - Magíster en Ciencias Sociales"
date: "2025-05-30"
lang: es
output:
  number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE,
                      warning = FALSE)
```

## Objetivo de la práctica

El objetivo de esta guía práctica es introducirnos en técnicas de asociación entre variables categóricas, aplicando lo apredendido hasta ahora sobre inferencia estadística. 

En detalle, aprenderemos:

1.  Generar y analizar tablas de contingencia (o cruzadas)
2.  Estimar e interpretar la prueba de Chi-cuadrado
3.  Aplicar coeficientes de correlación entre variables categóricas

## 0. Aplicación práctica

En esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el [Ministerio de Desarrollo Social y Familia](https://observatorio.ministeriodesarrollosocial.gob.cl/). Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienen la opción de acceder a la misma información a través del siguiente enlace: [{{< fa table >}} `CASEN 20222`](https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/proc_casen.RData). Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.

### 0.1. Carga de librerías y datos datos

Comencemos por preparar nuestros datos. Iniciamos cargando las librerías necesarias.

```{r librerias, collapse=TRUE}
pacman::p_load(tidyverse, # Manipulacion datos
               sjPlot, # Tablas
               psych, # Correlaciones
               DescTools, # Tablas
               gginference, # Visualizacion 
               rempsyc, # Reporte
               broom) # Varios

options(scipen = 999) # para desactivar notacion cientifica
rm(list = ls()) # para limpiar el entorno de trabajo
```

Cargamos los datos directamente desde internet.

```{r datos}
load(url("https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/casen_proc.RData")) #Cargar base de datos

dim(proc_casen)
```

Contamos con 29 variables (columnas) y 3000 observaciones (filas).

## 1. Tablas de contingencia

Una tabla de contingencia es una de las maneras más simples y útiles para representar el cruce entre dos variables categóricas.

Con ella, podemos obtener en las celdas las frecuencias **conjuntas** entre ambas variables, es decir, cuántos casos de una determinada categoría de la variable `Y` ocurren conjuntamente con una determinada categoría de la variable `X`. 

Además, podemos presentar los totales de cada fila y columna al exterior de la tabla, también conocidas como frecuencias **marginales**.

Veamos un ejemplo con `ss_salud` y `universitaria`:

```{r}
sjPlot::sjt.xtab(var.row = proc_casen$ss_salud, var.col = proc_casen$universitaria, 
                 show.summary = F, emph.total = T)
```

Sumado a esto, tenemos:

- _Frecuencias absolutas_: números que aparencen en la tabla (ya sean conjuntas o marginales)
- _Frecuencias porcentuales_: 
          
  * **porcentaje fila**: % que cada frecuencia conjunta representa sobre la marginal de su fila
  * **porcentaje columna**: % que cada frecuencia conjunta representa sobre la marginal de su columna
  * **porcentaje total**: % que cada frecuencia conjunta representa sobre el número total de casos de la tabla

Veamos cómo incorporar el porcentaje fila y columna en la tabla.

```{r}
sjPlot::sjt.xtab(var.row = proc_casen$ss_salud, 
                 var.col = proc_casen$universitaria, 
                 show.summary = F, 
                 emph.total = T, 
                 show.row.prc = T, # porcentaje fila
                 show.col.prc = T # porcentaje columna
                 )
```

Aquí, los porcentajes fila aparecen en azul y los porcentajes columna en verde. 

## 2. Prueba de hipótesis con Chi-cuadrado

La prueba de Chi-cudrado ($\chi^2$) es una herramienta estadística utilizada para evaluar si existe una asociación significativa entre dos variables categóricas. 

Testeamos la **hipótesis de independencia** en una tabla de contigencia. Por ejemplo, si decimos que existe una relación entre tener educación superior y la preferencia por algún sistema de salud, esperamos encontrar que un porcentaje más alto de quienes tienen educación superior se inclinen por un sistema de salud determinado. 

Se basa en la comparación de las **frecuencias observadas** en una tabla de contingencia con las **frecuencias esperadas** si las variables fueran independientes. Si existe una gran diferencia entre las esperadas y las observadas, podemos suponer que hay una relación entre variables. 

::: {.callout-tip}
#### Prueba de Chi-cuadrado

Contrastamos la _hipótesis nula_ (o de trabajo) de que las variables son idenpendientes entre ellas:
$$  H_{0}: \pi_{fc} =  \pi_{f}\pi_{c} $$

En relación a una _hipótesis alternativa_ sobre que las variables están relacionadas:
$$  H_{A}:  \pi_{fc} \neq  \pi_{f}\pi_{c} $$
:::

Veamos un ejemplo con nuestros datos. Evaluemos si el nivel educacional se relaciona con el tipo de sistema de salud al que pertenecen las personas en Chile durante el 2022.

Apliquemos cinco pasos para inferencia.

1. Formulamos nuestras hipótesis:

- $H_{0}$: No hay asociación entre el nivel educacional y la preferencia por un sistema de salud.

- $H_{A}$: El nivel educacional se asocia con la preferencia por un sistema de salud.

2. Generar tabla de contingencia con frecuencias observadas y esperadas:

```{r}
conti_table <- table(proc_casen$ss_salud, proc_casen$universitaria)
conti_table
```

Además, podemos añadir las frecuencias marginales.

```{r}
row_sum <- margin.table(conti_table, 1)
col_sum <- margin.table(conti_table, 2)

conti_added <- cbind(conti_table, as.vector(row_sum))
conti_added <- rbind(conti_added, c(as.vector(col_sum), sum(conti_table)))
conti_added
```

Ahora, generamos una tabla de contingencia con frecuencias esperadas.

Las _frecuencias observadas_ corresponden a:

$$ f_{e_c} = \frac{{\text{(Total marginal de fila para la celda)} \times \text{(Total marginal de columna para la celda)}}}{{N}} $$

Usando nuestros datos la frecuencia esperada para la primera celda sería:

$$ f_{e_c} = \frac{(2551)*(2236)}{{2964}} = 1924.4$$

Esto debemos repetirlo para cada celda... pero podemos hacerlo más rápido con `DescTools`.

```{r}
exp_table <- DescTools::ExpFreq(conti_added, freq = "abs")
round(exp_table, 1)
```

3. Calcular el valor estimado de la prueba:

Establecemos la diferencia entre lo observado y lo esperado, siendo:

$$\chi^2=\sum\frac{(f_o-f_e)^2}{f_e}$$
```{r}
chi_stat <- sum(
  (2027-1924.4)^2/1924.4,
  (524-626.6)^2/626.6,
  (111-209.7)^2/209.7,
  (167-68.3)^2/68.3,
  (37-44.5)^2/44.5,
  (22-14.5)^2/14.5,
  (61-57.3)^2/57.3,
  (15-18.7)^2/18.7
  )
chi_stat
```

4. Especifica el valor crítico de la prueba:

```{r}
df <- (4-1)*(2-1) # definimos grados de libertad

chi_critico <- qchisq(p = 0.05, df, lower.tail = F)
chi_critico
```

5. Contrasta el valor estimado con el crítico e interpreta los resultados:

```{r}
chi_stat > chi_critico
```

> En el análisis utilizando la prueba de $\chi^2$ de Pearson para la asociación entre el tipo de sistema de salud y el nivel educativo, se encontró una relación significativa (χ2 = 217.56 , df = 3, p< .001). Por tanto, rechazamos la $H_{0}$ sobre no asociación con un 95% de confianza, existiendo evidencia a favor de nuestra $H_{A}$ ya que hay evidencia de una relación entre el sistema de salud y el nivel educativo.

6. Y el cálculo directo en R:

```{r, collapse=TRUE}
chi_results <- chisq.test(table(proc_casen$ss_salud, proc_casen$universitaria))

stats.table <- tidy(chi_results, conf_int = T)
nice_table(stats.table)
```

Visualicemos la distribución de esta prueba y su zona de rechazo.

```{r}
ggchisqtest(chi_results)
```


## 3. Correlación entre categóricas

Al igual que otros coeficientes de correlación, las correlaciones entre categóricas:

- Oscila entre -1 y 1.
- Indica la dirección y fuerza de asociación entre variables.
- Su tamaño de efecto se puede interpretar a partir de ciertos estándares.
- Se interpreta de la misma forma que otros coeficientes de correlación.

### 3.1. Punto biserial

La correlación punto biserial se utiliza para calcular la correlación entre una variable categórica dicotómica y una variable continua.

Veamos la frecuencia de `sexo` y la media de ingresos `y1`.

```{r}
sjmisc::frq(proc_casen$sexo)

mean(proc_casen$y1, na.rm = T)
```

Obtengamos la correlación punto biserial entre sexo e ingresos.

```{r}
cor.test(proc_casen$sexo, proc_casen$y1)
```

### 3.2. Tetracórica

La correlación tetracórica se utiliza para calcular la correlación entre dos variables binarias categóricas, es decir, variables nominales dicómoticas (solo dos posibles valores).

Veamos las frecuencias de `sexo` y `disc_fisica`.

```{r}
sjmisc::frq(proc_casen$sexo)

sjmisc::frq(proc_casen$disc_fisica)
```

Obtengamos la correlación tetrácorica entre sexo y discriminación por apariencia física.

```{r}
matriz <- proc_casen %>% select(sexo, disc_fisica) # creamos matriz con var de interes

psych::tetrachoric(matriz, na.rm = T)
```

### 3.3. Policórica

La correlación policórica se utiliza para calcular la correlación entre dos variables ordinales categóricas, es decir, variables ordinales cuyos posibles valores siguen un orden (por ejemplo, variables tipo Likert).

Veamos las frecuencias de `ayuda_moverse` y `ayuda_thogar`.

```{r}
sjmisc::frq(proc_casen$ayuda_moverse)

sjmisc::frq(proc_casen$ayuda_thogar)
```

Obtengamos la correlación policórica entre si la persona necesitó ayuda para moverse dentro de la casa y si necesitó ayuda para realizar tareas dentro del hogar, en los últimos 30 días.

```{r}
matriz <- proc_casen %>% select(ayuda_moverse, ayuda_thogar) # creamos matriz con var de interes

psych::polychoric(matriz, na.rm = T)
```
